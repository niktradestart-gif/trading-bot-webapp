# ===================== üåê –°–ò–°–¢–ï–ú–ù–´–ï –ò –û–°–ù–û–í–ù–´–ï =====================
import os
import sys
import json
import asyncio
import logging
import random
import pickle
import joblib
from datetime import datetime, timedelta, time
from functools import wraps
from typing import Optional, Dict, List, Tuple

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ event loop –¥–ª—è Windows
if sys.platform.startswith("win"):
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# ===================== üìä –ë–ò–ë–õ–ò–û–¢–ï–ö–ò –î–õ–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ò –ò –ú–ê–¢–ï–ú–ê–¢–ò–ö–ò =====================
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import mplfinance as mpf
from scipy.signal import argrelextrema
from matplotlib.patches import Rectangle

# MetaTrader 5 API
import MetaTrader5 as mt5

# ===================== üìÖ –ü–õ–ê–ù–ò–†–û–í–©–ò–ö (APSCHEDULER) =====================
from apscheduler.events import EVENT_JOB_MISSED, EVENT_JOB_ERROR, EVENT_JOB_EXECUTED

def job_listener(event):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏–π job queue"""
    if event.code == EVENT_JOB_MISSED:
        logging.warning(f"‚è∞ Job {event.job_id} –±—ã–ª –ø—Ä–æ–ø—É—â–µ–Ω!")
    elif event.code == EVENT_JOB_ERROR:
        logging.error(f"‚ùå Job {event.job_id} –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –æ—à–∏–±–∫–æ–π: {event.exception}")
    elif event.code == EVENT_JOB_EXECUTED:
        logging.debug(f"‚úÖ Job {event.job_id} –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")

# ===================== ü§ñ TELEGRAM BOT =====================
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import (
    Application, CommandHandler, MessageHandler, ContextTypes, filters
)

# ===================== üß† –ú–ê–®–ò–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï (ML) =====================
import talib as ta
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# ===================== üß† OPENAI API =====================
from openai import OpenAI


# ===================== FIXED BOT WORKING HOURS =====================
from datetime import datetime, time, timedelta

# üïí –†–∞–±–æ—á–∏–µ —á–∞—Å—ã –ø–æ –ª–æ–∫–∞–ª—å–Ω–æ–º—É –≤—Ä–µ–º–µ–Ω–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ú–æ–ª–¥–æ–≤–∞ UTC+2)
TRADING_START = time(4, 0)    # –ù–∞—á–∞–ª–æ —Ç–æ—Ä–≥–æ–≤–ª–∏: 04:00
TRADING_END   = time(23, 59)  # –ö–æ–Ω–µ—Ü —Ç–æ—Ä–≥–æ–≤–ª–∏: 23:59

# üóìÔ∏è –í—ã—Ö–æ–¥–Ω—ã–µ (—Å—É–±–±–æ—Ç–∞ –∏ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ)
WEEKEND_DAYS = {5, 6}  # 5 = —Å—É–±–±–æ—Ç–∞, 6 = –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ

def is_trading_time() -> bool:
    """‚è∞ –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–∞—Ö –±–æ—Ç–∞ —Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏"""
    global BOT_LAST_STATUS, BOT_STATUS_NOTIFIED
    
    try:
        now = datetime.now()
        current_time = now.time()
        current_weekday = now.weekday()
        
        # üóìÔ∏è –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ (—Å—É–±–±–æ—Ç–∞ –∏ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ)
        if current_weekday in WEEKEND_DAYS:
            is_working_time = False
        else:
            # üïí –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—á–∏–µ —á–∞—Å—ã
            is_working_time = TRADING_START <= current_time <= TRADING_END
        
        # üîî –ü–†–û–í–ï–†–Ø–ï–ú –ò–ó–ú–ï–ù–ï–ù–ò–ï –°–¢–ê–¢–£–°–ê –î–õ–Ø –£–í–ï–î–û–ú–õ–ï–ù–ò–ô
        if BOT_LAST_STATUS is None:
            BOT_LAST_STATUS = is_working_time
            BOT_STATUS_NOTIFIED = True
        elif BOT_LAST_STATUS != is_working_time:
            # –°—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–∏–ª—Å—è - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
            BOT_LAST_STATUS = is_working_time
            BOT_STATUS_NOTIFIED = False
        
        if not is_working_time:
            # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∏—è –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
            if current_weekday in WEEKEND_DAYS:
                days_until_monday = (7 - current_weekday) % 7
                next_work_day = now + timedelta(days=days_until_monday)
                next_open = datetime.combine(next_work_day.date(), TRADING_START)
            elif current_time < TRADING_START:
                next_open = datetime.combine(now.date(), TRADING_START)
            else:
                next_open = datetime.combine(now.date() + timedelta(days=1), TRADING_START)
            
            time_until = next_open - now
            hours = time_until.seconds // 3600
            minutes = (time_until.seconds % 3600) // 60
            
            logging.info(f"‚è∞ –í–Ω–µ —Ä–∞–±–æ—á–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. –î–æ –æ—Ç–∫—Ä—ã—Ç–∏—è: {hours}—á {minutes}–º–∏–Ω")
            return False
        else:
            return True
            
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—Ä–µ–º–µ–Ω–∏: {e}")
        return False

# ==================== TIME FILTERS (TRADE HOURS) ====================
import json
from datetime import datetime

def load_time_filters():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª time_filters.json"""
    try:
        with open("time_filters.json", "r", encoding="utf-8") as f:
            data = json.load(f)
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} —Ñ–∏–ª—å—Ç—Ä–æ–≤ –ø–æ –ø–∞—Ä–∞–º.")
            return data
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å time_filters.json: {e}")
        return {}

TIME_FILTERS = load_time_filters()
TIME_FILTERS_LAST_UPDATE = datetime.now()

def auto_reload_filters():
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ (–±–µ–∑ —Ä–µ—Å—Ç–∞—Ä—Ç–∞)"""
    global TIME_FILTERS, TIME_FILTERS_LAST_UPDATE
    try:
        import os
        mtime = datetime.fromtimestamp(os.path.getmtime("time_filters.json"))
        if mtime > TIME_FILTERS_LAST_UPDATE:
            TIME_FILTERS = load_time_filters()
            TIME_FILTERS_LAST_UPDATE = datetime.now()
            print("‚ôªÔ∏è –§–∞–π–ª —Ñ–∏–ª—å—Ç—Ä–æ–≤ –æ–±–Ω–æ–≤–ª—ë–Ω –Ω–∞ –ª–µ—Ç—É.")
    except Exception:
        pass

def is_trade_allowed(pair: str, ts: datetime = None) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ —Ç–æ—Ä–≥–æ–≤–∞—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—É—é –ø–∞—Ä—É –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç"""
    ts = ts or datetime.utcnow()
    hour = ts.hour
    auto_reload_filters()  # üîÑ –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞
    allowed_hours = TIME_FILTERS.get(pair, TIME_FILTERS.get("DEFAULT", list(range(24))))
    return hour in allowed_hours

# ================== ML MODEL LOAD ==================
import joblib
import json
import logging
import os

def load_latest_ml_info():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—ä–µ–∫—Ç –∏–∑ ml_info.json (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏ dict)"""
    try:
        if not os.path.exists("ml_info.json"):
            logging.warning("‚ö†Ô∏è –§–∞–π–ª ml_info.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return {}

        with open("ml_info.json", "r", encoding="utf-8") as f:
            data = json.load(f)

        if isinstance(data, list):
            if data:
                latest = data[-1]
                logging.info(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –æ–±—É—á–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é ({latest.get('trained_at', 'N/A')})")
                return latest
            else:
                logging.warning("‚ö†Ô∏è ml_info.json –ø—É—Å—Ç (—Å–ø–∏—Å–æ–∫ –±–µ–∑ –∑–∞–ø–∏—Å–µ–π)")
                return {}
        elif isinstance(data, dict):
            return data
        else:
            logging.warning(f"‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç ml_info.json: {type(data)}")
            return {}

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è ml_info.json: {e}", exc_info=True)
        return {}

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏, —Å–∫–µ–π–ª–µ—Ä–∞ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
try:
    ml_model = joblib.load("ml_model.pkl")
    ml_scaler = joblib.load("ml_scaler.pkl")  # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    model_info = load_latest_ml_info()

    if model_info:
        logging.info(f"‚úÖ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({model_info.get('trained_at', 'N/A')})")
    else:
        logging.warning("‚ö†Ô∏è ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–µ–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞")

except Exception as e:
    logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å ML –º–æ–¥–µ–ª—å: {e}")
    ml_model, ml_scaler, model_info = None, None, {}

# ================== ML MODEL INITIALIZATION ==================
def initialize_ml_model():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML –º–æ–¥–µ–ª–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    global ml_model, ml_scaler, model_info
    try:
        if os.path.exists("ml_model.pkl") and os.path.exists("ml_scaler.pkl"):
            ml_model = joblib.load("ml_model.pkl")
            ml_scaler = joblib.load("ml_scaler.pkl")
            if os.path.exists("ml_info.json"):
                with open("ml_info.json", "r", encoding="utf-8") as f:
                    model_info = json.load(f)
            logging.info("‚úÖ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        else:
            logging.warning("‚ö† ML –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—É—á–µ–Ω–∏–∏")
            ml_model, ml_scaler, model_info = None, None, {}
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ML –º–æ–¥–µ–ª–∏: {e}")
        ml_model, ml_scaler, model_info = None, None, {}

# –í—ã–∑–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
initialize_ml_model()

# ===================== CONFIG =====================
from dotenv import load_dotenv
load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    print("‚ö† –û—à–∏–±–∫–∞: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env —Ñ–∞–π–ª –∏ —É–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —É–∫–∞–∑–∞–Ω—ã TELEGRAM_TOKEN –∏ OPENAI_API_KEY")
    sys.exit(1)

print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")

# MT5
MT5_LOGIN = int(os.getenv("MT5_LOGIN", "0"))
MT5_PASSWORD = os.getenv("MT5_PASSWORD", "")
MT5_SERVER = os.getenv("MT5_SERVER", "")
MT5_PATH = os.getenv("MT5_PATH", r"C:\Program Files\Po Trade MetaTrader 5\terminal64.exe")

# –ü–∞—Ä—ã
PAIRS: List[str] = [
    "EURUSD","AUDCAD","AUDCHF","AUDJPY","AUDUSD",
    "CADCHF","CADJPY","CHFJPY","EURAUD","EURCAD",
    "EURCHF","EURGBP","EURJPY","GBPAUD","GBPCAD",
    "GBPCHF","GBPJPY","GBPUSD","USDCAD","USDCHF","USDJPY"
]


# ===================== BOT STATUS TRACKING =====================
BOT_LAST_STATUS = None  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —Å—Ç–∞—Ç—É—Å –±–æ—Ç–∞ (True - —Ä–∞–±–æ—Ç–∞–µ—Ç, False - –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
BOT_STATUS_NOTIFIED = False  # –§–ª–∞–≥ —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏


# ===================== POCKET OPTION WHITELIST SYSTEM =====================
import json
import os
from datetime import datetime

# –û—Å–Ω–æ–≤–Ω–æ–π –±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫
WHITELIST_FILE = "pocket_users.json"
BACKUP_FILE = "whitelist_ids.json"
REFERRAL_LINK = "https://pocket-friends.com/r/0qrjewbjlf"

# –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (–∞–¥–º–∏–Ω + –¥–µ–º–æ)
DEFAULT_USERS = {
    '69662105': {
        'name': 'Admin', 
        'role': 'admin',
        'telegram_id': 5129282647,
        'registered_at': '2024-01-15T10:30:00',
        'status': 'active'
    }
}

def load_whitelist():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        if os.path.exists(WHITELIST_FILE):
            with open(WHITELIST_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏
            save_whitelist(DEFAULT_USERS)
            return DEFAULT_USERS.copy()
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ whitelist: {e}")
        return DEFAULT_USERS.copy()

def save_whitelist(whitelist_data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ –≤ —Ñ–∞–π–ª"""
    try:
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
        with open(WHITELIST_FILE, "w", encoding="utf-8") as f:
            json.dump(whitelist_data, f, ensure_ascii=False, indent=2)
        
        # –ë—ç–∫–∞–ø —Ç–æ–ª—å–∫–æ ID
        backup_data = list(whitelist_data.keys())
        with open(BACKUP_FILE, "w", encoding="utf-8") as f:
            json.dump(backup_data, f, ensure_ascii=False, indent=2)
            
        logging.info(f"üíæ Whitelist —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {len(whitelist_data)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è whitelist: {e}")

def is_valid_pocket_id(pocket_id: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å Pocket Option ID"""
    whitelist = load_whitelist()
    return pocket_id in whitelist

def get_pocket_user_info(pocket_id: str) -> dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –ø–æ Pocket ID"""
    whitelist = load_whitelist()
    return whitelist.get(pocket_id)

def add_user_to_whitelist(pocket_id: str, name: str, telegram_id: int = None, role: str = "user"):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫"""
    whitelist = load_whitelist()
    
    if pocket_id in whitelist:
        return False, "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
    
    whitelist[pocket_id] = {
        'name': name,
        'role': role,
        'telegram_id': telegram_id,
        'registered_at': datetime.now().isoformat(),
        'status': 'active'
    }
    
    save_whitelist(whitelist)
    return True, "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–±–∞–≤–ª–µ–Ω"

def remove_user_from_whitelist(pocket_id: str):
    """–£–¥–∞–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –±–µ–ª–æ–≥–æ —Å–ø–∏—Å–∫–∞"""
    whitelist = load_whitelist()
    
    if pocket_id in whitelist:
        del whitelist[pocket_id]
        save_whitelist(whitelist)
        return True, "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–¥–∞–ª–µ–Ω"
    
    return False, "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω"

def get_whitelist_stats():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–µ–ª–æ–≥–æ —Å–ø–∏—Å–∫–∞"""
    whitelist = load_whitelist()
    total = len(whitelist)
    admins = sum(1 for user in whitelist.values() if user.get('role') == 'admin')
    active = sum(1 for user in whitelist.values() if user.get('status') == 'active')
    
    return {
        'total_users': total,
        'admins': admins,
        'active_users': active,
        'users': total - admins
    }

# –ó–∞–≥—Ä—É–∂–∞–µ–º –±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
WHITELIST = load_whitelist()


# ===================== SETTINGS =====================
USE_GPT = True
openai_client = OpenAI(api_key=OPENAI_API_KEY)

ML_ENABLED = True
ML_PROBABILITY_THRESHOLD = 0.65

# –ù–û–í–ê–Ø –ì–ò–ë–ö–ê–Ø –°–ò–°–¢–ï–ú–ê - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–≤—É—Ö —Ä–µ–∂–∏–º–æ–≤
MULTI_USER_MODE = True  # –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å —Ä–µ–∂–∏–º–∞
ADMIN_USER_ID = 5129282647
AUTO_TRADING = True  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–∫–ª—é—á–µ–Ω–∞

# –ú—É–ª—å—Ç–∏–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
users: Dict[int, Dict] = {}

# –û–¥–Ω–æ–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
single_user_data = {
    'virtual_balance': 100.0,
    'trade_counter': 0,
    'trade_history': [],
    'current_trade': None
}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ñ–ª–∞–≥–∏
IS_RUNNING = True
VIRTUAL_TRADING = True

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç–∞–≤–æ–∫
STAKE_AMOUNT = 10  
WIN_PROBABILITY = 0.6  
WIN_PROFIT = 18  
LOSS_AMOUNT = 10  

# ===================== KEYBOARDS =====================
from telegram import ReplyKeyboardMarkup

# –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
main_keyboard = [
    ["üìä –¢–æ—Ä–≥–æ–≤–ª—è", "‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ"],
    ["üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "üß† –ú–æ–¥–µ–ª–∏"],
    ["üìÖ –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ", "üìã –ü–æ–º–æ—â—å"]
]
main_markup = ReplyKeyboardMarkup(main_keyboard, resize_keyboard=True)

# üìä –¢–æ—Ä–≥–æ–≤–ª—è
def get_trading_keyboard(user_id: int) -> ReplyKeyboardMarkup:
    """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏"""
    user_data = get_user_data(user_id)
    auto_status = "üü¢ –ê–≤—Ç–æ-—Ç–æ—Ä–≥–æ–≤–ª—è: –í–ö–õ" if user_data.get('auto_trading', False) else "üî¥ –ê–≤—Ç–æ-—Ç–æ—Ä–≥–æ–≤–ª—è: –í–´–ö–õ"
    
    keyboard = [
        ["üîÑ –°–ª–µ–¥—É—é—â–∏–π —Å–∏–≥–Ω–∞–ª", "üìà –ò—Å—Ç–æ—Ä–∏—è"],
        [auto_status],
        ["‚óÄÔ∏è –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

# ‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
management_keyboard = [
    ["üéØ –ò–∑–º–µ–Ω–∏—Ç—å —Å—Ç–∞–≤–∫—É", "üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"],
    ["üõë –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–æ—Ç–∞"],
    ["‚óÄÔ∏è –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"]
]
management_markup = ReplyKeyboardMarkup(management_keyboard, resize_keyboard=True)

# üß† –ú–æ–¥–µ–ª–∏
def get_models_keyboard(user_id: int) -> ReplyKeyboardMarkup:
    """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π —Å —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º"""
    user_data = get_user_data(user_id)
    
    ml_status = "üü¢ ML: –í–ö–õ" if user_data.get('ml_enabled', ML_ENABLED) else "üî¥ ML: –í–´–ö–õ"
    gpt_status = "üü¢ GPT: –í–ö–õ" if user_data.get('gpt_enabled', USE_GPT) else "üî¥ GPT: –í–´–ö–õ"
    smc_status = "üü¢ SMC: –í–ö–õ" if user_data.get('smc_enabled', True) else "üî¥ SMC: –í–´–ö–õ"
    
    keyboard = [
        ["üìä ML –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "üîÑ –û–±—É—á–∏—Ç—å ML"],
        [ml_status, gpt_status],
        [smc_status],
        ["‚óÄÔ∏è –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

# ===================== ENHANCED LOGGING =====================
def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # –§–æ—Ä–º–∞—Ç—Ç–µ—Ä —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    
    # –§–∞–π–ª–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
    file_handler = logging.FileHandler("bot_ai.log", encoding="utf-8")
    file_handler.setFormatter(formatter)
    
    # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö
    logger.handlers.clear()
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞
    logging.info("=" * 50)
    logging.info("üöÄ BOT ASPIRE TRADE STARTED")
    logging.info("=" * 50)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
setup_logging()

# ===================== UNIFIED USER MANAGEMENT =====================
def get_user_data(user_id: int = None) -> Dict:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ë–ï–ó –ë–ê–õ–ê–ù–°–ê"""
    if MULTI_USER_MODE and user_id is not None:
        if user_id not in users:
            users[user_id] = {
                'trade_counter': 0,
                'trade_history': [],
                'current_trade': None,
                'first_name': '',
                'username': '',
                'language': 'ru',
                'created_at': datetime.now().isoformat(),
                'auto_trading': True,
                'ml_enabled': ML_ENABLED,
                'gpt_enabled': USE_GPT,
                'smc_enabled': True
            }
        return users[user_id]
    else:
        return single_user_data

def is_admin(user_id: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–¥–º–∏–Ω–æ–º"""
    return user_id == ADMIN_USER_ID


# ===================== –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –§–õ–ï–¢–¢–ï–† ML –§–ò–ß–ï–ô =====================
def flatten_ml_features(features_dict, parent_key='', sep='_'):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Ä–∞—Å–ø–ª—é—â–∏–≤–∞–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ ML —Ñ–∏—á–µ–π –≤ –ø–ª–æ—Å–∫–∏–µ –∫–ª—é—á–∏"""
    items = {}
    for k, v in features_dict.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        if isinstance(v, dict):
            items.update(flatten_ml_features(v, new_key, sep=sep))
        else:
            if isinstance(v, (bool, np.bool_)):
                items[new_key] = bool(v)
            elif isinstance(v, (np.float32, np.float64, float)):
                items[new_key] = float(v)
            elif isinstance(v, (np.int32, np.int64, int)):
                items[new_key] = int(v)
            elif isinstance(v, np.ndarray):
                items[new_key] = v.tolist()
            else:
                try:
                    items[new_key] = float(v)
                except Exception:
                    items[new_key] = str(v)
    return items


# ===================== –°–û–•–†–ê–ù–ï–ù–ò–ï –î–ê–ù–ù–´–• –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô =====================
def save_users_data():
    """üíæ –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –ø–æ–ª–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π 42 ML-—Ñ–∏—á–µ–π –∏ –Ω–∞–¥—ë–∂–Ω—ã–º–∏ –±—ç–∫–∞–ø–∞–º–∏"""
    try:
        if MULTI_USER_MODE:
            users_to_save = {}
            for uid, data in users.items():
                trade_history_clean = []
                for trade in data.get('trade_history', []):
                    clean_trade = {
                        'id': int(trade.get('id', 0)),
                        'pair': str(trade.get('pair', '')),
                        'direction': str(trade.get('direction', '')),
                        'entry_price': float(trade.get('entry_price', 0)),
                        'exit_price': float(trade.get('exit_price', 0)) if trade.get('exit_price') else None,
                        'stake': float(trade.get('stake', STAKE_AMOUNT)),
                        'timestamp': str(trade.get('timestamp', datetime.now().isoformat())),
                        'result': str(trade.get('result', '')) if trade.get('result') else None,
                        'profit': float(trade.get('profit', 0)),
                        'expiry_minutes': int(trade.get('expiry_minutes', 1)),
                        'source': str(trade.get('source', '')),
                        'confidence': int(trade.get('confidence', 0)),
                        'completed_at': str(trade.get('completed_at', '')) if trade.get('completed_at') else None,
                        'stake_used': float(trade.get('stake_used', STAKE_AMOUNT))
                    }

                    # üß† –°–æ—Ö—Ä–∞–Ω—è–µ–º 42 ML-—Ñ–∏—á–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é, –≤–∫–ª—é—á–∞—è –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                    ml_features = trade.get('ml_features')
                    if ml_features and isinstance(ml_features, dict):
                        clean_ml_features = {}
                        for key, value in ml_features.items():
                            if isinstance(value, (bool, np.bool_)):
                                clean_ml_features[key] = bool(value)
                            elif isinstance(value, (np.float32, np.float64, float)):
                                clean_ml_features[key] = float(value)
                            elif isinstance(value, (np.int32, np.int64, int)):
                                clean_ml_features[key] = int(value)
                            elif isinstance(value, np.ndarray):
                                clean_ml_features[key] = value.tolist()
                            elif isinstance(value, dict):
                                clean_ml_features[key] = {
                                    k: (
                                        float(v) if isinstance(v, (np.float32, np.float64, float)) else
                                        int(v) if isinstance(v, (np.int32, np.int64, int)) else
                                        bool(v) if isinstance(v, (bool, np.bool_)) else v
                                    )
                                    for k, v in value.items()
                                }
                            else:
                                clean_ml_features[key] = str(value)
                        clean_trade['ml_features'] = clean_ml_features

                    trade_history_clean.append(clean_trade)

                trade_history_clean.sort(key=lambda x: x.get('id', 0))

                users_to_save[str(uid)] = {
                    'trade_counter': int(data.get('trade_counter', 0)),
                    'trade_history': trade_history_clean,
                    'current_trade': data.get('current_trade'),
                    'first_name': str(data.get('first_name', '')),
                    'username': str(data.get('username', '')),
                    'language': str(data.get('language', 'ru')),
                    'created_at': str(data.get('created_at', datetime.now().isoformat())),
                    'auto_trading': bool(data.get('auto_trading', True)),
                    'ml_enabled': bool(data.get('ml_enabled', ML_ENABLED)),
                    'gpt_enabled': bool(data.get('gpt_enabled', USE_GPT)),
                    'smc_enabled': bool(data.get('smc_enabled', True)),
                    'last_save': datetime.now().isoformat()
                }

            # üìÅ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å —Ä–µ–∑–µ—Ä–≤–Ω—ã–º–∏ –∫–æ–ø–∏—è–º–∏ (–Ω–µ —á–∞—â–µ 1 —Ä–∞–∑–∞ –≤ —á–∞—Å)
            os.makedirs("backups", exist_ok=True)
            temp_filename = "users_data.json.tmp"
            final_filename = "users_data.json"

            # üïí –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è –±—ç–∫–∞–ø–∞ –ø–æ —á–∞—Å—É, —á—Ç–æ–±—ã –Ω–µ –ø–ª–æ–¥–∏—Ç—å –ª–∏—à–Ω–∏–µ —Ñ–∞–π–ª—ã
            hour_stamp = datetime.now().strftime('%Y%m%d_%H')
            backup_filename = f"backups/users_data_backup_{hour_stamp}.json"

            try:
                # üìù –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                with open(temp_filename, "w", encoding="utf-8") as f:
                    json.dump(users_to_save, f, ensure_ascii=False, indent=2, default=str)

                # ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                with open(temp_filename, "r", encoding="utf-8") as f:
                    json.load(f)

                # üì¶ –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª ‚Äî –¥–µ–ª–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é, –Ω–æ –Ω–µ —á–∞—â–µ 1 —Ä–∞–∑–∞ –≤ —á–∞—Å
                import shutil
                if os.path.exists(final_filename):
                    if not os.path.exists(backup_filename):
                        shutil.copy2(final_filename, backup_filename)
                        logging.info(f"üíæ –ß–∞—Å–æ–≤–æ–π –±—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_filename}")

                        # üßπ –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã, –µ—Å–ª–∏ –∏—Ö –±–æ–ª—å—à–µ 4
                        backups = sorted(
                            [f for f in os.listdir("backups") if f.startswith("users_data_backup_")],
                            key=lambda x: os.path.getmtime(os.path.join("backups", x)),
                            reverse=True
                        )
                        if len(backups) > 4:
                            for old_backup in backups[4:]:
                                try:
                                    os.remove(os.path.join("backups", old_backup))
                                    logging.info(f"üóë –£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: {old_backup}")
                                except Exception as del_err:
                                    logging.warning(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {old_backup}: {del_err}")
                    
                os.remove(final_filename)
  
                # üîÑ –ê—Ç–æ–º–∞—Ä–Ω–∞—è –∑–∞–º–µ–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π
                os.rename(temp_filename, final_filename)

                # üß† ML-–±—ç–∫–∞–ø (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å—é –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)
                with open("ml_training_data.json", "w", encoding="utf-8") as f:
                    json.dump(users_to_save, f, ensure_ascii=False, indent=2, default=str)

                # üü¢ –õ–æ–≥ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                total_trades = sum(len(u['trade_history']) for u in users_to_save.values())
                logging.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ {len(users)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, {total_trades} —Å–¥–µ–ª–æ–∫")

            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
                if os.path.exists(temp_filename):
                    os.remove(temp_filename)
                raise e


        else:
            # üßç –û–¥–Ω–æ–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —Ä–µ–∂–∏–º
            trade_history_clean = []
            for trade in single_user_data.get('trade_history', []):
                clean_trade = {
                    'id': int(trade.get('id', 0)),
                    'pair': str(trade.get('pair', '')),
                    'direction': str(trade.get('direction', '')),
                    'entry_price': float(trade.get('entry_price', 0)),
                    'exit_price': float(trade.get('exit_price', 0)) if trade.get('exit_price') else None,
                    'stake': float(trade.get('stake', STAKE_AMOUNT)),
                    'timestamp': str(trade.get('timestamp', datetime.now().isoformat())),
                    'result': str(trade.get('result', '')) if trade.get('result') else None,
                    'profit': float(trade.get('profit', 0)),
                    'expiry_minutes': int(trade.get('expiry_minutes', 1)),
                    'source': str(trade.get('source', '')),
                    'confidence': int(trade.get('confidence', 0)),
                    'completed_at': str(trade.get('completed_at', '')) if trade.get('completed_at') else None,
                    'stake_used': float(trade.get('stake_used', STAKE_AMOUNT))
                }

                ml_features = trade.get('ml_features')
                if ml_features and isinstance(ml_features, dict):
                    clean_ml_features = {}
                    for key, value in ml_features.items():
                        if isinstance(value, (bool, np.bool_)):
                            clean_ml_features[key] = bool(value)
                        elif isinstance(value, (np.float32, np.float64, float)):
                            clean_ml_features[key] = float(value)
                        elif isinstance(value, (np.int32, np.int64, int)):
                            clean_ml_features[key] = int(value)
                        elif isinstance(value, np.ndarray):
                            clean_ml_features[key] = value.tolist()
                        elif isinstance(value, dict):
                            clean_ml_features[key] = {k: (float(v) if isinstance(v, (int,float)) else str(v)) for k,v in value.items()}
                        else:
                            clean_ml_features[key] = str(value)
                    clean_trade['ml_features'] = clean_ml_features

                trade_history_clean.append(clean_trade)

            trade_history_clean.sort(key=lambda x: x.get('id', 0))

            single_to_save = {
                'trade_counter': int(single_user_data.get('trade_counter', 0)),
                'trade_history': trade_history_clean,
                'current_trade': single_user_data.get('current_trade'),
                'last_save': datetime.now().isoformat()
            }

            os.makedirs("backups", exist_ok=True)
            temp_filename = "single_user_data.json.tmp"
            final_filename = "single_user_data.json"
            backup_filename = f"backups/single_user_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

            try:
                with open(temp_filename, "w", encoding="utf-8") as f:
                    json.dump(single_to_save, f, ensure_ascii=False, indent=2, default=str)

                with open(temp_filename, "r", encoding="utf-8") as f:
                    json.load(f)

                if os.path.exists(final_filename):
                    import shutil
                    shutil.copy2(final_filename, backup_filename)
                    os.remove(final_filename)

                os.rename(temp_filename, final_filename)

                with open("ml_training_data_single.json", "w", encoding="utf-8") as f:
                    json.dump(single_to_save, f, ensure_ascii=False, indent=2, default=str)

                logging.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, {len(trade_history_clean)} —Å–¥–µ–ª–æ–∫")

            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è single: {e}")
                if os.path.exists(temp_filename):
                    os.remove(temp_filename)
                raise e

    except Exception as e:
        logging.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ save_users_data: {e}")


def load_users_data():
    """üì• –ù–∞–¥—ë–∂–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –±—ç–∫–∞–ø–∞–º–∏ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º —Å—á–µ—Ç—á–∏–∫–æ–≤"""
    global users, single_user_data
    try:
        if MULTI_USER_MODE:
            if os.path.exists("users_data.json"):
                success = load_from_file("users_data.json", "multi")
                if not success:
                    backups = [f for f in os.listdir("backups") if f.startswith("users_data_backup")]
                    if backups:
                        backups.sort(reverse=True)
                        latest = os.path.join("backups", backups[0])
                        logging.warning(f"‚ö† –ü–æ–≤—Ä–µ–∂–¥—ë–Ω —Ñ–∞–π–ª, –ø—Ä–æ–±—É–µ–º –±—ç–∫–∞–ø: {latest}")
                        load_from_file(latest, "multi")
                    else:
                        users = {}
                        logging.warning("‚ö† –ù–µ—Ç –±—ç–∫–∞–ø–æ–≤ ‚Äî –ø—É—Å—Ç–∞—è –±–∞–∑–∞")
            else:
                users = {}
                logging.info("üìù users_data.json –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –±–∞–∑—É")
        else:
            if os.path.exists("single_user_data.json"):
                success = load_from_file("single_user_data.json", "single")
                if not success:
                    backups = [f for f in os.listdir("backups") if f.startswith("single_user_backup")]
                    if backups:
                        backups.sort(reverse=True)
                        latest = os.path.join("backups", backups[0])
                        logging.warning(f"‚ö† –ü–æ–≤—Ä–µ–∂–¥—ë–Ω single —Ñ–∞–π–ª, –ø—Ä–æ–±—É–µ–º –±—ç–∫–∞–ø: {latest}")
                        load_from_file(latest, "single")
                    else:
                        single_user_data = create_default_single_data()
            else:
                single_user_data = create_default_single_data()
                logging.info("üìù single_user_data.json –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –±–∞–∑—É")
    except Exception as e:
        logging.error(f"üí• –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        users = {}
        single_user_data = create_default_single_data()


def load_from_file(filename, mode):
    """üì• –ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON –∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å—á—ë—Ç—á–∏–∫–∏"""
    try:
        with open(filename, "r", encoding="utf-8") as f:
            content = f.read().strip()

        if not content:
            logging.warning(f"‚ö† –§–∞–π–ª {filename} –ø—É—Å—Ç")
            return False

        data = json.loads(content)

        if mode == "multi":
            users.clear()
            for uid_str, udata in data.items():
                uid = int(uid_str)
                users[uid] = udata
                hist_count = len(udata.get('trade_history', []))
                if udata.get('trade_counter', 0) != hist_count:
                    users[uid]['trade_counter'] = hist_count
            logging.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(users)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
        else:
            single_user_data.update(data)
            hist_count = len(single_user_data.get('trade_history', []))
            if single_user_data.get('trade_counter', 0) != hist_count:
                single_user_data['trade_counter'] = hist_count
            logging.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ single ({hist_count} —Å–¥–µ–ª–æ–∫)")
        return True

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ load_from_file {filename}: {e}")
        return False


def create_default_single_data():
    """–°–æ–∑–¥–∞—ë—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É single –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    return {
        'trade_counter': 0,
        'trade_history': [],
        'current_trade': None
    }
# ===================== SMART MONEY ANALYSIS =====================
def find_market_structure(df, lookback=25):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä—ã–Ω–∫–∞ - HH, HL, LH, LL"""
    highs = df['high'].values
    lows = df['low'].values
    structure_points = []
    
    for i in range(lookback, len(df) - lookback):
        if (highs[i] > max(highs[i-lookback:i]) and 
            highs[i] > max(highs[i+1:i+lookback+1])):
            structure_points.append({
                'type': 'HH',
                'price': highs[i],
                'index': i,
                'time': df.index[i]
            })
        if (lows[i] < min(lows[i-lookback:i]) and 
            lows[i] < min(lows[i+1:i+lookback+1])):
            structure_points.append({
                'type': 'LL',
                'price': lows[i],
                'index': i,
                'time': df.index[i]
            })
    
    return structure_points[-8:]

def find_horizontal_levels(df, threshold_pips=0.0005):
    try:
        levels = []
        prices = pd.concat([df['high'], df['low'], df['close']]).sort_values()
        price_values = prices.values
        clusters = []
        
        i = 0
        while i < len(price_values):
            current_price = price_values[i]
            cluster = [current_price]
            
            j = i + 1
            while j < len(price_values) and abs(price_values[j] - current_price) <= threshold_pips:
                cluster.append(price_values[j])
                j += 1
            
            if len(cluster) >= 5:
                cluster_mean = np.mean(cluster)
                
                touches = 0
                for idx in range(len(df)):
                    high = df['high'].iloc[idx]
                    low = df['low'].iloc[idx]
                    if (low <= cluster_mean <= high) or \
                       (abs(high - cluster_mean) <= threshold_pips) or \
                       (abs(low - cluster_mean) <= threshold_pips):
                        touches += 1
                
                if touches >= 6:
                    recent_prices = df['close'].tail(20)
                    above_level = sum(recent_prices > cluster_mean)
                    below_level = sum(recent_prices < cluster_mean)
                    
                    level_type = "RESISTANCE" if above_level > below_level else "SUPPORT"
                    
                    levels.append({
                        'price': cluster_mean,
                        'touches': touches,
                        'type': level_type,
                        'strength': 'STRONG' if touches > 10 else 'MEDIUM',
                        'cluster_size': len(cluster)
                    })
            
            i = j
        
        unique_levels = []
        for level in levels:
            is_duplicate = False
            for existing in unique_levels:
                if abs(level['price'] - existing['price']) <= threshold_pips:
                    is_duplicate = True
                    if level['touches'] > existing['touches']:
                        unique_levels.remove(existing)
                        unique_levels.append(level)
                    break
            
            if not is_duplicate:
                unique_levels.append(level)
        
        return sorted(unique_levels, key=lambda x: x['touches'], reverse=True)[:8]
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π: {e}")
        return []

def find_supply_demand_zones(df, strength=2, lookback=25):
    try:
        highs = df['high'].values
        lows = df['low'].values
        volumes = df['tick_volume'].values
        zones = []
        
        high_peaks = argrelextrema(highs, np.greater, order=strength)[0]
        low_peaks = argrelextrema(lows, np.less, order=strength)[0]
        
        avg_volume = np.mean(volumes[-50:]) if len(volumes) > 50 else np.mean(volumes)
        
        for peak in high_peaks[-8:]:
            if peak > 15:
                peak_high = highs[peak]
                if (peak_high > np.max(highs[max(0, peak-15):peak]) and 
                    peak_high > np.max(highs[peak+1:min(len(highs), peak+16)])):
                    
                    volume_ratio = volumes[peak] / avg_volume if avg_volume > 0 else 1
                    
                    if volume_ratio > 1.3:
                        zones.append({
                            'type': 'SUPPLY',
                            'top': peak_high,
                            'bottom': peak_high * 0.999,
                            'strength': 'STRONG' if volume_ratio > 2.0 else 'MEDIUM',
                            'index': peak,
                            'volume_ratio': volume_ratio,
                            'source': 'EXTREME'
                        })
        
        for valley in low_peaks[-8:]:
            if valley > 15:
                valley_low = lows[valley]
                if (valley_low < np.min(lows[max(0, valley-15):valley]) and 
                    valley_low < np.min(lows[valley+1:min(len(lows), valley+16)])):
                    
                    volume_ratio = volumes[valley] / avg_volume if avg_volume > 0 else 1
                    
                    if volume_ratio > 1.3:
                        zones.append({
                            'type': 'DEMAND',
                            'top': valley_low * 1.001,
                            'bottom': valley_low,
                            'strength': 'STRONG' if volume_ratio > 2.0 else 'MEDIUM',
                            'index': valley,
                            'volume_ratio': volume_ratio,
                            'source': 'EXTREME'
                        })
        
        horizontal_levels = find_horizontal_levels(df)
        for level in horizontal_levels:
            zone_width = 0.0003
            zones.append({
                'type': 'SUPPLY' if level['type'] == 'RESISTANCE' else 'DEMAND',
                'top': level['price'] + zone_width,
                'bottom': level['price'] - zone_width,
                'strength': level['strength'],
                'index': len(df) - 1,
                'volume_ratio': 1.5,
                'source': 'HORIZONTAL',
                'touches': level['touches']
            })
        
        zones.sort(key=lambda x: (
            3 if x['strength'] == 'STRONG' else 2 if x['strength'] == 'MEDIUM' else 1,
            x.get('touches', 0),
            x['volume_ratio']
        ), reverse=True)
        
        return zones[:5]
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∑–æ–Ω: {e}")
        return []
    
def calculate_order_blocks_advanced(df):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –æ—Ä–¥–µ—Ä-–±–ª–æ–∫–æ–≤ —Å –ª—É—á—à–∏–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ–º"""
    order_blocks = []
    avg_candle_size = df['high'].subtract(df['low']).rolling(50).mean().iloc[-1]
    
    if pd.isna(avg_candle_size) or avg_candle_size == 0:
        avg_candle_size = df['high'].subtract(df['low']).mean()
    
    for i in range(20, len(df) - 10):
        current_candle = df.iloc[i]
        candle_body = abs(current_candle['close'] - current_candle['open'])
        candle_range = current_candle['high'] - current_candle['low']
        
        is_significant = (candle_body > avg_candle_size * 2.0 or 
                         candle_range > avg_candle_size * 2.5)
        
        if not is_significant:
            continue
            
        # –ú–µ–¥–≤–µ–∂–∏–π OB
        if (current_candle['close'] < current_candle['open'] and
            candle_body > avg_candle_size * 1.8):
            
            next_candles = df.iloc[i+1:i+8]
            if len(next_candles) >= 3:
                touched_ob = any(low < current_candle['close'] for low in next_candles['low'])
                rebounded = any(close > current_candle['close'] for close in next_candles['close'])
                
                if touched_ob and rebounded:
                    order_blocks.append({
                        'type': 'BEARISH_OB',
                        'high': current_candle['open'],
                        'low': current_candle['close'],
                        'index': i,
                        'strength': 'STRONG'
                    })
        
        # –ë—ã—á–∏–π OB
        elif (current_candle['close'] > current_candle['open'] and
              candle_body > avg_candle_size * 1.8):
            
            next_candles = df.iloc[i+1:i+8]
            if len(next_candles) >= 3:
                touched_ob = any(high > current_candle['close'] for high in next_candles['high'])
                rebounded = any(close < current_candle['close'] for close in next_candles['close'])
                
                if touched_ob and rebounded:
                    order_blocks.append({
                        'type': 'BULLISH_OB',
                        'high': current_candle['close'],
                        'low': current_candle['open'],
                        'index': i,
                        'strength': 'STRONG'
                    })
    
    return order_blocks[-3:]

def calculate_fibonacci_levels(df):
    """–†–∞—Å—á—ë—Ç —É—Ä–æ–≤–Ω–µ–π –§–∏–±–æ–Ω–∞—á—á–∏ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∏–º–ø—É–ª—å—Å—É"""
    try:
        recent = df.tail(100)
        high = recent['high'].max()
        low = recent['low'].min()

        diff = high - low
        levels = []
        fib_ratios = [0, 0.236, 0.382, 0.5, 0.618, 0.786, 1]

        for r in fib_ratios:
            level = high - diff * r
            levels.append({"ratio": int(r*100), "level": level})

        return levels
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ calculate_fibonacci_levels: {e}")
        return []

def enhanced_trend_analysis(df):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∏–º–ø—É–ª—å—Å–Ω—ã—Ö –¥–≤–∏–∂–µ–Ω–∏–π"""
    try:
        # =============== –°–¢–ê–ù–î–ê–†–¢–ù–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ ===============
        ema_20 = ta.EMA(df['close'], 20).iloc[-1]
        ema_50 = ta.EMA(df['close'], 50).iloc[-1]
        ema_100 = ta.EMA(df['close'], 100).iloc[-1]
        
        adx = ta.ADX(df['high'], df['low'], df['close'], 14).iloc[-1]
        rsi = ta.RSI(df['close'], 14).iloc[-1]
        current_price = df['close'].iloc[-1]
        
        # =============== –ù–û–í–´–ï –ú–ï–¢–†–ò–ö–ò –ò–ú–ü–£–õ–¨–°–ê ===============
        # 1. –°–∏–ª–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
        if len(df) >= 10:
            price_change_5 = (current_price - df['close'].iloc[-5]) / df['close'].iloc[-5] * 100
            price_change_10 = (current_price - df['close'].iloc[-10]) / df['close'].iloc[-10] * 100
        else:
            price_change_5 = 0
            price_change_10 = 0
        
        # 2. –û–±—ä–µ–º –∏–º–ø—É–ª—å—Å–∞
        current_volume = df['tick_volume'].iloc[-1]
        avg_volume_20 = df['tick_volume'].tail(20).mean()
        volume_ratio = current_volume / avg_volume_20 if avg_volume_20 > 0 else 1
        
        # 3. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–ø—É–ª—å—Å–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
        is_strong_impulse = (
            abs(price_change_5) > 0.15 or  # –°–∏–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –∑–∞ 5 —Å–≤–µ—á–µ–π
            abs(price_change_10) > 0.25    # –°–∏–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –∑–∞ 10 —Å–≤–µ—á–µ–π
        )
        
        # 4. –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ –ø–æ EMA
        if ema_20 > ema_50 > ema_100:
            trend_direction = "BULLISH"
        elif ema_20 < ema_50 < ema_100:
            trend_direction = "BEARISH"
        else:
            trend_direction = "NEUTRAL"
        
        # 5. –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞ —Å —É—á–µ—Ç–æ–º –∏–º–ø—É–ª—å—Å–∞ –∏ ADX
        if adx > 30 and is_strong_impulse:
            trend_strength = "VERY_STRONG"
        elif adx > 25:
            trend_strength = "STRONG"
        elif adx < 15:
            trend_strength = "WEAK"
        else:
            trend_strength = "MODERATE"
        
        # 6. –°–æ—Å—Ç–æ—è–Ω–∏–µ RSI
        if rsi > 70:
            rsi_state = "OVERBOUGHT"
        elif rsi < 30:
            rsi_state = "OVERSOLD"
        else:
            rsi_state = "NEUTRAL"
        
        return {
            'direction': trend_direction,
            'strength': trend_strength,
            'rsi_state': rsi_state,
            'adx_value': adx,
            'rsi_value': rsi,
            'above_ema20': current_price > ema_20,
            'above_ema50': current_price > ema_50,
            # üî• –ù–æ–≤—ã–µ –ø–æ–ª—è –∏–º–ø—É–ª—å—Å–∞
            'price_change_5m': price_change_5,
            'price_change_10m': price_change_10,
            'volume_ratio': volume_ratio,
            'is_strong_impulse': is_strong_impulse,
            'impulse_direction': 'BULLISH' if price_change_5 > 0 else 'BEARISH'
        }
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ enhanced_trend_analysis: {e}")
        return {
            'direction': 'NEUTRAL',
            'strength': 'WEAK',
            'rsi_state': 'NEUTRAL',
            'is_strong_impulse': False
        }

def liquidity_analysis(df):
    """–ê–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω–µ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏"""
    try:
        recent_high = df['high'].tail(50).max()
        recent_low = df['low'].tail(50).min()
        current_price = df['close'].iloc[-1]
        atr = ta.ATR(df['high'], df['low'], df['close'], 14).iloc[-1]
        
        # –£—Ä–æ–≤–Ω–∏ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ (—Å—Ç–æ–ø-–ª–æ—Å—Å—ã)
        buy_liquidity_below = recent_low - atr * 0.5
        sell_liquidity_above = recent_high + atr * 0.5
        
        # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
        distance_to_buy_liquidity = current_price - buy_liquidity_below
        distance_to_sell_liquidity = sell_liquidity_above - current_price
        
        return {
            'buy_liquidity': buy_liquidity_below,
            'sell_liquidity': sell_liquidity_above,
            'distance_to_buy_liquidity_pips': distance_to_buy_liquidity * 10000,
            'distance_to_sell_liquidity_pips': distance_to_sell_liquidity * 10000,
            'near_buy_liquidity': distance_to_buy_liquidity < atr,
            'near_sell_liquidity': distance_to_sell_liquidity < atr
        }
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ liquidity_analysis: {e}")
        return {}

def price_action_patterns(df):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Price Action –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    patterns = []
    
    try:
        if len(df) < 3:
            return patterns
            
        current = df.iloc[-1]
        prev = df.iloc[-2]
        prev2 = df.iloc[-3]
        
        current_body = abs(current['close'] - current['open'])
        current_range = current['high'] - current['low']
        prev_body = abs(prev['close'] - prev['open'])
        
        # Pin Bar
        if current_body < current_range * 0.3:
            upper_wick = current['high'] - max(current['open'], current['close'])
            lower_wick = min(current['open'], current['close']) - current['low']
            
            if upper_wick > current_body * 2 and lower_wick < current_body:
                patterns.append({'type': 'BEARISH_PIN', 'strength': 'MEDIUM'})
            elif lower_wick > current_body * 2 and upper_wick < current_body:
                patterns.append({'type': 'BULLISH_PIN', 'strength': 'MEDIUM'})
        
        # Engulfing
        if (current['close'] > current['open'] and prev['close'] < prev['open'] and
            current['open'] < prev['close'] and current['close'] > prev['open']):
            patterns.append({'type': 'BULLISH_ENGULFING', 'strength': 'STRONG'})
        elif (current['close'] < current['open'] and prev['close'] > prev['open'] and
              current['open'] > prev['close'] and current['close'] < prev['open']):
            patterns.append({'type': 'BEARISH_ENGULFING', 'strength': 'STRONG'})
        
        # Inside Bar
        if (current['high'] < prev['high'] and current['low'] > prev['low']):
            patterns.append({'type': 'INSIDE_BAR', 'strength': 'WEAK'})
            
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ price_action_patterns: {e}")
    
    return patterns

def calculate_dynamic_expiry(df, confidence, signal_type=None):
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á—ë—Ç —ç–∫—Å–ø–∏—Ä–∞—Ü–∏–∏ –¥–ª—è –±–∏–Ω–∞—Ä–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (1‚Äì4 –º–∏–Ω)
    ‚ö° –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1 –º–∏–Ω—É—Ç—ã –Ω–∞ –∏–º–ø—É–ª—å—Å–∞—Ö –∏ —Å–∏–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–∞—Ö
    """
    try:
        atr = ta.ATR(df['high'], df['low'], df['close'], timeperiod=14).iloc[-1]
        current_price = df['close'].iloc[-1]
        volatility_percent = (atr / current_price) * 100 if current_price > 0 else 0

        # üìä 1. –ë–∞–∑–æ–≤–∞—è —ç–∫—Å–ø–∏—Ä–∞—Ü–∏—è –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        if volatility_percent >= 0.035:         # –∏–º–ø—É–ª—å—Å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ ‚Äî —á–∞—Å—Ç–æ –Ω—É–∂–µ–Ω –∫–æ—Ä–æ—Ç–∫–∏–π –≤—Ö–æ–¥
            base_expiry = 1
        elif volatility_percent >= 0.02:       # –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            base_expiry = 2
        elif volatility_percent >= 0.01:       # —Å–ø–æ–∫–æ–π–Ω—ã–π —Ä—ã–Ω–æ–∫
            base_expiry = 3
        else:                                  # —Ñ–ª–µ—Ç, —Å–ª–∞–±–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
            base_expiry = 4

        # üìå 2. –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø—É —Å–∏–≥–Ω–∞–ª–∞
        if signal_type == "BREAKOUT":
            # –ù–∞ –ø—Ä–æ–±–æ—è—Ö —á–∞—â–µ –ª—É—á—à–µ –±—ã—Å—Ç—Ä–∞—è —ç–∫—Å–ø–∏—Ä–∞—Ü–∏—è
            base_expiry = max(1, base_expiry - 1)
        elif signal_type == "REVERSAL":
            # –†–∞–∑–≤–æ—Ä–æ—Ç—ã —á–∞—Å—Ç–æ —Ç—Ä–µ–±—É—é—Ç —á—É—Ç—å –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏
            base_expiry = min(base_expiry + 1, 4)

        # üìå 3. –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Å–∏–≥–Ω–∞–ª–∞
        if confidence >= 9:
            # –û—á–µ–Ω—å —Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª ‚Äî —á–∞—Å—Ç–æ –ª—É—á—à–µ –∫–æ—Ä–æ—Ç–∫–∞—è —ç–∫—Å–ø–∏—Ä–∞—Ü–∏—è (1 –º–∏–Ω—É—Ç–∞)
            final_expiry = 1
        elif confidence >= 6:
            # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ‚Äî —ç–∫—Å–ø–∏—Ä–∞—Ü–∏—è –Ω–µ –±–æ–ª–µ–µ 2 –º–∏–Ω—É—Ç
            final_expiry = min(base_expiry, 2)
        else:
            # –°–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            final_expiry = base_expiry

        # üß† 4. –ì—Ä–∞–Ω–∏—Ü—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        final_expiry = max(1, min(final_expiry, 4))

        logging.info(
            f"üìä –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: {volatility_percent:.4f}% | —Ç–∏–ø={signal_type} | conf={confidence} ‚Üí —ç–∫—Å–ø–∏—Ä–∞—Ü–∏—è: {final_expiry} –º–∏–Ω"
        )
        return final_expiry

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π —ç–∫—Å–ø–∏—Ä–∞—Ü–∏–∏: {e}")
        return 2

def get_candle_time_info():
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –∑–∞–∫—Ä—ã—Ç–∏—è —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏"""
    now = datetime.now()
    seconds_passed = now.second
    seconds_remaining = 60 - seconds_passed
    
    completion_percent = (seconds_passed / 60) * 100
    
    return {
        'seconds_remaining': seconds_remaining,
        'seconds_passed': seconds_passed, 
        'completion_percent': completion_percent,
        'is_beginning': completion_percent < 25,
        'is_middle': 25 <= completion_percent <= 75,
        'is_ending': completion_percent > 75
    }

def early_entry_strategy(df, candle_time, trend_analysis):
    """–°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—Ö–æ–¥–∞ –≤ –Ω–∞—á–∞–ª–µ —Å–≤–µ—á–∏ –ø—Ä–∏ —Å–∏–ª—å–Ω–æ–º –∏–º–ø—É–ª—å—Å–µ"""
    if candle_time['seconds_passed'] < 10:
        if len(df) < 2:
            return None, 0, None
            
        prev_candle = df.iloc[-2]
        current_candle = df.iloc[-1]
        
        if current_candle['open'] > prev_candle['close'] * 1.0005:
            return "BUY", 2, "EARLY_GAP_UP"
        elif current_candle['open'] < prev_candle['close'] * 0.9995:
            return "SELL", 2, "EARLY_GAP_DOWN"
    
    return None, 0, None

def calculate_average_candle_size(df, period=20):
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Å–≤–µ—á–∏"""
    if len(df) < period:
        return 0
    candle_sizes = df['high'].tail(period) - df['low'].tail(period)
    return candle_sizes.mean()

def closing_candle_strategy(df, candle_time, trend_analysis):
    """–°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—Ö–æ–¥–∞ –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã—Ç–∏–µ–º —Å–≤–µ—á–∏"""
    if candle_time['seconds_remaining'] < 15:
        current_candle = df.iloc[-1]
        avg_candle_size = calculate_average_candle_size(df)
        
        if avg_candle_size > 0 and (current_candle['high'] - current_candle['low']) < avg_candle_size * 0.5:
            if trend_analysis['direction'] == 'BULLISH':
                return "BUY", 1, "BREAKOUT_ENDING"
            elif trend_analysis['direction'] == 'BEARISH':
                return "SELL", 1, "BREAKOUT_ENDING"
    
    return None, 0, None

def check_level_breakouts(df, current_price, zones):
    try:
        breakouts = []
        lookback = 8
        
        for zone in zones:
            zone_middle = (zone['top'] + zone['bottom']) / 2
            
            if zone['type'] == 'DEMAND':
                recent_closes = df['close'].tail(lookback)
                recent_lows = df['low'].tail(lookback)
                
                if any(close < zone['bottom'] for close in recent_closes) or \
                   any(low < zone['bottom'] for low in recent_lows):
                    breakouts.append({
                        'type': 'BEARISH_BREAKOUT',
                        'zone': zone,
                        'strength': 'STRONG' if zone['source'] == 'HORIZONTAL' else 'MEDIUM'
                    })
            
            elif zone['type'] == 'SUPPLY':
                recent_closes = df['close'].tail(lookback)
                recent_highs = df['high'].tail(lookback)
                
                if any(close > zone['top'] for close in recent_closes) or \
                   any(high > zone['top'] for high in recent_highs):
                    breakouts.append({
                        'type': 'BULLISH_BREAKOUT', 
                        'zone': zone,
                        'strength': 'STRONG' if zone['source'] == 'HORIZONTAL' else 'MEDIUM'
                    })
        
        return breakouts
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–±–æ–µ–≤: {e}")
        return []
# ===================== EXHAUSTION FILTER =====================
def is_exhausted_move(df, trend_analysis):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å—Ç–æ—â–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ª–æ–∂–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤"""
    try:
        if len(df) < 20:
            return False
            
        current_price = df['close'].iloc[-1]
        rsi = trend_analysis.get('rsi_value', 50)
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ RSI –≤ —ç–∫—Å—Ç—Ä–µ–º—É–º–∞—Ö
        if rsi < 25 or rsi > 75:
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑–∫–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
            price_change_5m = (current_price - df['close'].iloc[-5]) / df['close'].iloc[-5] * 100
            price_change_15m = (current_price - df['close'].iloc[-15]) / df['close'].iloc[-15] * 100
            
            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä–µ–º–∞
            current_volume = df['tick_volume'].iloc[-1]
            avg_volume = df['tick_volume'].tail(20).mean()
            volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∏—Å—Ç–æ—â–µ–Ω–∏—è:
            # - –†–µ–∑–∫–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ (>0.3% –∑–∞ 5 –º–∏–Ω—É—Ç)
            # - RSI –≤ —ç–∫—Å—Ç—Ä–µ–º—É–º–µ
            # - –û–±—ä–µ–º —Å–Ω–∏–∂–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –ø–∏–∫–∞
            if abs(price_change_5m) > 0.3 and volume_ratio < 0.8:
                logging.info(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏—Å—Ç–æ—â–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è: RSI={rsi:.1f}, Œî5m={price_change_5m:.2f}%, Œî15m={price_change_15m:.2f}%")
                return True
                
        return False
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ is_exhausted_move: {e}")
        return False

def enhanced_smart_money_analysis(df):
    if df is None or len(df) < 100:
        return None, None, 0, "NO_DATA"
    
    try:
        logging.info(f"üîß SMC –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—É—â–µ–Ω –¥–ª—è {len(df)} —Å–≤–µ—á–µ–π")
        
        # =============== –ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ï –ë–õ–û–ö–ò ===============
        zones = find_supply_demand_zones(df)
        structure = find_market_structure(df)
        order_blocks = calculate_order_blocks_advanced(df)
        fibonacci = calculate_fibonacci_levels(df)
        trend_analysis = enhanced_trend_analysis(df)
        liquidity_levels = liquidity_analysis(df)
        pa_patterns = price_action_patterns(df)
        candle_time = get_candle_time_info()
        
        # =============== –ù–û–í–´–ô –§–ò–õ–¨–¢–† –ò–°–¢–û–©–ï–ù–ò–Ø ===============
        if is_exhausted_move(df, trend_analysis):
            logging.warning("‚è∏Ô∏è –î–≤–∏–∂–µ–Ω–∏–µ –∏—Å—Ç–æ—â–µ–Ω–æ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∏–≥–Ω–∞–ª—ã –ø—Ä–æ—Ç–∏–≤ –∏–º–ø—É–ª—å—Å–∞")
            # –í —Å–ª—É—á–∞–µ –∏—Å—Ç–æ—â–µ–Ω–∏—è –º–æ–∂–Ω–æ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Ç—Å–∫–æ–∫
            if trend_analysis['rsi_state'] == 'OVERSOLD':
                return "BUY", 2, 4, "EXHAUSTION_BOUNCE"
            elif trend_analysis['rsi_state'] == 'OVERBOUGHT':
                return "SELL", 2, 4, "EXHAUSTION_BOUNCE"
            return None, None, 0, "EXHAUSTED_MOVE"

        # =============== –û–°–ù–û–í–ù–û–ô –ê–ù–ê–õ–ò–ó ===============
        breakouts = check_level_breakouts(df, df['close'].iloc[-1], zones)
        logging.info(f"üìä SMC –Ω–∞–π–¥–µ–Ω–æ: –∑–æ–Ω={len(zones)}, –ø—Ä–æ–±–æ–µ–≤={len(breakouts)}")

        current_price = df['close'].iloc[-1]
        signal, confidence, signal_type = None, 0, None
        
        buy_signals = 0
        sell_signals = 0
        buy_confidence = 0
        sell_confidence = 0

        bearish_breakouts = [b for b in breakouts if b['type'] == 'BEARISH_BREAKOUT']
        bullish_breakouts = [b for b in breakouts if b['type'] == 'BULLISH_BREAKOUT']
        
        if bearish_breakouts:
            logging.info(f"üìâ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –º–µ–¥–≤–µ–∂—å–∏ –ø—Ä–æ–±–æ–∏: {len(bearish_breakouts)}")
            sell_confidence += len(bearish_breakouts) * 3
            
        if bullish_breakouts:
            logging.info(f"üìà –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –±—ã—á—å–∏ –ø—Ä–æ–±–æ–∏: {len(bullish_breakouts)}")
            buy_confidence += len(bullish_breakouts) * 3

        # üü° –†–∞–Ω–Ω–∏–π –≤—Ö–æ–¥
        early_signal, early_conf, early_source = early_entry_strategy(df, candle_time, trend_analysis)
        if early_signal:
            return early_signal, 1, early_conf + 2, f"EARLY_{early_source}"

        # üü† –í—Ö–æ–¥ –≤ –∫–æ–Ω—Ü–µ —Å–≤–µ—á–∏
        closing_signal, closing_conf, closing_source = closing_candle_strategy(df, candle_time, trend_analysis)
        if closing_signal:
            return closing_signal, 1, closing_conf + 2, f"CLOSING_{closing_source}"

        # =============== –ê–ù–ê–õ–ò–ó –ó–û–ù ===============
        for zone in zones:
            if zone['strength'] in ['STRONG', 'MEDIUM']:
                zone_middle = (zone['top'] + zone['bottom']) / 2
                distance_to_zone = min(abs(current_price - zone['top']), abs(current_price - zone['bottom']))
                
                if distance_to_zone <= (zone['top'] - zone['bottom']) * 2:
                    
                    if (zone['type'] == 'DEMAND' and 
                        current_price >= zone['bottom'] and 
                        not any(b['type'] == 'BEARISH_BREAKOUT' and b['zone'] == zone for b in breakouts)):
                        
                        base_confidence = 3
                        if zone['source'] == 'HORIZONTAL':
                            base_confidence += 1
                        if trend_analysis['direction'] == 'BULLISH':
                            base_confidence += 1
                        
                        bull_patterns = [p for p in pa_patterns if 'BULLISH' in p['type']]
                        if bull_patterns:
                            base_confidence += 1
                        
                        buy_signals += 1
                        buy_confidence += base_confidence
                        logging.info(f"‚úÖ SMC –∑–æ–Ω–∞ —Å–ø—Ä–æ—Å–∞: BUY +{base_confidence}")
                        
                    elif (zone['type'] == 'SUPPLY' and 
                          current_price <= zone['top'] and
                          not any(b['type'] == 'BULLISH_BREAKOUT' and b['zone'] == zone for b in breakouts)):
                        
                        base_confidence = 3
                        if zone['source'] == 'HORIZONTAL':
                            base_confidence += 1
                        if trend_analysis['direction'] == 'BEARISH':
                            base_confidence += 1
                        
                        bear_patterns = [p for p in pa_patterns if 'BEARISH' in p['type']]
                        if bear_patterns:
                            base_confidence += 1
                        
                        sell_signals += 1
                        sell_confidence += base_confidence
                        logging.info(f"‚úÖ SMC –∑–æ–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: SELL +{base_confidence}")

        # =============== –û–†–î–ï–†-–ë–õ–û–ö–ò ===============
        for ob in order_blocks:
            ob_middle = (ob['high'] + ob['low']) / 2
            if (ob['type'] == 'BULLISH_OB' and 
                current_price <= ob_middle and
                ob['low'] <= current_price <= ob['high']):
                
                conf_boost = 2
                if liquidity_levels.get('near_sell_liquidity'):
                    conf_boost += 1
                
                buy_signals += 1
                buy_confidence += conf_boost
                logging.info(f"‚úÖ SMC –±—ã—á–∏–π OB: BUY +{conf_boost}")
                
            elif (ob['type'] == 'BEARISH_OB' and 
                  current_price >= ob_middle and
                  ob['low'] <= current_price <= ob['high']):
                
                conf_boost = 2
                if liquidity_levels.get('near_buy_liquidity'):
                    conf_boost += 1
                
                sell_signals += 1
                sell_confidence += conf_boost
                logging.info(f"‚úÖ SMC –º–µ–¥–≤–µ–∂–∏–π OB: SELL +{conf_boost}")

        # =============== –†–ê–ó–†–ï–®–ï–ù–ò–ï –ö–û–ù–§–õ–ò–ö–¢–û–í ===============
        if buy_signals > 0 and sell_signals > 0:
            logging.info(f"‚öñÔ∏è –ö–æ–Ω—Ñ–ª–∏–∫—Ç —Å–∏–≥–Ω–∞–ª–æ–≤: BUY={buy_signals}(conf:{buy_confidence}) vs SELL={sell_signals}(conf:{sell_confidence})")
            
            if buy_confidence > sell_confidence:
                signal, confidence = 'BUY', buy_confidence
                logging.info(f"‚úÖ –†–∞–∑—Ä–µ—à–µ–Ω –∫–æ–Ω—Ñ–ª–∏–∫—Ç –≤ –ø–æ–ª—å–∑—É BUY")
            elif sell_confidence > buy_confidence:
                signal, confidence = 'SELL', sell_confidence
                logging.info(f"‚úÖ –†–∞–∑—Ä–µ—à–µ–Ω –∫–æ–Ω—Ñ–ª–∏–∫—Ç –≤ –ø–æ–ª—å–∑—É SELL")
            else:
                logging.info(f"‚ùå –ö–æ–Ω—Ñ–ª–∏–∫—Ç –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω ‚Äî —Ä–∞–≤–Ω—ã–µ confidence")
                return None, None, 0, "CONFLICT_SIGNAL"
        elif buy_signals > 0:
            signal, confidence = 'BUY', buy_confidence
        elif sell_signals > 0:
            signal, confidence = 'SELL', sell_confidence

        # =============== –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ë–û–ù–£–°–´ ===============
        for fib in fibonacci:
            if abs(current_price - fib["level"]) / current_price < 0.0015:
                if fib["ratio"] in [38, 50, 61]:
                    confidence += 1
                    logging.info(f"‚úÖ SMC —Ñ–∏–±–æ —É—Ä–æ–≤–µ–Ω—å: +1")

        if len(structure) >= 2 and signal:
            last_structure = structure[-1]['type']
            if last_structure == 'HH' and signal == 'BUY':
                confidence += 2
                logging.info(f"‚úÖ SMC —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ HH: +2")
            elif last_structure == 'LL' and signal == 'SELL':
                confidence += 2
                logging.info(f"‚úÖ SMC —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ LL: +2")

        for pattern in pa_patterns:
            if pattern['type'] == 'BULLISH_ENGULFING' and signal == 'BUY':
                confidence += 2
                logging.info(f"‚úÖ SMC –±—ã—á–∏–π engulfing: +2")
            elif pattern['type'] == 'BEARISH_ENGULFING' and signal == 'SELL':
                confidence += 2
                logging.info(f"‚úÖ SMC –º–µ–¥–≤–µ–∂–∏–π engulfing: +2")
            elif 'PIN' in pattern['type'] and signal:
                confidence += 1
                logging.info(f"‚úÖ SMC pin bar: +1")

        # =============== –í–†–ï–ú–ï–ù–ù–û–ô –ë–û–ù–£–° ===============
        if signal:
            if candle_time['is_beginning']:
                confidence -= 1
                logging.info(f"‚ö†Ô∏è –ù–∞—á–∞–ª–æ —Å–≤–µ—á–∏ ‚Äî –ø–æ–Ω–∏–∂–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: -1")
            elif candle_time['is_ending']:
                confidence += 1
                logging.info(f"‚úÖ –ö–æ–Ω–µ—Ü —Å–≤–µ—á–∏ ‚Äî —É—Å–∏–ª–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: +1")

        confidence = max(0, min(confidence, 10))

        if confidence >= 2:
            logging.info(f"üéØ SMC –°–ò–ì–ù–ê–õ: {signal} (conf:{confidence})")
            expiry = calculate_dynamic_expiry(df, confidence, signal_type)
            return signal, expiry, confidence, "ENHANCED_SMART_MONEY"

        logging.info(f"‚ùå SMC –Ω–µ –Ω–∞—à–µ–ª —Å–∏–≥–Ω–∞–ª–æ–≤ (conf:{confidence})")
        return None, None, 0, "NO_SMC_SIGNAL"
    
    except Exception as e:
        logging.error(f"üí• –û—à–∏–±–∫–∞ SMC –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return None, None, 0, "SMC_ERROR"
    
# ===================== ML (SAFE + DYNAMIC FEATURES) =====================
import os
import json
import pickle
import numpy as np
import pandas as pd
import joblib
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional

import talib as ta
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# ---- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –±–æ—Ç–∞ ----
ml_model = None
ml_scaler = None
model_info: Dict = {}

# –ü–æ—Ä–æ–≥ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ proba ‚Üí —Å–∏–≥–Ω–∞–ª (–∫–∞–∫ –±—ã–ª–æ —É —Ç–µ–±—è)
ML_PROBABILITY_THRESHOLD = float(os.getenv("ML_PROBA_THR", "0.55"))

# –ü—É—Ç–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
ML_MODEL_PATH = "ml_model.pkl"
ML_SCALER_PATH = "ml_scaler.pkl"
ML_INFO_PATH = "ml_info.json"       # –∏—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏–π (—Å–ø–∏—Å–æ–∫)
ML_INFO_LAST = "ml_info_last.json"  # –ø–æ—Å–ª–µ–¥–Ω—è—è –∑–∞–ø–∏—Å—å
ML_FEATS_PKL = "ml_features_selected.pkl"

# –ú–∏–Ω–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö
MIN_SAMPLES_TO_TRAIN = 100

# –ï—Å–ª–∏ —Ö–æ—á–µ—à—å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å top-K ‚Äî –ø–æ—Å—Ç–∞–≤—å —á–∏—Å–ª–æ; –µ—Å–ª–∏ 0 ‚Üí –≤–æ–∑—å–º–µ–º –¥–ª–∏–Ω—É –∏–∑ pkl/–∏—Å—Ç–æ—Ä–∏–∏
TOP_K_FEATURES = 0  # 0 = –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—É—â–µ–≥–æ —Å–ø–∏—Å–∫–∞ —Ñ–∏—á –∏–∑ pkl/–∏—Å—Ç–æ—Ä–∏–∏

# ===================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–û–ï =====================

def _safe_json_load(path: str):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None

def _append_ml_info(entry: Dict):
    """–ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏–π –∫–∞–∫ —Å–ø–∏—Å–æ–∫."""
    try:
        data = _safe_json_load(ML_INFO_PATH)
        if isinstance(data, list):
            data.append(entry)
        elif isinstance(data, dict):
            data = [data, entry]
        else:
            data = [entry]
        with open(ML_INFO_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å {ML_INFO_PATH}: {e}")

def _load_selected_features_fallback() -> List[str]:
    """–§–æ–ª–ª–±—ç–∫: —á–∏—Ç–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ pkl (–µ—Å–ª–∏ –µ—Å—Ç—å)."""
    try:
        if os.path.exists(ML_FEATS_PKL):
            with open(ML_FEATS_PKL, "rb") as f:
                obj = pickle.load(f)
            if isinstance(obj, dict):
                return list(obj.keys())
            return list(obj)
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {ML_FEATS_PKL}: {e}")
    return []

def _get_expected_feature_list() -> List[str]:
    """
    –ì–ª–∞–≤–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã: ml_info_last.json["feature_names"].
    –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî —Ñ–æ–ª–ª–±—ç–∫ –∫ ml_features_selected.pkl.
    """
    info = _safe_json_load(ML_INFO_LAST)
    if isinstance(info, dict) and isinstance(info.get("feature_names"), list):
        return info["feature_names"]
    return _load_selected_features_fallback()

def _vectorize_for_inference(ml_features: Dict[str, float], expected_features: List[str]) -> np.ndarray:
    """–°–æ–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫—É —Ñ–∏—á –≤ —Ç–æ—á–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ expected_features; –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ ‚Üí 0.0."""
    row = [float(ml_features.get(f, 0.0)) for f in expected_features]
    return np.asarray([row], dtype=float)

def load_ml_artifacts() -> bool:
    """–ì—Ä—É–∑–∏–º –º–æ–¥–µ–ª—å, —Å–∫–µ–π–ª–µ—Ä –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å model_info."""
    global ml_model, ml_scaler, model_info
    try:
        if os.path.exists(ML_MODEL_PATH) and os.path.exists(ML_SCALER_PATH):
            ml_model = joblib.load(ML_MODEL_PATH)
            ml_scaler = joblib.load(ML_SCALER_PATH)
        else:
            logging.warning("‚ö†Ô∏è ML –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å.")
            return False

        info = _safe_json_load(ML_INFO_LAST)
        if info is None:
            data = _safe_json_load(ML_INFO_PATH)
            if isinstance(data, list) and data:
                info = data[-1]
            elif isinstance(data, dict):
                info = data
        model_info = info or {}
        if not isinstance(model_info.get("feature_names", None), list):
            # –≤—Å—ë —Ä–∞–≤–Ω–æ –¥–∞–¥–∏–º —à–∞–Ω—Å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å—É —á–µ—Ä–µ–∑ pkl-—Å–ø–∏—Å–æ–∫
            model_info["feature_names"] = _load_selected_features_fallback()

        logging.info("‚úÖ ML –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        return True
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ML –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤: {e}", exc_info=True)
        return False

# ===================== –ü–û–î–ì–û–¢–û–í–ö–ê –§–ò–ß–ï–ô (—Ç–≤–æ—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è) =====================
def prepare_ml_features(df):
    """–ì–æ—Ç–æ–≤–∏—Ç –ø–æ–ª–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∏–∑ 50+ ML-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Å–¥–µ–ª–∫–∏ –∏ –æ–±—É—á–µ–Ω–∏—è (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ)."""
    try:
        if df is None or len(df) < 100:
            return None

        close, high, low, volume = df['close'], df['high'], df['low'], df['tick_volume']
        features = {}

        # –ë–∞–∑–æ–≤—ã–µ
        features['price'] = float(close.iloc[-1])
        features['volume'] = float(volume.iloc[-1]) if not volume.isna().all() else 0.0

        # RSI
        for period in [14, 21]:
            rsi = ta.RSI(close, timeperiod=period)
            features[f'rsi_{period}'] = float(rsi.iloc[-1]) if len(close) >= period and not rsi.isna().all() else 50.0

        # ATR + ratio
        atr = ta.ATR(high, low, close, timeperiod=14)
        if len(close) >= 14 and not atr.isna().all():
            features['atr'] = float(atr.iloc[-1])
            atr_50 = atr.rolling(50).mean()
            features['atr_ratio'] = float(atr.iloc[-1] / atr_50.iloc[-1]) if len(atr_50) > 0 and not pd.isna(atr_50.iloc[-1]) else 1.0
        else:
            features['atr'] = 0.0
            features['atr_ratio'] = 1.0

        # OBV + —Ç—Ä–µ–Ω–¥
        try:
            obv = ta.OBV(close, volume)
            features['obv'] = float(obv.iloc[-1]) if not obv.isna().all() else 0.0
            features['obv_trend'] = float(obv.diff(5).iloc[-1]) if len(obv) > 5 and not pd.isna(obv.diff(5).iloc[-1]) else 0.0
        except Exception:
            features['obv'] = 0.0
            features['obv_trend'] = 0.0

        features['adx'] = float(ta.ADX(high, low, close, timeperiod=14).iloc[-1]) if len(close) >= 14 else 0.0

        # –ò–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã
        for period in [15, 30, 60]:
            if len(close) >= period:
                features[f'price_change_{period}m'] = float((close.iloc[-1] - close.iloc[-period]) / close.iloc[-period] * 100)
            else:
                features[f'price_change_{period}m'] = 0.0

        features['volatility'] = float(close.pct_change().std() * 100)

        # MACD
        try:
            macd, _, _ = ta.MACD(close, 12, 26, 9)
            features['macd'] = float(macd.iloc[-1]) if not macd.isna().all() else 0.0
        except Exception:
            features['macd'] = 0.0

        # Bollinger
        try:
            bb_u, _, bb_l = ta.BBANDS(close, timeperiod=20)
            if not bb_u.isna().all() and not bb_l.isna().all():
                bb_range = bb_u.iloc[-1] - bb_l.iloc[-1]
                features['bb_position'] = float((close.iloc[-1] - bb_l.iloc[-1]) / max(1e-9, bb_range))
            else:
                features['bb_position'] = 0.5
        except Exception:
            features['bb_position'] = 0.5

        # –°–≤–µ—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—É–ø—Ä–æ—â—ë–Ω–Ω–æ)
        try:
            co, ch, cl, cc = df['open'].iloc[-1], df['high'].iloc[-1], df['low'].iloc[-1], df['close'].iloc[-1]
            po, ph, pl, pc = df['open'].iloc[-2], df['high'].iloc[-2], df['low'].iloc[-2], df['close'].iloc[-2]
            features['bullish_engulfing'] = int(pc < po and cc > co and co < pc and cc > po)
            features['bearish_engulfing'] = int(pc > po and cc < co and co > pc and cc < po)
            if len(df) >= 4:
                soldiers = all([
                    df['close'].iloc[-3] > df['open'].iloc[-3],
                    df['close'].iloc[-2] > df['open'].iloc[-2],
                    df['close'].iloc[-1] > df['open'].iloc[-1],
                    df['close'].iloc[-1] > df['close'].iloc[-2],
                    df['close'].iloc[-2] > df['close'].iloc[-3]
                ])
                features['three_white_soldiers'] = int(soldiers)
            else:
                features['three_white_soldiers'] = 0
        except Exception:
            features['bullish_engulfing'] = 0
            features['bearish_engulfing'] = 0
            features['three_white_soldiers'] = 0

        # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ –¥–Ω–µ–≤–Ω—ã—Ö —ç–∫—Å—Ç—Ä–µ–º—É–º–æ–≤
        try:
            daily_high = high.tail(1440).max()
            daily_low = low.tail(1440).min()
            features['distance_to_daily_high'] = float((daily_high - close.iloc[-1]) / daily_high * 100) if daily_high > 0 else 50.0
            features['distance_to_daily_low'] = float((close.iloc[-1] - daily_low) / close.iloc[-1] * 100) if close.iloc[-1] > 0 else 50.0
            rng = daily_high - daily_low
            features['daily_range_position'] = float((close.iloc[-1] - daily_low) / rng) if rng > 0 else 0.5
        except Exception:
            features['distance_to_daily_high'] = 50.0
            features['distance_to_daily_low'] = 50.0
            features['daily_range_position'] = 0.5

        # --- SMC / —É—Ä–æ–≤–Ω–∏ (—Ç—Ä–µ–±—É—é—Ç —Ç–≤–æ–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π; –æ—Å—Ç–∞–≤–ª—è–µ–º try/except, –∫–∞–∫ —É —Ç–µ–±—è)
        try:
            zones = find_supply_demand_zones(df)
            structure = find_market_structure(df)
            order_blocks = calculate_order_blocks_advanced(df)
            fibonacci = calculate_fibonacci_levels(df)
            pa_patterns = price_action_patterns(df)

            features['smc_zones_count'] = len(zones)
            features['smc_structure_count'] = len(structure)
            features['smc_ob_count'] = len(order_blocks)
            features['smc_fib_count'] = len(fibonacci)
            features['smc_patterns_count'] = len(pa_patterns)

            features['smc_has_demand_zone'] = int(any(z['type'] == 'DEMAND' for z in zones))
            features['smc_has_supply_zone'] = int(any(z['type'] == 'SUPPLY' for z in zones))
            features['smc_has_bullish_ob'] = int(any(ob['type'] == 'BULLISH_OB' for ob in order_blocks))
            features['smc_has_bearish_ob'] = int(any(ob['type'] == 'BEARISH_OB' for ob in order_blocks))
            features['smc_has_engulfing'] = int(any('ENGULFING' in p['type'] for p in pa_patterns))
            features['smc_has_pinbar'] = int(any('PIN' in p['type'] for p in pa_patterns))

            current_price = close.iloc[-1]
            round_info = detect_round_levels(current_price)
            features['smc_round_distance_pips'] = float(round_info['distance_pips'])
            features['smc_round_strength'] = {'WEAK': 0, 'MEDIUM': 1, 'STRONG': 2, 'VERY_STRONG': 3}.get(round_info['strength'], 0)
        except Exception:
            for key in [
                'smc_zones_count','smc_structure_count','smc_ob_count','smc_fib_count','smc_patterns_count',
                'smc_has_demand_zone','smc_has_supply_zone','smc_has_bullish_ob','smc_has_bearish_ob',
                'smc_has_engulfing','smc_has_pinbar','smc_round_distance_pips','smc_round_strength'
            ]:
                features[key] = 0

        # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ —É—Ä–æ–≤–Ω–∏
        try:
            horizontal_levels = find_horizontal_levels(df)
            features['horizontal_levels_count'] = len(horizontal_levels)
            if horizontal_levels:
                closest_level = min(horizontal_levels, key=lambda x: abs(x['price'] - close.iloc[-1]))
                features['distance_to_horizontal_level'] = abs(closest_level['price'] - close.iloc[-1]) * 10000
                features['horizontal_level_strength'] = closest_level['touches']
                features['is_near_horizontal_level'] = int(features['distance_to_horizontal_level'] < 5)
            else:
                features['distance_to_horizontal_level'] = 100
                features['horizontal_level_strength'] = 0
                features['is_near_horizontal_level'] = 0
        except Exception:
            features['horizontal_levels_count'] = 0
            features['distance_to_horizontal_level'] = 100
            features['horizontal_level_strength'] = 0
            features['is_near_horizontal_level'] = 0

        # –í—Ä–µ–º—è/—Å–≤–µ—á–∏
        try:
            candle_time = get_candle_time_info()
            features['candle_seconds_remaining'] = candle_time['seconds_remaining']
            features['candle_seconds_passed'] = candle_time['seconds_passed']
            features['candle_completion_percent'] = candle_time['completion_percent']
            features['candle_is_beginning'] = int(candle_time['is_beginning'])
            features['candle_is_middle'] = int(candle_time['is_middle'])
            features['candle_is_ending'] = int(candle_time['is_ending'])

            current_candle = df.iloc[-1]
            features['candle_body_size'] = abs(current_candle['close'] - current_candle['open'])
            features['candle_range'] = current_candle['high'] - current_candle['low']
            features['candle_body_ratio'] = features['candle_body_size'] / max(1e-9, features['candle_range'])

            features['early_gap_signal'] = int(early_entry_strategy(df, candle_time, {'direction': 'NEUTRAL'})[0])
            features['closing_breakout_signal'] = int(closing_candle_strategy(df, candle_time, {'direction': 'NEUTRAL'})[0])
        except Exception:
            for key in [
                'candle_seconds_remaining','candle_seconds_passed','candle_completion_percent',
                'candle_is_beginning','candle_is_middle','candle_is_ending',
                'candle_body_size','candle_range','candle_body_ratio',
                'early_gap_signal','closing_breakout_signal'
            ]:
                features[key] = 0

        # –ö–æ–Ω—Ç–µ–∫—Å—Ç
        features['exhaustion_rsi_extreme'] = int((features.get('rsi_14', 50) < 25) or (features.get('rsi_14', 50) > 75))

        # –ò–º–ø—É–ª—å—Å
        pc_key = 'price_change_15m' if 'price_change_15m' in features else 'price_change_60m'
        pc = features.get(pc_key, 0.0)
        if pc == 0 and len(df) >= 15:
            pc = float((close.iloc[-1] - close.iloc[-15]) / close.iloc[-15] * 100)
        features['strong_impulse'] = int(abs(pc) > 0.3)

        volume_avg_20 = df['tick_volume'].tail(20).mean() if 'tick_volume' in df.columns else 1
        current_volume = df['tick_volume'].iloc[-1] if 'tick_volume' in df.columns else 1
        features['volume_declining'] = int(current_volume < (volume_avg_20 * 0.8))

        features['signal_vs_trend_conflict'] = 0
        features['signal_vs_rsi_conflict'] = 0

        # –ß–∏—Å—Ç–∏–º NaN
        for k, v in list(features.items()):
            if pd.isna(v):
                features[k] = 0.0

        return features
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ ML features: {e}", exc_info=True)
        return None

# ===================== –ò–ù–§–ï–†–ï–ù–° (–ë–ï–ó–û–ü–ê–°–ù–´–ô) =====================
def ml_predict_proba_safe(ml_features: Dict[str, float]) -> Optional[float]:
    """–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å WIN (0..1). –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–∞–¥–∞–µ—Ç –∏–∑-–∑–∞ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
    try:
        global ml_model, ml_scaler, model_info
        if ml_model is None or ml_scaler is None:
            if not load_ml_artifacts():
                return None

        expected = model_info.get("feature_names", []) or _get_expected_feature_list()
        if not expected:
            logging.warning("‚ö†Ô∏è feature_names –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç ‚Äî –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –ø—Ä–æ–ø—É—â–µ–Ω")
            return None

        X_raw = _vectorize_for_inference(ml_features or {}, expected)
        X = ml_scaler.transform(X_raw)
        if hasattr(ml_model, "predict_proba"):
            return float(ml_model.predict_proba(X)[0, 1])
        return float(ml_model.predict(X)[0])
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ ML –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {e}", exc_info=True)
        return None

def ml_predict_enhanced(features_dict: dict, pair: str, current_price: float):
    """
    –°–æ–≤–º–µ—Å—Ç–∏–º–∞—è –æ–±—ë—Ä—Ç–∫–∞ –ø–æ–¥ —Å—Ç–∞—Ä—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:
    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict {probability, confidence, signal, ...}
    """
    try:
        proba = ml_predict_proba_safe(features_dict)
        if proba is None:
            return {"probability": 0.5, "confidence": 0.0, "signal": None}

        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∫–∞–∫ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç 0.5 (0..1)
        confidence_score = float(abs(proba - 0.5) * 2.0)

        signal = None
        if proba >= ML_PROBABILITY_THRESHOLD:
            signal = "BUY"
        elif proba <= (1.0 - ML_PROBABILITY_THRESHOLD):
            signal = "SELL"

        logging.info(f"ü§ñ ML {pair}: proba={proba:.3f}, conf={confidence_score:.3f}, signal={signal}")
        return {
            "probability": proba,
            "confidence": confidence_score,
            "signal": signal,
            "price": current_price,
        }
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ ml_predict_enhanced –¥–ª—è {pair}: {e}", exc_info=True)
        return {"probability": 0.5, "confidence": 0.0, "signal": None}

# ===================== –í–ê–õ–ò–î–ê–¶–ò–Ø –°–ò–ì–ù–ê–õ–ê (–æ—Å—Ç–∞–≤–ª–µ–Ω–æ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º) =====================
def validate_ml_signal_with_context(ml_result, trend_analysis, pair):
    """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç ML-—Å–∏–≥–Ω–∞–ª —Å —É—á—ë—Ç–æ–º —Ç—Ä–µ–Ω–¥–∞/RSI/–∏–º–ø—É–ª—å—Å–∞."""
    if not ml_result or not ml_result.get('signal'):
        return ml_result

    signal = ml_result['signal']
    confidence = ml_result['confidence']

    # –ü—Ä–æ—Ç–∏–≤ —Ç—Ä–µ–Ω–¥–∞
    if (signal == 'BUY' and trend_analysis['direction'] == 'BEARISH' and 
        trend_analysis['strength'] in ['STRONG', 'VERY_STRONG']):
        confidence *= 0.5
        logging.info(f"‚ö†Ô∏è ML: BUY –ø—Ä–æ—Ç–∏–≤ —Å–∏–ª—å–Ω–æ–≥–æ –º–µ–¥–≤–µ–∂—å–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞ ({pair})")
    elif (signal == 'SELL' and trend_analysis['direction'] == 'BULLISH' and 
          trend_analysis['strength'] in ['STRONG', 'VERY_STRONG']):
        confidence *= 0.5
        logging.info(f"‚ö†Ô∏è ML: SELL –ø—Ä–æ—Ç–∏–≤ —Å–∏–ª—å–Ω–æ–≥–æ –±—ã—á—å–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞ ({pair})")

    # RSI —ç–∫—Å—Ç—Ä–µ–º—É–º—ã
    if signal == 'BUY' and trend_analysis['rsi_state'] == 'OVERBOUGHT':
        confidence *= 0.6
        logging.info(f"‚ö†Ô∏è ML: BUY –≤ –∑–æ–Ω–µ –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç–∏ ({pair})")
    elif signal == 'SELL' and trend_analysis['rsi_state'] == 'OVERSOLD':
        confidence *= 0.6
        logging.info(f"‚ö†Ô∏è ML: SELL –≤ –∑–æ–Ω–µ –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç–∏ ({pair})")

    # –ò–º–ø—É–ª—å—Å
    if trend_analysis.get('is_strong_impulse', False):
        impulse_dir = trend_analysis.get('impulse_direction')
        if impulse_dir and signal != impulse_dir:
            confidence *= 0.4
            logging.info(f"‚ö†Ô∏è ML: —Å–∏–≥–Ω–∞–ª –ø—Ä–æ—Ç–∏–≤ —Å–∏–ª—å–Ω–æ–≥–æ –∏–º–ø—É–ª—å—Å–∞ ({pair})")

    ml_result['confidence'] = confidence
    ml_result['validated'] = confidence >= 0.3
    return ml_result

# ===================== –§–ò–õ–¨–¢–† –í–•–û–î–ê (–æ—Å—Ç–∞–≤–ª–µ–Ω–æ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º) =====================
def should_take_trade(pair: str, smc_signal: dict, ml_result: dict, rsi_value: float, trends: dict) -> bool:
    """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –≤—Ö–æ–¥–∞ –≤ —Å–¥–µ–ª–∫—É."""
    try:
        smc_conf = smc_signal.get('confidence', 0) if (smc_signal and smc_signal.get('signal')) else 0
        smc_dir = smc_signal.get('signal') if smc_signal else None

        ml_dir = ml_result.get('signal') if ml_result else None
        ml_conf = ml_result.get('confidence', 0) if ml_result else 0
        ml_valid = ml_result.get('validated', False) if ml_result else False

        rsi_overbought = rsi_value >= 70
        rsi_oversold = rsi_value <= 30

        major_trend = trends.get('M30', 'NEUTRAL')
        minor_trend = trends.get('M5', 'NEUTRAL')

        # –û—Ç—Å–µ–∏–≤–∞–µ–º —Å–ª–∞–±—ã–µ
        if smc_conf < 4 and (ml_conf < 0.15 or not ml_valid):
            return False

        # –°–∏–ª—å–Ω—ã–π SMC + ML –Ω–µ –ø—Ä–æ—Ç–∏–≤
        if smc_dir and smc_conf >= 6:
            if ml_dir is None or ml_dir == smc_dir:
                return True

        # –£–≤–µ—Ä–µ–Ω–Ω—ã–π ML + –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if ml_valid and ml_conf >= 0.25:
            if ml_dir == 'BUY' and (minor_trend == 'BULLISH' or major_trend == 'BULLISH') and not rsi_overbought:
                return True
            if ml_dir == 'SELL' and (minor_trend == 'BEARISH' or major_trend == 'BEARISH') and not rsi_oversold:
                return True

        if ml_dir == 'BUY' and rsi_overbought:
            return False
        if ml_dir == 'SELL' and rsi_oversold:
            return False

        return False
    except Exception as e:
        logging.error(f"[FILTER] –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è {pair}: {e}")
        return False

# ===================== –£–¢–ò–õ–ò–¢–´ –†–ï–ú–û–ù–¢–ê ML –§–ò–ß–ï–ô (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) =====================
def repair_ml_features():
    """–ü–æ–º–µ—á–∞–µ—Ç —Å–¥–µ–ª–∫–∏ –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ ml_features, –Ω–µ –ø–æ–¥—Å—Ç–∞–≤–ª—è—è —Ñ–µ–π–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è."""
    try:
        needs_repair_count = 0
        if MULTI_USER_MODE:
            for user_id, user_data in users.items():
                for trade in user_data.get('trade_history', []):
                    if not trade.get('ml_features') and trade.get('pair'):
                        trade['needs_ml_recalculation'] = True
                        needs_repair_count += 1
        else:
            for trade in single_user_data.get('trade_history', []):
                if not trade.get('ml_features') and trade.get('pair'):
                    trade['needs_ml_recalculation'] = True
                    needs_repair_count += 1

        if needs_repair_count > 0:
            save_users_data()
            logging.info(f"üîß –ü–æ–º–µ—á–µ–Ω–æ {needs_repair_count} —Å–¥–µ–ª–æ–∫ –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ ml_features")
        return needs_repair_count
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è ml_features: {e}")
        return 0

# ===================== TELEGRAM COMMAND: /repairml =====================
from telegram import Update
from telegram.ext import ContextTypes

async def repair_ml_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ Telegram /repairml ‚Äî –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ ml_features –¥–ª—è —Å–¥–µ–ª–æ–∫"""
    user_id = update.effective_user.id

    if MULTI_USER_MODE and not is_admin(user_id):
        await update.message.reply_text("‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
        return

    await update.message.reply_text("üîÑ –ó–∞–ø—É—Å–∫–∞—é –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ ml_features –¥–ª—è –≤—Å–µ—Ö —Å–¥–µ–ª–æ–∫...")

    repaired_count = repair_ml_features()

    if repaired_count > 0:
        await update.message.reply_text(
            f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ ml_features –¥–ª—è {repaired_count} —Å–¥–µ–ª–æ–∫!\n"
            f"üöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å /forcetrain –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."
        )
    else:
        await update.message.reply_text("‚ÑπÔ∏è –í—Å–µ —Å–¥–µ–ª–∫–∏ —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç ml_features, –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")


# ===================== –û–ë–£–ß–ï–ù–ò–ï =====================
def train_ml_model():
    """
    –£—Å—Ç–æ–π—á–∏–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ:
    - time-based split
    - RandomForest —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
    - –≤—ã–±–æ—Ä —Ñ–∏—á: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑ pkl/–∏—Å—Ç–æ—Ä–∏–∏ –∏–ª–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ (top-K)
    - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ feature_names –≤ ml_info_last.json
    """
    global ml_model, ml_scaler, model_info

    try:
        # –°–±–æ—Ä –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
        all_trades = []
        if MULTI_USER_MODE:
            for user_data in users.values():
                all_trades.extend(user_data.get('trade_history', []))
            logging.info(f"üìä ML: —Å–æ–±—Ä–∞–Ω–æ {len(all_trades)} —Å–¥–µ–ª–æ–∫ –∏–∑ {len(users)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
        else:
            all_trades.extend(single_user_data.get('trade_history', []))
            logging.info(f"üìä ML: —Å–æ–±—Ä–∞–Ω–æ {len(all_trades)} —Å–¥–µ–ª–æ–∫ –∏–∑ –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")

        completed = [
            t for t in all_trades
            if t.get('result') in ('WIN', 'LOSS')
            and isinstance(t.get('ml_features'), dict)
        ]
        if len(completed) < MIN_SAMPLES_TO_TRAIN:
            logging.warning(f"‚ö† –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(completed)} < {MIN_SAMPLES_TO_TRAIN}")
            return

        # –ë–∞–∑–æ–≤—ã–π –ø–µ—Ä–µ—á–µ–Ω—å —Ñ–∏—á ‚Äî –±–µ—Ä—ë–º –∏–∑ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ ¬´–±–æ–≥–∞—Ç–æ–π¬ª —Å–¥–µ–ª–∫–∏
        base_feature_names = None
        for t in reversed(completed[-400:]):
            feats = t.get('ml_features')
            if isinstance(feats, dict) and len(feats) >= 10:
                base_feature_names = list(feats.keys())
                break
        if not base_feature_names:
            logging.warning("‚ùå –ù–µ—Ç —Å–¥–µ–ª–æ–∫ —Å ml_features ‚Äî –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ")
            return

        # –§–æ—Ä–º–∏—Ä—É–µ–º –º–∞—Ç—Ä–∏—Ü—É
        X, y, ts = [], [], []
        for tr in completed:
            feats = tr.get('ml_features', {})
            X.append([float(feats.get(f, 0.0)) for f in base_feature_names])
            y.append(1 if tr.get('result') == 'WIN' else 0)
            ts.append(tr.get('timestamp', None))
        X = np.asarray(X, dtype=float)
        y = np.asarray(y, dtype=int)
        ts = pd.to_datetime(pd.Series(ts), errors='coerce').astype('int64').fillna(0).to_numpy()

        # Time-based split
        order = np.argsort(ts)
        X, y = X[order], y[order]
        split_idx = int(len(X) * 0.75)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        logging.info(f"üïí Time-based split: train={len(X_train)}, test={len(X_test)}")

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        scaler = StandardScaler()
        X_train_s = scaler.fit_transform(X_train)
        X_test_s = scaler.transform(X_test)

        # –ë–∞–∑–æ–≤–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        params = {
            'n_estimators': 140,
            'max_depth': 6,
            'min_samples_split': 20,
            'min_samples_leaf': 10,
            'max_features': 0.5,
            'max_samples': 0.8,
            'min_weight_fraction_leaf': 0.01,
            'random_state': 42,
            'class_weight': 'balanced',
            'n_jobs': -1,
        }
        base_model = RandomForestClassifier(**params)
        base_model.fit(X_train_s, y_train)

        # –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ –æ—Ç–±–æ—Ä–∞
        train_acc = accuracy_score(y_train, base_model.predict(X_train_s))
        test_acc = accuracy_score(y_test, base_model.predict(X_test_s))
        overfit_ratio = train_acc / max(test_acc, 1e-6)

        # ----- –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ -----
        # 1) –ø—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Å–ø–∏—Å–æ–∫ (–∏—Å—Ç–æ—Ä–∏—è/pkl), —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
        preserved = _get_expected_feature_list()
        if preserved:
            selected_features = [f for f in preserved if f in base_feature_names]
            logging.info(f"üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(selected_features)} —à—Ç.")
        else:
            # 2) –∏–Ω–∞—á–µ –±–µ—Ä—ë–º top-K –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            importances = base_model.feature_importances_
            pairs = list(zip(base_feature_names, importances))
            pairs.sort(key=lambda x: x[1], reverse=True)
            if TOP_K_FEATURES and TOP_K_FEATURES > 0:
                k = min(TOP_K_FEATURES, len(pairs))
            else:
                # –µ—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω–æ–≥–æ K ‚Äî –≤–æ–∑—å–º—ë–º —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä pkl/–∏—Å—Ç–æ—Ä–∏–∏ (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –ø–æ—è–≤–∏—Ç—Å—è)
                k = len(pairs)
            selected_features = [f for f, _ in pairs[:k]]
            logging.info(f"üèÜ –í—ã–±—Ä–∞–Ω—ã top-{len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏")

        # –ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º –ø–æ–¥–º–∞—Ç—Ä–∏—Ü—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
        idx = {f: i for i, f in enumerate(base_feature_names)}
        cols = [idx[f] for f in selected_features if f in idx]
        X_train_top = X_train[:, cols]
        X_test_top = X_test[:, cols]

        scaler2 = StandardScaler()
        X_train_top_s = scaler2.fit_transform(X_train_top)
        X_test_top_s = scaler2.transform(X_test_top)

        model = RandomForestClassifier(**params)
        model.fit(X_train_top_s, y_train)

        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ –æ—Ç–±–æ—Ä–∞
        y_tr2 = model.predict(X_train_top_s)
        y_te2 = model.predict(X_test_top_s)
        train_acc2 = accuracy_score(y_train, y_tr2)
        test_acc2 = accuracy_score(y_test, y_te2)
        precision2 = precision_score(y_test, y_te2, zero_division=0)
        recall2 = recall_score(y_test, y_te2, zero_division=0)
        f12 = f1_score(y_test, y_te2, zero_division=0)
        overfit_ratio2 = train_acc2 / max(test_acc2, 1e-6)

        # CV –Ω–∞ train
        try:
            folds = min(5, max(2, len(X_train_top_s)//400))
            cv_scores = cross_val_score(model, X_train_top_s, y_train, cv=folds, scoring='accuracy')
            cv_mean, cv_std = float(np.mean(cv_scores)), float(np.std(cv_scores))
        except Exception as e:
            logging.warning(f"CV –ø—Ä–æ–ø—É—â–µ–Ω: {e}")
            cv_mean, cv_std = float('nan'), float('nan')

        # ---- –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ TOP-–≤–µ—Ä—Å–∏—é ----
        joblib.dump(model, ML_MODEL_PATH)
        joblib.dump(scaler2, ML_SCALER_PATH)

        # –û–±–Ω–æ–≤–∏–º pkl —Å–æ —Å–ø–∏—Å–∫–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—á—Ç–æ–±—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –±—ã–ª –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–µ–Ω)
        try:
            with open(ML_FEATS_PKL, "wb") as f:
                pickle.dump(selected_features, f)
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å {ML_FEATS_PKL}: {e}")

        # model_info + –∏—Å—Ç–æ—Ä–∏—è
        global model_info, ml_model, ml_scaler
        ml_model, ml_scaler = model, scaler2

        win_rate_overall = float(np.mean(y)) * 100.0
        model_info = {
            "trained_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "n_features": len(selected_features),
            "trades_used": int(len(X)),
            "train_accuracy": round(train_acc2 * 100, 2),
            "test_accuracy": round(test_acc2 * 100, 2),
            "test_precision": round(precision2 * 100, 2),
            "test_recall": round(recall2 * 100, 2),
            "test_f1": round(f12 * 100, 2),
            "cv_accuracy": round(cv_mean * 100, 2) if not np.isnan(cv_mean) else None,
            "cv_std": round(cv_std * 100, 2) if not np.isnan(cv_std) else None,
            "overfitting_ratio": round(overfit_ratio2, 2),
            "feature_names": selected_features,  # <<< –ö—Ä–∏—Ç–∏—á–Ω–æ: —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
            "train_samples": int(len(y_train)),
            "test_samples": int(len(y_test)),
            "win_rate": round(win_rate_overall, 2),
            "model_params": model.get_params()
        }
        with open(ML_INFO_LAST, "w", encoding="utf-8") as f:
            json.dump(model_info, f, ensure_ascii=False, indent=2)
        _append_ml_info(model_info)

        logging.info(f"‚úÖ ML (features={len(selected_features)}): Test={test_acc2:.3f} | Train={train_acc2:.3f} | Overfit={overfit_ratio2:.2f}")

        return model_info
    
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è ML: {e}", exc_info=True)

# ===================== (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ú–Ø–ì–ö–ò–ô –ë–£–°–¢ –£–í–ï–†–ï–ù–ù–û–°–¢–ò =====================
# –ï—Å–ª–∏ –ø–æ–ª—å–∑—É–µ—à—å—Å—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π —à–∫–∞–ª–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ SMC/GPT, –º–æ–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å —ç—Ç–æ –º–µ—Å—Ç–æ:
ML_CONF_THRESHOLDS = {"boost2": 0.62, "boost1": 0.58, "cut1": 0.45, "cut2": 0.40}
ML_CONF_MAX_ABS_DELTA = 2
ML_CONF_MIN_BASE = 4
ML_CONF_MAX_BASE = 9

def apply_ml_confidence_boost(base_conf: int, ml_features: Dict[str, float]) -> Tuple[int, Optional[float], str]:
    """–ú—è–≥–∫–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ ML proba (–Ω–µ –ª–æ–º–∞—è SMC/GPT)."""
    proba = ml_predict_proba_safe(ml_features)
    if proba is None:
        return base_conf, None, "ML:skip"

    conf = int(base_conf)
    delta = 0
    if proba >= ML_CONF_THRESHOLDS["boost2"] and conf >= ML_CONF_MIN_BASE and conf < ML_CONF_MAX_BASE:
        delta = min(2, ML_CONF_MAX_ABS_DELTA)
    elif proba >= ML_CONF_THRESHOLDS["boost1"]:
        delta = min(1, ML_CONF_MAX_ABS_DELTA)
    elif proba <= ML_CONF_THRESHOLDS["cut2"]:
        delta = -min(2, ML_CONF_MAX_ABS_DELTA)
    elif proba <= ML_CONF_THRESHOLDS["cut1"]:
        delta = -min(1, ML_CONF_MAX_ABS_DELTA)

    new_conf = max(0, min(10, conf + delta))
    expl = f"ML:{proba:.2f}"
    if delta != 0:
        expl += f" Œî{delta:+d}"
    return new_conf, proba, expl

# ===================== GPT ANALYSIS =====================
def gpt_full_market_read(pair: str, df_m1: pd.DataFrame, df_m5: pd.DataFrame):
    """GPT-–∞–Ω–∞–ª–∏–∑ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –≤—Ä–µ–º–µ–Ω–∏ —ç–∫—Å–ø–∏—Ä–∞—Ü–∏–∏ (1-4 –º–∏–Ω—É—Ç—ã)"""
    try:
        if df_m1 is None or len(df_m1) < 100:
            return None, None
            
        # –ë–µ—Ä–µ–º 400 —Å–≤–µ—á–µ–π M1 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        candles = df_m1.tail(400)[['open','high','low','close','tick_volume']].round(5)
        candles = candles.to_dict(orient='records')
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ —ç–∫—Å–ø–∏—Ä–∞—Ü–∏–∏
        current_price = df_m1['close'].iloc[-1]
        atr = ta.ATR(df_m1['high'], df_m1['low'], df_m1['close'], timeperiod=14).iloc[-1]
        volatility_percent = (atr / current_price) * 100 if current_price > 0 else 0
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤–æ–µ –≤—Ä–µ–º—è —ç–∫—Å–ø–∏—Ä–∞—Ü–∏–∏ –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–∫–∞–∫ –≤ SMC)
        if volatility_percent >= 0.035:
            base_expiry = 1
        elif volatility_percent >= 0.02:
            base_expiry = 2
        elif volatility_percent >= 0.01:
            base_expiry = 3
        else:
            base_expiry = 4
            
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 1-4 –º–∏–Ω—É—Ç–∞–º–∏ –∫–∞–∫ –≤ SMC
        base_expiry = max(1, min(base_expiry, 4))

        prompt = f"""
–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–µ–π–¥–µ—Ä –±–∏–Ω–∞—Ä–Ω—ã—Ö –æ–ø—Ü–∏–æ–Ω–æ–≤. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ—Å–ª–µ–¥–Ω–∏–µ 400 —Å–≤–µ—á–µ–π M1 (6.5 —á–∞—Å–∞ –¥–∞–Ω–Ω—ã—Ö) –¥–ª—è –ø–∞—Ä—ã {pair}.

–ö–†–ò–¢–ï–†–ò–ò –ê–ù–ê–õ–ò–ó–ê:
1. –û–ø—Ä–µ–¥–µ–ª–∏ –æ–±—â–∏–π —Ç—Ä–µ–Ω–¥ (–±—ã—á–∏–π/–º–µ–¥–≤–µ–∂–∏–π/—Ñ–ª—ç—Ç)
2. –ù–∞–π–¥–∏ –∫–ª—é—á–µ–≤—ã–µ —É—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è  
3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–±—ä–µ–º—ã –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö –¥–≤–∏–∂–µ–Ω–∏—è—Ö
4. –û—Ü–µ–Ω–∏ —Å–∏–ª—É —Ç–µ–∫—É—â–µ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
5. –û–ø—Ä–µ–¥–µ–ª–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞

–í–ê–ñ–ù–û: –í—Ä–µ–º—è —ç–∫—Å–ø–∏—Ä–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 1 –¥–æ 4 –º–∏–Ω—É—Ç. –¢–µ–∫—É—â–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: {volatility_percent:.4f}% - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è {base_expiry} –º–∏–Ω.

–û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON: {{"decision":"BUY/SELL/WAIT","expiry":1-4,"confidence":1-10,"reason":"–∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"}}

–î–∞–Ω–Ω—ã–µ —Å–≤–µ—á–µ–π (–ø–µ—Ä–≤—ã–µ 50 –∏–∑ 400): {json.dumps(candles[:50], ensure_ascii=False)}
"""
        resp = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":"–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–µ–π–¥–µ—Ä. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON."},
                      {"role":"user","content":prompt}],
            temperature=0.1,
            timeout=45
        )
        
        text = resp.choices[0].message.content.strip()
        if "```" in text:
            text = text.replace("```json","").replace("```","").strip()
            
        if "{" in text and "}" in text:
            json_str = text[text.find("{"):text.rfind("}")+1]
            try:
                data = json.loads(json_str)
                decision = data.get("decision")
                expiry = data.get("expiry", base_expiry)
                confidence = data.get("confidence", 5)
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —ç–∫—Å–ø–∏—Ä–∞—Ü–∏—é 1-4 –º–∏–Ω—É—Ç–∞–º–∏ –∫–∞–∫ –≤ SMC
                expiry = max(1, min(expiry, 4))
                
                if decision in ["BUY","SELL"] and confidence >= 6:
                    return decision, expiry
                return None, None
            except:
                return None, None
        return None, None
        
    except Exception as e:
        logging.warning(f"GPT error: {e}")
        return None, None
# ===================== ROUND LEVELS DETECTION =====================
def detect_round_levels(price: float, pip_distance: float = 0.0050) -> dict:
    """–£–õ–£–ß–®–ï–ù–ù–û–ï –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫—Ä—É–≥–ª—ã—Ö —É—Ä–æ–≤–Ω–µ–π"""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑—Ä—è–¥ —Ü–µ–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫—Ä—É–≥–ª—ã—Ö —É—Ä–æ–≤–Ω–µ–π
    if price >= 100:
        # –î–ª—è JPY –ø–∞—Ä
        round_levels = [
            round(price / 5) * 5 - 10,  # –ë–ª–∏–∂–∞–π—à–∏–µ —É—Ä–æ–≤–Ω–∏
            round(price / 5) * 5 - 5,
            round(price / 5) * 5,
            round(price / 5) * 5 + 5,
            round(price / 5) * 5 + 10
        ]
        threshold = 1.0  # 100 –ø–∏–ø—Å–æ–≤ –¥–ª—è JPY
    elif price >= 1.0:
        # –î–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–∞—Ä
        base = int(price)
        round_levels = []
        for i in range(base - 2, base + 3):
            round_levels.extend([
                i + 0.0000,
                i + 0.1000,
                i + 0.2000, 
                i + 0.3000,
                i + 0.4000,
                i + 0.5000,
                i + 0.6000,
                i + 0.7000,
                i + 0.8000,
                i + 0.9000
            ])
        threshold = 0.0020  # 20 –ø–∏–ø—Å–æ–≤
    else:
        # –î–ª—è —ç–∫–∑–æ—Ç–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä
        round_levels = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
        threshold = 0.0020
    
    # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à–∏–π –∫—Ä—É–≥–ª—ã–π —É—Ä–æ–≤–µ–Ω—å
    closest_level = min(round_levels, key=lambda x: abs(x - price))
    distance = abs(price - closest_level)
    distance_pips = distance * 10000
    
    # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ª–æ–≥–∏–∫–∞ —Å–∏–ª—ã
    if distance <= threshold * 0.1:
        strength = "VERY_STRONG"
        confidence_boost = 3
    elif distance <= threshold * 0.3:
        strength = "STRONG" 
        confidence_boost = 2
    elif distance <= threshold * 0.6:
        strength = "MEDIUM"
        confidence_boost = 1
    else:
        strength = "WEAK"
        confidence_boost = 0
    
    return {
        "closest_level": closest_level,
        "distance": distance,
        "distance_pips": distance_pips,
        "strength": strength,
        "confidence_boost": confidence_boost,
        "is_near_round": distance <= threshold
    }


def log_trade_to_file(trade: dict, result: str = None):
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∫–∞–∂–¥—É—é —Å–¥–µ–ª–∫—É –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ª–æ–≥-—Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    """
    try:
        log_entry = {
            "timestamp": trade.get('timestamp', datetime.now().isoformat()),
            "pair": trade.get('pair'),
            "direction": trade.get('direction'),
            "entry_price": trade.get('entry_price'),
            "exit_price": trade.get('exit_price'),
            "stake": trade.get('stake'),
            "result": result or trade.get('result'),
            "profit": trade.get('profit'),
            "source": trade.get('source'),
            "confidence": trade.get('confidence'),
            "ml_probability": trade.get('ml_features', {}).get('ml_probability') if isinstance(trade.get('ml_features'), dict) else None,
            "ml_confidence": trade.get('ml_features', {}).get('ml_confidence') if isinstance(trade.get('ml_features'), dict) else None,
            "round_level": trade.get('ml_features', {}).get('round_level_info', {}).get('closest_level') if isinstance(trade.get('ml_features'), dict) else None,
            "round_distance": trade.get('ml_features', {}).get('round_level_info', {}).get('distance_pips') if isinstance(trade.get('ml_features'), dict) else None,
            "expiry_minutes": trade.get('expiry_minutes')
        }
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ CSV
        log_file = "trades_log.csv"
        file_exists = os.path.exists(log_file)
        
        with open(log_file, 'a', encoding='utf-8') as f:
            if not file_exists:
                headers = ",".join(log_entry.keys())
                f.write(headers + "\n")
            
            values = ",".join(str(v) if v is not None else "" for v in log_entry.values())
            f.write(values + "\n")
            
        logging.info(f"‚úÖ –°–¥–µ–ª–∫–∞ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞ –≤ {log_file}")
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–¥–µ–ª–∫–∏: {e}")
        
# ===================== ANALYZE PAIR =====================
def get_mt5_data(symbol: str, n: int, timeframe) -> Optional[pd.DataFrame]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∫–æ—Ç–∏—Ä–æ–≤–∫–∏ –∏–∑ MT5"""
    try:
        if not mt5.terminal_info():
            logging.error("MT5 —Ç–µ—Ä–º–∏–Ω–∞–ª –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω")
            return None

        rates = mt5.copy_rates_from_pos(symbol, timeframe, 0, n)
        if rates is None or len(rates) == 0:
            logging.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}")
            return None

        df = pd.DataFrame(rates)
        df['time'] = pd.to_datetime(df['time'], unit='s')
        df.set_index('time', inplace=True)
        return df

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö MT5: {e}")
        return None

def analyze_trend(df, timeframe_name="M1"):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç—Ä–µ–Ω–¥ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ"""
    if df is None or len(df) < 50:
        return "NEUTRAL"
    
    try:
        # –ê–Ω–∞–ª–∏–∑ –ø–æ EMA –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞
        ema_10 = ta.EMA(df['close'], timeperiod=10).iloc[-1]
        ema_20 = ta.EMA(df['close'], timeperiod=20).iloc[-1]
        ema_50 = ta.EMA(df['close'], timeperiod=50).iloc[-1]
        current_price = df['close'].iloc[-1]
        
        # –ú–Ω–æ–≥–æ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
        bullish_signals = 0
        bearish_signals = 0
        
        # –¶–µ–Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ EMA
        if current_price > ema_10 > ema_20 > ema_50:
            bullish_signals += 2
        elif current_price < ema_10 < ema_20 < ema_50:
            bearish_signals += 2
        
        # –ù–∞–∫–ª–æ–Ω EMA
        ema_10_prev = ta.EMA(df['close'], timeperiod=10).iloc[-2] if len(df) > 10 else ema_10
        if ema_10 > ema_10_prev:
            bullish_signals += 1
        else:
            bearish_signals += 1
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞
        if bullish_signals - bearish_signals >= 2:
            trend = "BULLISH"
        elif bearish_signals - bullish_signals >= 2:
            trend = "BEARISH"
        else:
            trend = "NEUTRAL"
            
        logging.debug(f"üìà {timeframe_name} —Ç—Ä–µ–Ω–¥: {trend} (bullish:{bullish_signals}, bearish:{bearish_signals})")
        return trend
        
    except Exception as e:
        logging.warning(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–∞ –Ω–∞ {timeframe_name}: {e}")
        return "NEUTRAL"

def analyze_pair(pair: str):
    try:

        global ml_model, ml_scaler, ml_features_count
        # üïí –ü–†–û–í–ï–†–Ø–ï–ú –§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ô –ì–†–ê–§–ò–ö –†–ê–ë–û–¢–´ –ë–û–¢–ê
        if not is_trading_time():
            logging.info(f"‚è∏ –í–Ω–µ —Ä–∞–±–æ—á–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –±–æ—Ç–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ {pair}")
            return None, None, 0, "OUT_OF_SCHEDULE", None
        
        logging.info(f"üîç –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ä—ã: {pair}")

        # 1Ô∏è‚É£ –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df_m1 = get_mt5_data(pair, 400, mt5.TIMEFRAME_M1)
        df_m5 = get_mt5_data(pair, 200, mt5.TIMEFRAME_M5)
        df_m15 = get_mt5_data(pair, 100, mt5.TIMEFRAME_M15)
        df_m30 = get_mt5_data(pair, 80, mt5.TIMEFRAME_M30)
        if df_m1 is None or df_m5 is None:
            logging.warning(f"‚ö† –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {pair}")
            return None, None, 0, "NO_DATA", None

        current_price = df_m1['close'].iloc[-1]
        logging.info(f"üí∞ {pair}: —Ç–µ–∫—É—â–∞—è —Ü–µ–Ω–∞ = {current_price:.5f}")

        # 2Ô∏è‚É£ –¢—Ä–µ–Ω–¥—ã –∏ —É—Ä–æ–≤–Ω–∏
        trend_analysis = enhanced_trend_analysis(df_m1)
        m5_trend = analyze_trend(df_m5, "M5")
        m15_trend = analyze_trend(df_m15, "M15")
        m30_trend = analyze_trend(df_m30, "M30")
        round_info = detect_round_levels(current_price)
        logging.info(f"üìä –¢—Ä–µ–Ω–¥—ã M5={m5_trend}, M15={m15_trend}, M30={m30_trend}")
        logging.info(f"üéØ –ö—Ä—É–≥–ª—ã–π —É—Ä–æ–≤–µ–Ω—å: {round_info['closest_level']} —Å–∏–ª–∞={round_info['strength']}")

        # 3Ô∏è‚É£ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ ML —Ñ–∏—á–µ–π (42 –ø—Ä–∏–∑–Ω–∞–∫–∞)
        ml_enabled_for_this_pair = ML_ENABLED
        if ML_ENABLED and (ml_model is None or ml_scaler is None):
            initialize_ml_model()
            if ml_model is None or ml_scaler is None:
                ml_enabled_for_this_pair = False
                logging.warning(f"‚è≠ {pair}: ML –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω - –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")

        ml_features_dict = prepare_ml_features(df_m1)
        ml_features_data = None
        feats_array = None

        if ml_features_dict is not None:
            # üß† –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ —Å–¥–µ–ª–∫–∏
            ml_features_data = ml_features_dict.copy()

            # ‚û°Ô∏è –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º dict ‚Üí array –¥–ª—è –ø–æ–¥–∞—á–∏ –≤ ML –º–æ–¥–µ–ª—å
            feature_names = list(ml_features_dict.keys())
            feats_array = np.array([ml_features_dict[f] for f in feature_names]).reshape(1, -1)
            ml_features_data['round_level_info'] = round_info

            logging.info(f"üìä {pair}: –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã {len(feature_names)} ML —Ñ–∏—á–µ–π")

        # 4Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
        smc_result = {
            "signal": None,
            "confidence": 0,
            "expiry": None,
            "source": "SMC"
        }
        ml_result = None
        gpt_result = None

        # --- SMC ---
        smc_signal, smc_expiry, smc_conf, smc_source = enhanced_smart_money_analysis(df_m1)
        if smc_signal and smc_conf >= 4:
            smc_result.update({"signal": smc_signal, "confidence": smc_conf, "expiry": smc_expiry})
            logging.info(f"‚úÖ {pair}: SMC —Å–∏–≥–Ω–∞–ª = {smc_signal} (conf={smc_conf})")

        # --- ML ---
        if ml_enabled_for_this_pair and feats_array is not None:
            try:
                # üîß –î–û–ë–ê–í–¨ –≠–¢–û–¢ –ë–õ–û–ö –î–õ–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø SCALER
                current_feature_count = feats_array.shape[1]
                if (ml_scaler is not None and 
                    hasattr(ml_scaler, 'n_features_in_') and 
                    ml_scaler.n_features_in_ != current_feature_count):
            
                    logging.warning(f"üîÑ –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: scaler={ml_scaler.n_features_in_}, –¥–∞–Ω–Ω—ã–µ={current_feature_count}")
                    logging.info("üîÑ –ü–µ—Ä–µ—Å–æ–∑–¥–∞—é scaler —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é...")
            
                    # –ü–ï–†–ï–°–û–ó–î–ê–ï–ú SCALER –° –ü–†–ê–í–ò–õ–¨–ù–û–ô –†–ê–ó–ú–ï–†–ù–û–°–¢–¨–Æ
                    ml_scaler = StandardScaler()
                    ml_scaler.fit(feats_array)  # –û–±—É—á–∞–µ–º –Ω–∞ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        
                # ‚úÖ –¢–ï–ü–ï–†–¨ –≠–¢–ê –°–¢–†–û–ö–ê –ë–£–î–ï–¢ –†–ê–ë–û–¢–ê–¢–¨ –ë–ï–ó –û–®–ò–ë–û–ö
                feats_scaled = ml_scaler.transform(feats_array)
        
                ml_pred = ml_model.predict_proba(feats_scaled)[0][1]
                ml_confidence = round(ml_pred * 100, 1)
                ml_signal = "BUY" if ml_pred >= 0.5 else "SELL"

                ml_result = {
                    "signal": ml_signal,
                    "confidence": ml_pred,
                    "validated": True
                }

                ml_result = validate_ml_signal_with_context(ml_result, trend_analysis, pair)
                logging.info(f"ü§ñ {pair}: ML —Å–∏–≥–Ω–∞–ª={ml_result['signal']} conf={ml_result['confidence']:.2f} valid={ml_result['validated']}")

            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ ML –¥–ª—è {pair}: {e}")

        # --- GPT ---
        if USE_GPT:
            gpt_signal, gpt_expiry = gpt_full_market_read(pair, df_m1, df_m5)
            if gpt_signal:
                gpt_result = {"signal": gpt_signal, "confidence": 6, "expiry": gpt_expiry, "source": "GPT"}
                logging.info(f"üí¨ {pair}: GPT —Å–∏–≥–Ω–∞–ª={gpt_signal}")

        # 5Ô∏è‚É£ ‚úÖ –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
        final_signal = None
        final_expiry = None
        final_confidence = 0
        final_source = None

        # üìå 1. SMC –µ—Å–ª–∏ —Å–∏–ª—å–Ω—ã–π, –∞ ML –Ω–µ –ø—Ä–æ—Ç–∏–≤ ‚Üí –±–µ—Ä—ë–º
        if smc_result['signal'] and smc_result['confidence'] >= 7:
            if not ml_result or ml_result['signal'] == smc_result['signal']:
                final_signal = smc_result['signal']
                final_confidence = smc_result['confidence']
                final_expiry = smc_result['expiry']
                final_source = "ENHANCED_SMART_MONEY"

        # üìå 2. ML –µ—Å–ª–∏ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω –∏ –Ω–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É–µ—Ç —Å RSI –∏ —Ç—Ä–µ–Ω–¥–æ–º
        elif ml_result and ml_result['signal'] and ml_result['validated'] and ml_result['confidence'] >= 0.25:
            rsi_val = ml_features_dict.get('rsi', 50)
            if (ml_result['signal'] == 'BUY' and rsi_val < 70 and m15_trend == 'BULLISH') or \
               (ml_result['signal'] == 'SELL' and rsi_val > 30 and m15_trend == 'BEARISH'):
                final_signal = ml_result['signal']
                final_confidence = int(ml_result['confidence'] * 20)
                final_expiry = 2
                final_source = "ML_VALIDATED"

        # üìå 3. GPT –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –¥—Ä—É–≥–æ–≥–æ –Ω–µ—Ç
        elif gpt_result:
            final_signal = gpt_result['signal']
            final_confidence = gpt_result['confidence']
            final_expiry = gpt_result['expiry']
            final_source = gpt_result['source']

        # 6Ô∏è‚É£ –í–æ–∑–≤—Ä–∞—Ç
        if final_signal:
            logging.info(f"üöÄ {pair}: –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª = {final_signal} ({final_source}, conf={final_confidence})")
            
            return final_signal, final_expiry, final_confidence, final_source, ml_features_data

        logging.info(f"‚ùå {pair}: —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–µ—Ç –∏–ª–∏ –æ–Ω–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã")
        return None, None, 0, "NO_SIGNAL", ml_features_data

    except Exception as e:
        logging.error(f"üí• –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ä—ã {pair}: {e}", exc_info=True)
        return None, None, 0, "ERROR", None
    
# ===================== FAST CHART (MATPLOTLIB) =====================
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from io import BytesIO
import pandas as pd
import logging
from datetime import datetime

# üî• –ì–õ–û–ë–ê–õ–¨–ù–´–ô –ö–≠–® –ì–†–ê–§–ò–ö–û–í –í –ü–ê–ú–Ø–¢–ò
CHART_CACHE = {}
CACHE_EXPIRY = 300  # 5 –º–∏–Ω—É—Ç

def enhanced_plot_chart(df, pair, entry_price, direction):
    """–°–£–ü–ï–†-–ë–´–°–¢–†–´–ô TradingView-—Å—Ç–∏–ª—å –≥—Ä–∞—Ñ–∏–∫ —Å–æ —Å–≤–µ—á–∞–º–∏ (1-2 —Å–µ–∫—É–Ω–¥—ã)"""
    
    try:
        if df is None or len(df) < 100:
            return None

        # üî• –ü–†–û–í–ï–†–ö–ê –ö–≠–®–ê –í –ü–ê–ú–Ø–¢–ò
        cache_key = f"{pair}_{direction}_{entry_price:.5f}"
        current_time = datetime.now()
        
        if cache_key in CHART_CACHE:
            cached_time, chart_bytes = CHART_CACHE[cache_key]
            if (current_time - cached_time).total_seconds() < CACHE_EXPIRY:
                logging.info(f"üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –∏–∑ –ø–∞–º—è—Ç–∏ –¥–ª—è {pair}")
                chart_stream = BytesIO(chart_bytes)
                chart_stream.name = f"chart_{pair}.png"
                return chart_stream

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 80 —Å–≤–µ—á–µ–π –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        df_plot = df.tail(80).copy()
        
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        plt.style.use('dark_background')
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), 
                                      gridspec_kw={'height_ratios': [3, 1]})
        fig.patch.set_facecolor('#0a1120')
        
        # ======== –°–í–ï–ß–ù–û–ô –ì–†–ê–§–ò–ö ========
        # –¶–≤–µ—Ç–∞ TradingView
        green_color = '#00ff88'  # –ë—ã—á–∏–π
        red_color = '#ff4444'    # –ú–µ–¥–≤–µ–∂–∏–π
        
        # –†–∏—Å—É–µ–º —Å–≤–µ—á–∏ –≤—Ä—É—á–Ω—É—é
        for i in range(len(df_plot)):
            open_price = df_plot['open'].iloc[i]
            close_price = df_plot['close'].iloc[i]
            high_price = df_plot['high'].iloc[i]
            low_price = df_plot['low'].iloc[i]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç —Å–≤–µ—á–∏
            color = green_color if close_price >= open_price else red_color
            alpha = 0.8
            
            # –¢–µ–ª–æ —Å–≤–µ—á–∏
            body_bottom = min(open_price, close_price)
            body_top = max(open_price, close_price)
            body_height = body_top - body_bottom
            
            if body_height > 0:
                ax1.bar(i, body_height, bottom=body_bottom, color=color, alpha=alpha, width=0.8)
            
            # –¢–µ–Ω–∏ —Å–≤–µ—á–∏
            ax1.plot([i, i], [low_price, body_bottom], color=color, linewidth=1, alpha=alpha)
            ax1.plot([i, i], [body_top, high_price], color=color, linewidth=1, alpha=alpha)
        
        # SMA20
        sma20 = df_plot['close'].rolling(20).mean()
        ax1.plot(range(len(sma20)), sma20, color='#ffaa00', linewidth=2, label='SMA 20', alpha=0.9)
        
        # ======== –ö–õ–Æ–ß–ï–í–´–ï –õ–ò–ù–ò–ò ========
        # –õ–∏–Ω–∏—è –≤—Ö–æ–¥–∞ (–±–µ–ª–∞—è –ø—É–Ω–∫—Ç–∏—Ä–Ω–∞—è)
        ax1.axhline(y=entry_price, color='white', linestyle='--', 
                   linewidth=2, label=f'Entry: {entry_price:.5f}')
        
        # –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞ (–≥–æ–ª—É–±–∞—è —Ç–æ—á–µ—á–Ω–∞—è)
        current_price = df_plot['close'].iloc[-1]
        ax1.axhline(y=current_price, color='#00ffff', linestyle=':', 
                   linewidth=1.5, label=f'Current: {current_price:.5f}')
        
        # ======== –û–§–û–†–ú–õ–ï–ù–ò–ï ========
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –®–†–ò–§–¢–û–í - —É–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        title_text = f"{pair} - SMART MONEY - {direction}"
        ax1.set_title(title_text, color='white', fontsize=16, fontweight='bold', pad=20)
        
        ax1.legend(loc='upper left', facecolor='#1e2a3a')
        ax1.grid(True, alpha=0.3, color='#1e2a3a')
        ax1.set_facecolor('#0a1120')
        ax1.tick_params(colors='white')
        
        # ======== –û–ë–™–ï–ú–´ ========
        if 'volume' in df_plot.columns or 'tick_volume' in df_plot.columns:
            volumes = df_plot['volume'] if 'volume' in df_plot.columns else df_plot['tick_volume']
            
            # –¶–≤–µ—Ç–∞ –æ–±—ä–µ–º–æ–≤ –∫–∞–∫ –≤ TradingView (–∑–µ–ª–µ–Ω—ã–π/–∫—Ä–∞—Å–Ω—ã–π)
            volume_colors = []
            for i in range(len(df_plot)):
                if df_plot['close'].iloc[i] >= df_plot['open'].iloc[i]:
                    volume_colors.append(green_color)
                else:
                    volume_colors.append(red_color)
            
            ax2.bar(range(len(volumes)), volumes, color=volume_colors, alpha=0.7)
        
        ax2.set_ylabel('Volume', color='white')
        ax2.grid(True, alpha=0.3, color='#1e2a3a')
        ax2.set_facecolor('#0a1120')
        ax2.tick_params(colors='white')
        
        # ======== –ò–ù–§–û-–ü–ê–ù–ï–õ–¨ ========
        trend_analysis = enhanced_trend_analysis(df)
        info_bg = '#00cc66' if direction == 'BUY' else '#ff4444'
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –®–†–ò–§–¢–û–í - –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤
        info_text = (f"PRICE: {current_price:.5f}\n"
                    f"TREND: {trend_analysis['direction']}\n"
                    f"STRENGTH: {trend_analysis['strength']}\n"
                    f"SIGNAL: {direction}")
        
        ax1.text(0.02, 0.98, info_text, transform=ax1.transAxes, 
                fontsize=10, verticalalignment='top', color='white',
                bbox=dict(boxstyle='round', facecolor=info_bg, alpha=0.9, edgecolor='white'))

        plt.tight_layout()
        
        # ======== –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ü–ê–ú–Ø–¢–¨ ========
        chart_stream = BytesIO()
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –®–†–ò–§–¢–û–í - —É–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        plt.savefig(chart_stream, format='png', dpi=100, bbox_inches='tight', 
                   facecolor='#0a1120', edgecolor='none')
        plt.close()
        
        chart_bytes = chart_stream.getvalue()
        
        # üî• –°–û–•–†–ê–ù–Ø–ï–ú –í –ö–≠–® –ü–ê–ú–Ø–¢–ò
        CHART_CACHE[cache_key] = (current_time, chart_bytes)
        
        # üî• –°–û–ó–î–ê–ï–ú –ù–û–í–´–ô BytesIO –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
        chart_stream = BytesIO(chart_bytes)
        chart_stream.name = f"chart_{pair}.png"
        
        logging.info(f"‚ö° –ë–´–°–¢–†–´–ô –≥—Ä–∞—Ñ–∏–∫ —Å–æ–∑–¥–∞–Ω –≤ –ø–∞–º—è—Ç–∏: {pair} (1-2 —Å–µ–∫)")
        return chart_stream
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ã—Å—Ç—Ä–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞: {e}")
        return None

# ===================== GLOBAL SIGNAL VARIABLES =====================
CURRENT_SIGNAL = None
CURRENT_SIGNAL_TIMESTAMP = None
SIGNAL_EXPIRY_MINUTES = 2  # –°–∏–≥–Ω–∞–ª –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω 2 –º–∏–Ω—É—Ç—ã

from datetime import datetime  # –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —ç—Ç–æ—Ç –∏–º–ø–æ—Ä—Ç –µ—Å—Ç—å –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞

# ===================== AUTO TRADING LOOP - –§–ò–ù–ê–õ =====================
async def auto_trading_loop(context: ContextTypes.DEFAULT_TYPE):
    """–§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ —Ü–∏–∫–ª–∞ —Å –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–ô –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –±–æ—Ç–∞"""
    start_time = datetime.now()  # ‚è±Ô∏è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –î–û–ë–ê–í–ò–¢–¨ –≠–¢–£ –°–¢–†–û–ö–£ –í –ù–ê–ß–ê–õ–û –§–£–ù–ö–¶–ò–ò
    
    try:
        logging.info("üîÑ ===== –ó–ê–ü–£–°–ö –ê–í–¢–û-–¢–†–ï–ô–î–ò–ù–ì –¶–ò–ö–õ–ê =====")

        # üïí –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞
        if not is_trading_time():
            logging.info("‚è∏ –í–Ω–µ —Ä–∞–±–æ—á–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –±–æ—Ç–∞ ‚Äî —Ü–∏–∫–ª –ø—Ä–æ–ø—É—â–µ–Ω")
            return

        # üì• –ó–∞–≥—Ä—É–∂–∞–µ–º / –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        logging.info(f"üë• –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(users)}")

        if not users or len(users) == 0:
            logging.warning("‚ö† –ë–∞–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø—É—Å—Ç–∞")
            return

        # üöÄ –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        tasks = []
        user_tasks = []

        for user_id, user_data in users.copy().items():
            try:
                uid = int(user_id)
                auto_trading = user_data.get('auto_trading', False)
                
                if not auto_trading:
                    logging.info(f"‚è∏ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {uid}: –∞–≤—Ç–æ-—Ç—Ä–µ–π–¥–∏–Ω–≥ –æ—Ç–∫–ª—é—á—ë–Ω")
                    continue
                    
                logging.info(f"üöÄ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {uid}: –¥–æ–±–∞–≤–ª—è–µ–º –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
                # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                task = asyncio.create_task(
                    process_auto_trade_for_user(uid, user_data, context),
                    name=f"user_{uid}"
                )
                tasks.append(task)
                user_tasks.append(uid)

            except Exception as user_err:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {user_err}", exc_info=True)

        # üî• –ó–ê–ü–£–°–ö –í–°–ï–• –ó–ê–î–ê–ß –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û
        processed_users = 0
        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_tasks[i]}: {result}")
                else:
                    processed_users += 1

        logging.info(f"‚úÖ –ê–í–¢–û-–¢–†–ï–ô–î–ò–ù–ì –¶–ò–ö–õ –ó–ê–í–ï–†–®–ï–ù. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {processed_users}/{len(users)}")

    except Exception as e:
        logging.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∞–≤—Ç–æ-—Ç—Ä–µ–π–¥–∏–Ω–≥–∞: {e}", exc_info=True)
    
    finally:
        execution_time = (datetime.now() - start_time).total_seconds()
        logging.info(f"‚è±Ô∏è –ê–≤—Ç–æ-—Ç—Ä–µ–π–¥–∏–Ω–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {execution_time:.1f} —Å–µ–∫")

# ===================== TRADE RESULT CHECKER =====================
async def check_trade_result(context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏ –∏ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç –µ—ë —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –∏—Å—Ç–æ—Ä–∏–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    try:
        job_data = context.job.data
        user_id = job_data['user_id']
        pair = job_data['pair']
        trade_id = job_data['trade_id']

        logging.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–¥–µ–ª–∫–∏ #{trade_id} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}, –ø–∞—Ä–∞: {pair}")

        user_data = get_user_data(user_id)
        if not user_data:
            logging.error(f"‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return

        current_trade = user_data.get('current_trade')
        if not current_trade:
            logging.warning(f"‚ö†Ô∏è –£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–¥–µ–ª–∫–∏")
            return

        if current_trade.get('id') != trade_id:
            logging.warning(f"‚ö†Ô∏è ID —Å–¥–µ–ª–∫–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –æ–∂–∏–¥–∞–ª–∏ {trade_id}, –ø–æ–ª—É—á–∏–ª–∏ {current_trade.get('id')}")
            return

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É
        df = get_mt5_data(pair, 2, mt5.TIMEFRAME_M1)
        if df is None or len(df) < 1:
            logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {pair}")
            return

        current_price = df['close'].iloc[-1]
        entry_price = current_trade['entry_price']
        direction = current_trade['direction']

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏
        if direction == 'BUY':
            result = 'WIN' if current_price > entry_price else 'LOSS'
        else:  # SELL
            result = 'WIN' if current_price < entry_price else 'LOSS'

        # –°—É–º–º–∞ —Å—Ç–∞–≤–∫–∏
        stake = current_trade.get('stake', STAKE_AMOUNT)
        profit = WIN_PROFIT if result == 'WIN' else -stake

        # ‚úÖ –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –∑–∞–ø–∏—Å—å —Å–¥–µ–ª–∫–∏
        closed_trade = {
            'id': trade_id,
            'pair': pair,
            'direction': direction,
            'entry_price': entry_price,
            'exit_price': current_price,
            'stake': stake,
            'stake_used': stake,
            'timestamp': current_trade.get('timestamp', datetime.now().isoformat()),
            'completed_at': datetime.now().isoformat(),
            'result': result,
            'profit': profit,
            'confidence': current_trade.get('confidence', 0),
            'source': current_trade.get('source', 'UNKNOWN'),
            'expiry_minutes': current_trade.get('expiry_minutes', 1),
            'ml_features': current_trade.get('ml_features', None)
        }

        # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º —Å–¥–µ–ª–∫—É –≤ –∏—Å—Ç–æ—Ä–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if 'trade_history' not in user_data:
            user_data['trade_history'] = []

        user_data['trade_history'].append(closed_trade)
        user_data['trade_counter'] = len(user_data['trade_history'])

        # ‚úÖ –û—á–∏—â–∞–µ–º —Ç–µ–∫—É—â—É—é –∞–∫—Ç–∏–≤–Ω—É—é —Å–¥–µ–ª–∫—É
        user_data['current_trade'] = None

        # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        save_users_data()

        # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º —Å–¥–µ–ª–∫—É –≤ —Ñ–∞–π–ª –∏—Å—Ç–æ—Ä–∏–∏ (–µ—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –µ—Å—Ç—å)
        try:
            log_trade_to_file(closed_trade, result)
        except Exception as e:
            logging.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–¥–µ–ª–∫–∏ –≤ —Ñ–∞–π–ª: {e}")

        # üìù –ü–æ–¥—Å—á—ë—Ç —Ç–µ–∫—É—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏
        total = len(user_data['trade_history'])
        wins = sum(1 for t in user_data['trade_history'] if t.get('result') == 'WIN')
        losses = sum(1 for t in user_data['trade_history'] if t.get('result') == 'LOSS')
        win_rate = round(wins / total * 100, 1) if total > 0 else 0

        # üì¢ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        result_emoji = "üü¢" if result == "WIN" else "üî¥"
        result_text = (
            f"{result_emoji} –°–î–ï–õ–ö–ê #{trade_id} –ó–ê–í–ï–†–®–ï–ù–ê\n\n"
            f"üíº –ü–∞—Ä–∞: {pair}\n"
            f"üìä –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {direction}\n"
            f"üí∞ –í—Ö–æ–¥: {entry_price:.5f}\n"
            f"üí∞ –í—ã—Ö–æ–¥: {current_price:.5f}\n"
            f"üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}\n\n"
            f"üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"
            f"‚Ä¢ –í—Å–µ–≥–æ: {total}\n"
            f"‚Ä¢ üü¢ –í—ã–∏–≥—Ä—ã—à–∏: {wins}\n"
            f"‚Ä¢ üî¥ –ü—Ä–æ–∏–≥—Ä—ã—à–∏: {losses}\n"
            f"‚Ä¢ üéØ Win Rate: {win_rate}%"
        )

        try:
            await context.bot.send_message(
                chat_id=user_id,
                text=result_text,
                reply_markup=get_trading_keyboard(user_id)
            )
            logging.info(f"‚úÖ –°–¥–µ–ª–∫–∞ #{trade_id} –∑–∞–∫—Ä—ã—Ç–∞: {result}")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")

    except Exception as e:
        logging.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ check_trade_result: {e}", exc_info=True)
# ===================== ü§ñ PROCESS AUTO TRADE =====================
async def process_auto_trade_for_user(user_id: int, user_data: Dict, context: ContextTypes.DEFAULT_TYPE):
    """–ê–≤—Ç–æ-—Ç—Ä–µ–π–¥–∏–Ω–≥: –∞–Ω–∞–ª–∏–∑, –æ—Ç–∫—Ä—ã—Ç–∏–µ —Å–¥–µ–ª–∫–∏ –∏ –æ—Ç–ª–æ–∂–µ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å –ø–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è"""
    try:
        # ‚è∏ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –±–æ—Ç–∞
        if not is_trading_time():
            logging.info(f"‚è∏ –í–Ω–µ —Ä–∞–±–æ—á–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ ‚Äî –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id}, —Ü–∏–∫–ª –ø—Ä–æ–ø—É—â–µ–Ω")
            return

        # ‚è∏ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É–∂–µ –æ—Ç–∫—Ä—ã—Ç—É—é —Å–¥–µ–ª–∫—É
        if user_data.get('current_trade'):
            logging.info(f"‚è∏ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} —É–∂–µ –∏–º–µ–µ—Ç –æ—Ç–∫—Ä—ã—Ç—É—é —Å–¥–µ–ª–∫—É ‚Äî –ø—Ä–æ–ø—É—Å–∫")
            return

        logging.info(f"üöÄ [AUTO] –°—Ç–∞—Ä—Ç –∞–≤—Ç–æ–∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è user_id={user_id}")
        random.shuffle(PAIRS)

        for pair in PAIRS:
            start_time = datetime.now()
            result = analyze_pair(pair)
            if not result or len(result) < 4:
                continue

            signal, expiry, conf, source = result[:4]

            # üéØ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–ª–∞–±—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
            if not signal or conf < 6:
                continue

            # üìä –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å MT5
            df = get_mt5_data(pair, 300, mt5.TIMEFRAME_M1)
            if df is None or len(df) < 50:
                continue

            entry_price = df['close'].iloc[-1]
            trade_number = user_data['trade_counter'] + 1
            ml_features_dict = prepare_ml_features(df) or {}

            # üìù –¢–µ–∫—Å—Ç —Å–∏–≥–Ω–∞–ª–∞
            signal_text = (
                f"üéØ –°–î–ï–õ–ö–ê #{trade_number}\n"
                f"ü§ñ –ê–í–¢–û-–¢–†–ï–ô–î–ò–ù–ì –°–ò–ì–ù–ê–õ\n"
                f"üíº –ü–∞—Ä–∞: `{pair}`\n"
                f"üìä –°–∏–≥–Ω–∞–ª: {signal}\n"
                f"üí∞ –¶–µ–Ω–∞ –≤—Ö–æ–¥–∞: {entry_price:.5f}\n"
                f"‚è∞ –≠–∫—Å–ø–∏—Ä–∞—Ü–∏—è: {expiry} –º–∏–Ω\n"
                f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf}/10\n"
                f"üîç –ò—Å—Ç–æ—á–Ω–∏–∫: {source}\n\n"
                f"–°–¥–µ–ª–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∞! –†–µ–∑—É–ª—å—Ç–∞—Ç —á–µ—Ä–µ–∑ {expiry} –º–∏–Ω—É—Ç..."
            )

            # üìà –û—Ç–ø—Ä–∞–≤–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –ò–ó –ü–ê–ú–Ø–¢–ò (BytesIO)
            chart_stream = enhanced_plot_chart(df, pair, entry_price, signal)
            user_markup = get_trading_keyboard(user_id)
            try:
                if chart_stream:
                    # üî• –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –û–¢–ü–†–ê–í–ö–ê BytesIO –ò–ó –ü–ê–ú–Ø–¢–ò
                    await context.bot.send_photo(
                        chat_id=user_id, 
                        photo=chart_stream,  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º BytesIO –Ω–∞–ø—Ä—è–º—É—é
                        caption=signal_text, 
                        reply_markup=user_markup
                    )
                    # üî• –ù–ï –ù–£–ñ–ù–û –£–î–ê–õ–Ø–¢–¨ –§–ê–ô–õ - –µ–≥–æ –Ω–µ—Ç!
                    logging.info(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –∏–∑ –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}")
                else:
                    await context.bot.send_message(chat_id=user_id, text=signal_text, reply_markup=user_markup)
            except Exception as tg_err:
                logging.error(f"‚ö† –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–∏–≥–Ω–∞–ª–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {tg_err}")

            # üìå –°–¥–µ–ª–∫–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –¢–û–õ–¨–ö–û –∫–∞–∫ —Ç–µ–∫—É—â–∞—è
            trade = {
                'id': trade_number,
                'pair': pair,
                'direction': signal,
                'entry_price': float(entry_price),
                'expiry_minutes': int(expiry),
                'stake': float(STAKE_AMOUNT),
                'timestamp': datetime.now().isoformat(),
                'ml_features': ml_features_dict,
                'source': source,
                'confidence': int(conf)
            }

            user_data['current_trade'] = trade
            user_data['trade_counter'] += 1
            save_users_data()
            logging.info(f"üìå –¢–µ–∫—É—â–∞—è —Å–¥–µ–ª–∫–∞ #{trade_number} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (–∏—Å—Ç–æ—Ä–∏—è ‚Äî –ø–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è)")

            # ‚è± –ü–ª–∞–Ω–∏—Ä—É–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å–¥–µ–ª–∫–∏
            check_delay = (expiry * 60) + 5
            context.job_queue.run_once(
                check_trade_result,
                check_delay,
                data={'user_id': user_id, 'pair': pair, 'trade_id': trade_number}
            )

            logging.info(f"üïí –ü–ª–∞–Ω –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–¥–µ–ª–∫–∏ #{trade_number} —á–µ—Ä–µ–∑ {check_delay} —Å–µ–∫")
            elapsed = (datetime.now() - start_time).total_seconds()
            logging.info(f"‚úÖ –°–¥–µ–ª–∫–∞ #{trade_number} ({pair} {signal}) –æ—Ç–∫—Ä—ã—Ç–∞ –∑–∞ {elapsed:.2f} —Å–µ–∫")

            # üõë –û–¥–Ω–∞ —Å–¥–µ–ª–∫–∞ –∑–∞ —Ü–∏–∫–ª
            return

        logging.info(f"üèÅ [AUTO] –ê–Ω–∞–ª–∏–∑ –¥–ª—è user_id={user_id} –∑–∞–≤–µ—Ä—à—ë–Ω –±–µ–∑ –æ—Ç–∫—Ä—ã—Ç–∏—è —Å–¥–µ–ª–æ–∫")

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ process_auto_trade_for_user: {e}", exc_info=True)
        
# ===================== TELEGRAM COMMANDS =====================
# -------- WHITELIST MANAGEMENT COMMANDS --------
async def whitelist_add_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω)"""
    user_id = update.effective_user.id
    
    if not is_admin(user_id):
        await update.message.reply_text("‚ùå –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤")
        return
        
    if not context.args or len(context.args) < 2:
        await update.message.reply_text(
            "üìù –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n"
            "/whitelist_add <pocket_id> <–∏–º—è> [role=user]\n\n"
            "–ü—Ä–∏–º–µ—Ä:\n"
            "/whitelist_add 12345678 \"–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤\"\n"
            "/whitelist_add 87654321 \"–ú–∞—Ä–∏—è\" admin"
        )
        return
        
    pocket_id = context.args[0]
    name = context.args[1]
    role = context.args[2] if len(context.args) > 2 else "user"
    
    success, message = add_user_to_whitelist(pocket_id, name, role=role)
    
    if success:
        await update.message.reply_text(f"‚úÖ {message}")
    else:
        await update.message.reply_text(f"‚ùå {message}")

async def whitelist_remove_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–£–¥–∞–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –±–µ–ª–æ–≥–æ —Å–ø–∏—Å–∫–∞ (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω)"""
    user_id = update.effective_user.id
    
    if not is_admin(user_id):
        await update.message.reply_text("‚ùå –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤")
        return
        
    if not context.args:
        await update.message.reply_text(
            "üìù –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n"
            "/whitelist_remove <pocket_id>\n\n"
            "–ü—Ä–∏–º–µ—Ä:\n"
            "/whitelist_remove 12345678"
        )
        return
        
    pocket_id = context.args[0]
    success, message = remove_user_from_whitelist(pocket_id)
    
    if success:
        await update.message.reply_text(f"‚úÖ {message}")
    else:
        await update.message.reply_text(f"‚ùå {message}")

async def whitelist_stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–µ–ª–æ–≥–æ —Å–ø–∏—Å–∫–∞"""
    stats = get_whitelist_stats()
    
    await update.message.reply_text(
        f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–µ–ª–æ–≥–æ —Å–ø–∏—Å–∫–∞**\n\n"
        f"üë• –í—Å–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: `{stats['total_users']}`\n"
        f"üõ°Ô∏è –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤: `{stats['admins']}`\n"
        f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: `{stats['users']}`\n"
        f"üü¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö: `{stats['active_users']}`",
        parse_mode='Markdown'
    )

async def whitelist_show_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –±–µ–ª–æ–º —Å–ø–∏—Å–∫–µ (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω)"""
    user_id = update.effective_user.id
    
    if not is_admin(user_id):
        await update.message.reply_text("‚ùå –¢–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤")
        return
        
    whitelist = load_whitelist()
    
    if not whitelist:
        await update.message.reply_text("üìù –ë–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
        return
        
    message = "üìã **–ë–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π:**\n\n"
    
    for pocket_id, user_data in whitelist.items():
        role_icon = "üõ°Ô∏è" if user_data.get('role') == 'admin' else "üë§"
        message += f"{role_icon} `{pocket_id}` - {user_data['name']}\n"
        
        if user_data.get('telegram_id'):
            message += f"   üì± TG: {user_data['telegram_id']}\n"
            
        message += f"   üìÖ {user_data.get('registered_at', 'Unknown')[:10]}\n\n"
    
    await update.message.reply_text(message, parse_mode='Markdown')

# -------- BOT STATUS NOTIFICATIONS --------
async def send_bot_status_notification(context: ContextTypes.DEFAULT_TYPE):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ –±–æ—Ç–∞ –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º"""
    global BOT_LAST_STATUS, BOT_STATUS_NOTIFIED
    
    try:
        if BOT_STATUS_NOTIFIED:
            return  # –£–∂–µ —É–≤–µ–¥–æ–º–∏–ª–∏
            
        now = datetime.now()
        current_time = now.time()
        current_weekday = now.weekday()
        weekday_name = ['–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫', '–í—Ç–æ—Ä–Ω–∏–∫', '–°—Ä–µ–¥–∞', '–ß–µ—Ç–≤–µ—Ä–≥', '–ü—è—Ç–Ω–∏—Ü–∞', '–°—É–±–±–æ—Ç–∞', '–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ'][current_weekday]
        
        if BOT_LAST_STATUS:  # –ë–æ—Ç –Ω–∞—á–∞–ª —Ä–∞–±–æ—Ç—É
            message = (
                "üöÄ **–ë–û–¢ –ù–ê–ß–ê–õ –†–ê–ë–û–¢–£!**\n\n"
                f"üïê –í—Ä–µ–º—è: {now.strftime('%H:%M:%S')}\n"
                f"üìÖ –î–µ–Ω—å: {weekday_name}\n\n"
                "ü§ñ –ê–≤—Ç–æ-—Ç—Ä–µ–π–¥–∏–Ω–≥ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω\n"
                "üìä –ü–æ–∏—Å–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –∑–∞–ø—É—â–µ–Ω\n"
                "üéØ –ì–æ—Ç–æ–≤ –∫ —Ç–æ—Ä–≥–æ–≤–ª–µ!"
            )
            
        else:  # –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è
            # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∏—è
            if current_weekday in WEEKEND_DAYS:
                days_until_monday = (7 - current_weekday) % 7
                next_work_day = now + timedelta(days=days_until_monday)
                next_open = datetime.combine(next_work_day.date(), TRADING_START)
                reason = "–≤—ã—Ö–æ–¥–Ω–æ–π –¥–µ–Ω—å"
            else:
                next_open = datetime.combine(now.date() + timedelta(days=1), TRADING_START)
                reason = "–æ–∫–æ–Ω—á–∞–Ω–∏–µ —Ä–∞–±–æ—á–µ–≥–æ –¥–Ω—è"
            
            time_until = next_open - now
            hours = time_until.seconds // 3600
            minutes = (time_until.seconds % 3600) // 60
            
            message = (
                "‚è∏ **–ë–û–¢ –û–°–¢–ê–ù–û–í–õ–ï–ù**\n\n"
                f"üïê –í—Ä–µ–º—è: {now.strftime('%H:%M:%S')}\n"
                f"üìÖ –î–µ–Ω—å: {weekday_name}\n"
                f"üìã –ü—Ä–∏—á–∏–Ω–∞: {reason}\n\n"
                f"üîÑ **–í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã:**\n"
                f"‚è∞ {next_open.strftime('%d.%m.%Y –≤ %H:%M')}\n"
                f"‚è≥ –ß–µ—Ä–µ–∑: {hours}—á {minutes}–º–∏–Ω\n\n"
                "üìä –¢–æ—Ä–≥–æ–≤–ª—è –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –¥–æ —É—Ç—Ä–∞"
            )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Å –∞–≤—Ç–æ-—Ç—Ä–µ–π–¥–∏–Ω–≥–æ–º
        notified_users = 0
        for user_id, user_data in users.items():
            try:
                if user_data.get('auto_trading', False):
                    await context.bot.send_message(
                        chat_id=user_id,
                        text=message,
                        parse_mode='Markdown',
                        reply_markup=main_markup
                    )
                    notified_users += 1
                    
                    # –ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    if BOT_LAST_STATUS:
                        welcome_text = (
                            f"üëã –° –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ–º! –†–∞–±–æ—á–∏–π –¥–µ–Ω—å –Ω–∞—á–∞–ª—Å—è.\n\n"
                            f"üìä –°—Ç–∞—Ç—É—Å: üü¢ –ê–ö–¢–ò–í–ï–ù\n"
                            f"ü§ñ –ê–≤—Ç–æ-—Ç—Ä–µ–π–¥–∏–Ω–≥: {'üü¢ –í–ö–õ' if user_data.get('auto_trading', False) else 'üî¥ –í–´–ö–õ'}\n"
                            f"üéØ –†–µ–∂–∏–º: –ü–æ–∏—Å–∫ —Å–∏–≥–Ω–∞–ª–æ–≤"
                        )
                        await context.bot.send_message(
                            chat_id=user_id,
                            text=welcome_text,
                            reply_markup=get_trading_keyboard(user_id)
                        )
                        
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        
        BOT_STATUS_NOTIFIED = True
        logging.info(f"üîî –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ —Å—Ç–∞—Ç—É—Å–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã {notified_users} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º")
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ —Å—Ç–∞—Ç—É—Å–µ: {e}")

# -------- START & STATUS --------
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –ø–æ–∫–∞–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é"""
    user = update.effective_user
    user_id = user.id

    user_data = get_user_data(user_id)
    user_data['first_name'] = user.first_name or ""
    user_data['username'] = user.username or ""

    # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    history = user_data.get('trade_history', [])
    finished_trades = [t for t in history if t.get('result') in ("WIN", "LOSS")]
    total = len(finished_trades)
    wins = len([t for t in finished_trades if t.get('result') == "WIN"])
    winrate = round(wins / total * 100, 1) if total > 0 else 0

    welcome_text = (
        f"üëã –ü—Ä–∏–≤–µ—Ç, {user.first_name}!\n\n"
        f"ü§ñ –Ø ‚Äî AI Trading Bot —Å —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–µ–π Smart Money Concepts.\n\n"
        f"üìä –ú–æ–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\n"
        f"‚Ä¢ Smart Money –∞–Ω–∞–ª–∏–∑ (SMC)\n"
        f"‚Ä¢ –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (ML)\n"
        f"‚Ä¢ GPT-–∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞\n"
        f"‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è\n"
        f"‚Ä¢ –ü–æ–¥—Ä–æ–±–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏\n\n"
        f"üìà –°–¥–µ–ª–æ–∫: {total}\n"
        f"üéØ Win Rate: {winrate}%\n\n"
        f"üìã –ò—Å–ø–æ–ª—å–∑—É–π –∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é –Ω–∏–∂–µ üëá"
    )

    await update.message.reply_text(welcome_text, reply_markup=main_markup)
    save_users_data()
async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global users
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π —Å—Ç–∞—Ç—É—Å"""
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)

    if ml_model and model_info and not model_info.get("error"):
        acc = model_info.get("accuracy")
        if isinstance(acc, (int, float)):
            ml_status = f"‚úÖ –û–±—É—á–µ–Ω–∞ ({model_info.get('trades_used', '?')} —Å–¥–µ–ª–æ–∫, {acc*100:.1f}%)"
        else:
            ml_status = f"‚úÖ –û–±—É—á–µ–Ω–∞ ({model_info.get('trades_used', '?')} —Å–¥–µ–ª–æ–∫)"
    else:
        error_msg = model_info.get("error", "–ù–µ –æ–±—É—á–µ–Ω–∞") if model_info else "–ù–µ –æ–±—É—á–µ–Ω–∞"
        ml_status = f"‚ö† {error_msg}"

    personal_stake = user_data.get('personal_stake', STAKE_AMOUNT)
    personal_profit = round(personal_stake * 0.8)

    status_text = (
         f"üìä –°–¢–ê–¢–£–° –°–ò–°–¢–ï–ú–´\n\n"
         f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_data['first_name']}\n"
         f"üìà –°–¥–µ–ª–æ–∫: {user_data['trade_counter']}\n"
         f"ü§ñ –ê–≤—Ç–æ-—Ç—Ä–µ–π–¥–∏–Ω–≥: {'‚úÖ –í–ö–õ' if user_data.get('auto_trading', False) else '‚ö† –í–´–ö–õ'}\n\n"
         f"üåê –†–µ–∂–∏–º: {'–ú—É–ª—å—Ç–∏–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π' if MULTI_USER_MODE else '–û–¥–Ω–æ–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π'}\n"
         f"üì° MT5: {'‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω' if mt5.terminal_info() else '‚ö† –û—Ç–∫–ª—é—á–µ–Ω'}\n"
         f"üß† ML: {ml_status}\n"
         f"ü§ñ GPT: {'‚úÖ –ê–∫—Ç–∏–≤–µ–Ω' if USE_GPT else '‚ö† –í—ã–∫–ª—é—á–µ–Ω'}"
    )

    await update.message.reply_text(status_text, reply_markup=main_markup)

# -------- –ù–û–í–ê–Ø –ö–û–ú–ê–ù–î–ê –†–ê–°–ü–ò–°–ê–ù–ò–Ø --------
async def schedule_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞"""
    now = datetime.now()
    current_time = now.time()
    current_weekday = now.weekday()
    weekday_name = ['–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫', '–í—Ç–æ—Ä–Ω–∏–∫', '–°—Ä–µ–¥–∞', '–ß–µ—Ç–≤–µ—Ä–≥', '–ü—è—Ç–Ω–∏—Ü–∞', '–°—É–±–±–æ—Ç–∞', '–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ'][current_weekday]
    
    is_working_time = is_trading_time()
    status = "üü¢ –†–ê–ë–û–¢–ê–ï–¢" if is_working_time else "üî¥ –û–¢–ö–õ–Æ–ß–ï–ù"
    
    # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∏—è
    if not is_working_time:
        if current_weekday in WEEKEND_DAYS:
            days_until_monday = (7 - current_weekday) % 7
            next_work_day = now + timedelta(days=days_until_monday)
            next_open = datetime.combine(next_work_day.date(), TRADING_START)
        elif current_time < TRADING_START:
            next_open = datetime.combine(now.date(), TRADING_START)
        else:
            next_open = datetime.combine(now.date() + timedelta(days=1), TRADING_START)
        
        time_until = next_open - now
        hours = time_until.seconds // 3600
        minutes = (time_until.seconds % 3600) // 60
        until_text = f"‚è∞ –î–æ –æ—Ç–∫—Ä—ã—Ç–∏—è: {hours}—á {minutes}–º–∏–Ω"
    else:
        time_until_close = datetime.combine(now.date(), TRADING_END) - now
        hours = time_until_close.seconds // 3600
        minutes = (time_until_close.seconds % 3600) // 60
        until_text = f"‚è∞ –î–æ –∑–∞–∫—Ä—ã—Ç–∏—è: {hours}—á {minutes}–º–∏–Ω"
    
    schedule_text = (
        f"üìÖ –†–ê–°–ü–ò–°–ê–ù–ò–ï –†–ê–ë–û–¢–´ –ë–û–¢–ê\n\n"
        f"üïê –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è: {now.strftime('%Y-%m-%d %H:%M:%S')}\n"
        f"üìÖ –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏: {weekday_name}\n"
        f"üìä –°—Ç–∞—Ç—É—Å: {status}\n"
        f"{until_text}\n\n"
        f"üïí –†–∞–±–æ—á–∏–µ —á–∞—Å—ã:\n"
        f"‚Ä¢ –ï–∂–µ–¥–Ω–µ–≤–Ω–æ: {TRADING_START.strftime('%H:%M')} - {TRADING_END.strftime('%H:%M')}\n"
        f"‚Ä¢ –í—ã—Ö–æ–¥–Ω—ã–µ: –°—É–±–±–æ—Ç–∞, –í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ\n\n"
        f"üåê –ß–∞—Å–æ–≤–æ–π –ø–æ—è—Å: –õ–æ–∫–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Å–∏—Å—Ç–µ–º—ã"
    )
    
    await update.message.reply_text(schedule_text)

# -------- –ò–°–¢–û–†–ò–Ø & –°–ò–ì–ù–ê–õ–´ --------
async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)

    history = user_data.get('trade_history', [])
    if not history:
        await update.message.reply_text("üì≠ –£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Å–¥–µ–ª–æ–∫.")
        return

    # ‚úÖ –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏
    finished_trades = [t for t in history if t.get('result') in ("WIN", "LOSS")]
    if not finished_trades:
        await update.message.reply_text("‚è≥ –£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫.")
        return

    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 ‚Äî –Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É
    last_trades = finished_trades[-10:]
    lines = ["üìà *–ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–¥–µ–ª–æ–∫:*", ""]
    for trade in reversed(last_trades):
        trade_id = trade.get('id', '?')
        date = trade.get('timestamp', '').replace("T", " ")[:16]
        pair = trade.get('pair', '?')
        direction = trade.get('direction', '?')
        result = trade.get('result', '')
        icon = "üü¢" if result == "WIN" else "üî¥"
        lines.append(f"#{trade_id} {date} {icon} {pair} {direction} | {result}")

    text = "\n".join(lines)
    await update.message.reply_text(text, parse_mode="Markdown")
    
async def next_signal_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∏—Å–∫ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–∏–≥–Ω–∞–ª–∞"""
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)

    # üïí –ü–†–û–í–ï–†–ö–ê –†–ê–ë–û–ß–ï–ì–û –í–†–ï–ú–ï–ù–ò –î–õ–Ø –†–£–ß–ù–´–• –°–ò–ì–ù–ê–õ–û–í
    if not is_trading_time():
        now = datetime.now()
        current_weekday = now.weekday()
        
        # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∏—è
        if current_weekday in WEEKEND_DAYS:
            days_until_monday = (7 - current_weekday) % 7
            next_work_day = now + timedelta(days=days_until_monday)
            next_open = datetime.combine(next_work_day.date(), TRADING_START)
            reason = "–≤—ã—Ö–æ–¥–Ω–æ–π –¥–µ–Ω—å"
        else:
            next_open = datetime.combine(now.date() + timedelta(days=1), TRADING_START)
            reason = "–æ–∫–æ–Ω—á–∞–Ω–∏–µ —Ä–∞–±–æ—á–µ–≥–æ –¥–Ω—è"
        
        time_until = next_open - now
        hours = time_until.seconds // 3600
        minutes = (time_until.seconds % 3600) // 60
        
        await update.message.reply_text(
            f"‚è∏ **–°–µ–π—á–∞—Å –Ω–µ—Ä–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è –±–æ—Ç–∞**\n\n"
            f"üìã –ü—Ä–∏—á–∏–Ω–∞: {reason}\n"
            f"üîÑ **–ë–æ—Ç –Ω–∞—á–Ω–µ—Ç —Ä–∞–±–æ—Ç—É:**\n"
            f"‚è∞ {next_open.strftime('%d.%m.%Y –≤ %H:%M')}\n"
            f"‚è≥ –ß–µ—Ä–µ–∑: {hours}—á {minutes}–º–∏–Ω\n\n"
            f"üïí –†–∞–±–æ—á–∏–µ —á–∞—Å—ã:\n"
            f"‚Ä¢ {TRADING_START.strftime('%H:%M')}-{TRADING_END.strftime('%H:%M')}\n"
            f"‚Ä¢ –ë–µ–∑ –≤—ã—Ö–æ–¥–Ω—ã—Ö (–∫—Ä–æ–º–µ —Å—É–±–±–æ—Ç—ã, –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å—è)",
            parse_mode='Markdown',
            reply_markup=get_trading_keyboard(user_id)
        )
        return
    if user_data.get('current_trade'):
        await update.message.reply_text(
            "‚è≥ –£ –≤–∞—Å —É–∂–µ –µ—Å—Ç—å –∞–∫—Ç–∏–≤–Ω–∞—è —Å–¥–µ–ª–∫–∞! –î–æ–∂–¥–∏—Ç–µ—Å—å –µ—ë –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.",
            reply_markup=get_trading_keyboard(user_id)
        )
        return

    await update.message.reply_text("üîç –ò—â—É –ª—É—á—à–∏–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã...", reply_markup=get_trading_keyboard(user_id))

    random.shuffle(PAIRS)

    for pair in PAIRS:

        # ‚è∞ –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º —á–∞—Å–∞–º –∏–∑ time_filters.json
        if not is_trade_allowed(pair):
            logging.info(f"‚è∞ –ü—Ä–æ–ø—É—Å–∫ {pair} ‚Äî –Ω–µ—Ä–∞–∑—Ä–µ—à—ë–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ç–æ—Ä–≥–æ–≤–ª–∏ (—Ä—É—á–Ω–æ–π –ø–æ–∏—Å–∫ —Å–∏–≥–Ω–∞–ª–∞).")
            continue
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: —É–±—Ä–∞–ª–∏ user_id –∏–∑ –≤—ã–∑–æ–≤–∞
        result = analyze_pair(pair)
        if len(result) >= 4:
            signal, expiry, conf, source = result[:4]
            ml_features_data = result[4] if len(result) > 4 else None

            if signal and conf >= 6:
                df = get_mt5_data(pair, 2, mt5.TIMEFRAME_M1)
                if df is None:
                    continue

                entry_price = df['close'].iloc[-1]
                chart_df = get_mt5_data(pair, 300, mt5.TIMEFRAME_M1)
                chart_path = enhanced_plot_chart(chart_df, pair, entry_price, signal)

                signal_text = (
                    f"üéØ –¢–û–†–ì–û–í–´–ô –°–ò–ì–ù–ê–õ\n\n"
                    f"üíº –ü–∞—Ä–∞: `{pair}`\n"
                    f"üìä –°–∏–≥–Ω–∞–ª: {signal}\n"
                    f"üí∞ –¶–µ–Ω–∞ –≤—Ö–æ–¥–∞: {entry_price:.5f}\n"
                    f"‚è∞ –≠–∫—Å–ø–∏—Ä–∞—Ü–∏—è: {expiry} –º–∏–Ω\n"
                    f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf}/10\n"
                    f"üîç –ò—Å—Ç–æ—á–Ω–∏–∫: {source}"
                )

                if chart_path:
                    with open(chart_path, 'rb') as photo:
                        await update.message.reply_photo(photo=photo, caption=signal_text, reply_markup=get_trading_keyboard(user_id))
                    try:
                        os.remove(chart_path)
                    except:
                        pass
                else:
                    await update.message.reply_text(signal_text, reply_markup=get_trading_keyboard(user_id))

                context.user_data['last_signal'] = {
                    'pair': pair,
                    'signal': signal,
                    'entry_price': entry_price,
                    'expiry': expiry,
                    'ml_features': ml_features_data,
                    'source': source
                }
                return

    await update.message.reply_text("‚ö† –°–∏–≥–Ω–∞–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", reply_markup=get_trading_keyboard(user_id))


# -------- –°–¢–ê–¢–ò–°–¢–ò–ö–ê & –ú–û–î–ï–õ–ò --------
async def statistics_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º trade_history –∏–∑ user_data, –∞ –Ω–µ –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    history = user_data.get('trade_history', [])

    # ‚úÖ –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ —Å–¥–µ–ª–∫–∏ (WIN/LOSS)
    finished_trades = [t for t in history if t.get('result') in ("WIN", "LOSS")]

    total = len(finished_trades)
    wins = len([t for t in finished_trades if t.get('result') == "WIN"])
    losses = len([t for t in finished_trades if t.get('result') == "LOSS"])
    winrate = round(wins / total * 100, 1) if total > 0 else 0

    text = (
        "üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–û–†–ì–û–í–õ–ò\n\n"
        f"üìà –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {total}\n"
        f"üü¢ –í—ã–∏–≥—Ä—ã—à–∏: {wins}\n"
        f"üî¥ –ü—Ä–æ–∏–≥—Ä—ã—à–∏: {losses}\n"
        f"üéØ Win Rate: {winrate}%"
    )

    await update.message.reply_text(text)
    
async def model_stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É ML –º–æ–¥–µ–ª–∏, –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —á–∏—Ç–∞—è ml_info.json"""
    try:
        # –ü—Ä–æ–±—É–µ–º –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ ml_info.json
        info = {}
        if os.path.exists("ml_info.json"):
            with open("ml_info.json", "r", encoding="utf-8") as f:
                info = json.load(f)

            # ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –µ—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ (–∏—Å—Ç–æ—Ä–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–π), –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å
            if isinstance(info, list):
                info = info[-1] if info else {}
        else:
            info = model_info  # fallback –Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é

        if not info or info.get("error"):
            stats_text = "‚ùå ML –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞"
            if info and "error" in info:
                stats_text += f"\n–û—à–∏–±–∫–∞: {info['error']}"
        else:
            # üßÆ –ê–∫–∫—É—Ä–∞—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            trades_used = info.get("trades_used", 0)
            n_features = info.get("n_features", 0)
            trained_at = info.get("trained_at", "N/A")

            train_acc = info.get("train_accuracy", 0)
            test_acc = info.get("test_accuracy", 0)
            cv_acc = info.get("cv_accuracy", 0)
            cv_std = info.get("cv_std", 0)

            # –ï—Å–ª–∏ –≤–¥—Ä—É–≥ –ø—Ä–æ—Ü–µ–Ω—Ç—ã >1, –Ω–µ —É–º–Ω–æ–∂–∞–µ–º –µ—â—ë —Ä–∞–∑
            if train_acc > 1:
                train_acc = train_acc / 100
            if test_acc > 1:
                test_acc = test_acc / 100
            if cv_acc > 1:
                cv_acc = cv_acc / 100
            if cv_std > 1:
                cv_std = cv_std / 100

            win_rate = info.get("win_rate", 0)
            if win_rate > 1:
                win_rate = win_rate / 100

            overfit_ratio = 1.0
            if test_acc > 0:
                overfit_ratio = train_acc / test_acc

            train_samples = info.get("train_samples", 0)
            test_samples = info.get("test_samples", 0)

            stats_text = (
                f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê ML –ú–û–î–ï–õ–ò\n\n"
                f"üïê –û–±—É—á–µ–Ω–∞: {trained_at}\n"
                f"üìà –°–¥–µ–ª–æ–∫: {trades_used}\n"
                f"üß† –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {n_features}\n"
                f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å (—Ç–µ—Å—Ç): {test_acc*100:.2f}%\n"
                f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å (train): {train_acc*100:.2f}%\n"
                f"üìä Win rate: {win_rate*100:.2f}%\n"
                f"üîç –ö–æ—ç—Ñ. –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {overfit_ratio:.2f}\n"
                f"üìã –¢–µ—Å—Ç–æ–≤—ã—Ö: {test_samples}\n"
                f"üìö –û–±—É—á–∞—é—â–∏—Ö: {train_samples}\n"
                f"üéØ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: {cv_acc*100:.2f}% ¬± {cv_std*100:.2f}%"
            )

        await update.message.reply_text(
            stats_text,
            reply_markup=get_models_keyboard(update.effective_user.id)
        )
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ model_stats_command: {e}", exc_info=True)
        await update.message.reply_text(
            "‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–∏",
            reply_markup=get_models_keyboard(update.effective_user.id)
        )


async def retrain_model_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–µ—Ä–µ–æ–±—É—á–∞–µ—Ç ML –º–æ–¥–µ–ª—å (–¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É)"""
    user_id = update.effective_user.id

    # üß© –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞
    if MULTI_USER_MODE and not is_admin(user_id):
        await update.message.reply_text(
            "‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.",
            reply_markup=get_models_keyboard(user_id)
        )
        return

    # üîÑ –°–æ–æ–±—â–µ–Ω–∏–µ –æ —Å—Ç–∞—Ä—Ç–µ –æ–±—É—á–µ–Ω–∏—è
    await update.message.reply_text(
        "üîÑ –ó–∞–ø—É—Å–∫–∞—é –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.",
        reply_markup=get_models_keyboard(user_id)
    )

    try:
        # üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
        result = train_ml_model()

        # ‚úÖ –£–°–ü–ï–®–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï
        if result and not result.get("error"):
            test_acc = result.get("test_accuracy", 0)
            cv_accuracy = result.get("cv_accuracy", 0)
            trades_used = result.get("trades_used", 0)
            overfit = result.get("overfitting_ratio", 0)
            f1 = result.get("f1_score", 0)
            model_type = result.get("model_type", "N/A")

            # –ü—Ä–∏–≤–æ–¥–∏–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (–µ—Å–ª–∏ –Ω–µ 0‚Äì1)
            if test_acc <= 1:
                test_acc *= 100
            if cv_accuracy <= 1:
                cv_accuracy *= 100

            msg = (
                "‚úÖ ML –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞!\n"
                f"üìä –¢–æ—á–Ω–æ—Å—Ç—å (—Ç–µ—Å—Ç): {test_acc:.2f}%\n"
                f"üéØ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: {cv_accuracy:.2f}%\n"
                f"üìà –°–¥–µ–ª–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {trades_used}\n"
                f"üß† –¢–∏–ø –º–æ–¥–µ–ª–∏: {model_type}\n"
                f"üìä F1 Score: {f1:.2f}% | Overfit: {overfit:.2f}\n"
            )

            await update.message.reply_text(msg, reply_markup=get_models_keyboard(user_id))
            logging.info(f"[ML] ‚úÖ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞: Test={test_acc:.2f}% CV={cv_accuracy:.2f}%")

        # ‚ö†Ô∏è –û–ë–†–ê–ë–û–¢–ö–ê –û–®–ò–ë–û–ö
        else:
            error_msg = result.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if result else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
            await update.message.reply_text(
                f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {error_msg}",
                reply_markup=get_models_keyboard(user_id)
            )
            logging.error(f"[ML] ‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {error_msg}")

    except Exception as e:
        # üß® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê
        logging.exception(f"[ML] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
        await update.message.reply_text(
            f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏: {e}",
            reply_markup=get_models_keyboard(user_id)
        )
            
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ retrain_model_command: {e}", exc_info=True)
        await update.message.reply_text(
            f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}",
            reply_markup=get_models_keyboard(user_id)
        )
# -------- TOGGLE FUNCTIONS (ML / GPT / SMC) --------
async def toggle_ml(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)
    user_data['ml_enabled'] = not user_data.get('ml_enabled', ML_ENABLED)
    status = "üü¢ ML: –í–ö–õ" if user_data['ml_enabled'] else "üî¥ ML: –í–´–ö–õ"
    await update.message.reply_text(f"‚öôÔ∏è ML —Ä–µ–∂–∏–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω: {status}", reply_markup=get_models_keyboard(user_id))


async def toggle_gpt(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)
    user_data['gpt_enabled'] = not user_data.get('gpt_enabled', USE_GPT)
    status = "üü¢ GPT: –í–ö–õ" if user_data['gpt_enabled'] else "üî¥ GPT: –í–´–ö–õ"
    await update.message.reply_text(f"‚öôÔ∏è GPT —Ä–µ–∂–∏–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω: {status}", reply_markup=get_models_keyboard(user_id))


async def toggle_smc(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)
    user_data['smc_enabled'] = not user_data.get('smc_enabled', True)
    status = "üü¢ SMC: –í–ö–õ" if user_data['smc_enabled'] else "üî¥ SMC: –í–´–ö–õ"
    await update.message.reply_text(f"‚öôÔ∏è SMC –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω: {status}", reply_markup=get_models_keyboard(user_id))


# -------- –ù–û–í–´–ï –ö–û–ú–ê–ù–î–´ (–î–û–ë–ê–í–¨–¢–ï –≠–¢–û–¢ –ë–õ–û–ö) --------
async def settings_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞"""
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)
    
    personal_stake = user_data.get('personal_stake', STAKE_AMOUNT)
    auto_trading = user_data.get('auto_trading', AUTO_TRADING)
    ml_enabled = user_data.get('ml_enabled', ML_ENABLED)
    gpt_enabled = user_data.get('gpt_enabled', USE_GPT)
    
    settings_text = (
        f"‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò –ë–û–¢–ê\n\n"
        f"üí∞ –°—Ç–∞–≤–∫–∞: {personal_stake}\n"
        f"ü§ñ –ê–≤—Ç–æ-—Ç–æ—Ä–≥–æ–≤–ª—è: {'‚úÖ –í–ö–õ' if auto_trading else '‚ùå –í–´–ö–õ'}\n"
        f"üß† ML: {'‚úÖ –í–ö–õ' if ml_enabled else '‚ùå –í–´–ö–õ'}\n"
        f"üí¨ GPT: {'‚úÖ –í–ö–õ' if gpt_enabled else '‚ùå –í–´–ö–õ'}\n\n"
        f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—é –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫."
    )
    
    await update.message.reply_text(settings_text, reply_markup=main_markup)

async def stop_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –±–æ—Ç–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    user_id = update.effective_user.id
    
    if MULTI_USER_MODE and not is_admin(user_id):
        await update.message.reply_text("‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")
        return
        
    global IS_RUNNING
    IS_RUNNING = False
    
    await update.message.reply_text("üõë –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç.")
    logging.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ø—Ä–∞–≤–∫—É –ø–æ –∫–æ–º–∞–Ω–¥–∞–º"""
    help_text = (
        "üìã –°–ü–†–ê–í–ö–ê –ü–û –ö–û–ú–ê–ù–î–ê–ú\n\n"
        "–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "‚Ä¢ /start - –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞\n"
        "‚Ä¢ /status - –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã\n"
        "‚Ä¢ /stats - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏\n"
        "‚Ä¢ /history - –ò—Å—Ç–æ—Ä–∏—è —Å–¥–µ–ª–æ–∫\n"
        "‚Ä¢ /next - –°–ª–µ–¥—É—é—â–∏–π —Å–∏–≥–Ω–∞–ª\n"
        "‚Ä¢ /settings - –ù–∞—Å—Ç—Ä–æ–π–∫–∏\n\n"
        "–î–ª—è ML –º–æ–¥–µ–ª–∏:\n"
        "‚Ä¢ /modelstats - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ML\n"
        "‚Ä¢ /retrain - –ü–µ—Ä–µ–æ–±—É—á–∏—Ç—å ML\n\n"
        "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:\n"
        "‚Ä¢ /stake <—Å—É–º–º–∞> - –ò–∑–º–µ–Ω–∏—Ç—å —Å—Ç–∞–≤–∫—É\n"
        "‚Ä¢ /resetbalance - –°–±—Ä–æ—Å–∏—Ç—å –±–∞–ª–∞–Ω—Å\n"
        "‚Ä¢ /stop - –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–æ—Ç–∞ (–∞–¥–º–∏–Ω)\n\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞! üéØ"
    )
    
    await update.message.reply_text(help_text, reply_markup=main_markup)

async def toggle_auto_trading(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç –∞–≤—Ç–æ-—Ç—Ä–µ–π–¥–∏–Ω–≥ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)
    
    user_data['auto_trading'] = not user_data.get('auto_trading', False)
    status = "üü¢ –í–ö–õ" if user_data['auto_trading'] else "üî¥ –í–´–ö–õ"
    
    await update.message.reply_text(
        f"ü§ñ –ê–≤—Ç–æ-—Ç—Ä–µ–π–¥–∏–Ω–≥: {status}",
        reply_markup=get_trading_keyboard(user_id)
    )
    save_users_data()
    
async def clear_active_trade_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û—á–∏—â–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—É—é —Å–¥–µ–ª–∫—É (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)"""
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)
    
    if user_data.get('current_trade'):
        trade_info = user_data['current_trade']
        user_data['current_trade'] = None
        save_users_data()
        
        await update.message.reply_text(
            f"üîÑ –ê–∫—Ç–∏–≤–Ω–∞—è —Å–¥–µ–ª–∫–∞ –æ—á–∏—â–µ–Ω–∞:\n"
            f"–ü–∞—Ä–∞: {trade_info.get('pair')}\n"
            f"–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {trade_info.get('direction')}\n"
            f"–¶–µ–Ω–∞: {trade_info.get('entry_price')}\n\n"
            f"–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –Ω–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª.",
            reply_markup=get_trading_keyboard(user_id)
        )
    else:
        await update.message.reply_text(
            "‚úÖ –ê–∫—Ç–∏–≤–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –Ω–µ—Ç",
            reply_markup=get_trading_keyboard(user_id)
        )

async def restore_counter_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫ —Å–¥–µ–ª–æ–∫"""
    user_id = update.effective_user.id
    
    if MULTI_USER_MODE and not is_admin(user_id):
        await update.message.reply_text("‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")
        return
        
    await update.message.reply_text("üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–∞ —Å–¥–µ–ª–æ–∫...")
    
    try:
        if MULTI_USER_MODE:
            for user_id, user_data in users.items():
                actual_trades = len(user_data.get('trade_history', []))
                current_counter = user_data.get('trade_counter', 0)
                
                if actual_trades > current_counter:
                    user_data['trade_counter'] = actual_trades
                    await update.message.reply_text(
                        f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å—á–µ—Ç—á–∏–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}:\n"
                        f"–ë—ã–ª–æ: {current_counter}\n"
                        f"–°—Ç–∞–ª–æ: {actual_trades}"
                    )
                else:
                    await update.message.reply_text(
                        f"‚ÑπÔ∏è –°—á–µ—Ç—á–∏–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω: {current_counter}"
                    )
        else:
            actual_trades = len(single_user_data.get('trade_history', []))
            current_counter = single_user_data.get('trade_counter', 0)
            
            if actual_trades > current_counter:
                single_user_data['trade_counter'] = actual_trades
                await update.message.reply_text(
                    f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å—á–µ—Ç—á–∏–∫:\n"
                    f"–ë—ã–ª–æ: {current_counter}\n"
                    f"–°—Ç–∞–ª–æ: {actual_trades}"
                )
            else:
                await update.message.reply_text(
                    f"‚ÑπÔ∏è –°—á–µ—Ç—á–∏–∫ –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω: {current_counter}"
                )
        
        save_users_data()
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å—á–µ—Ç—á–∏–∫–∞: {e}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")

async def check_data_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö"""
    user_id = update.effective_user.id
    
    if MULTI_USER_MODE and not is_admin(user_id):
        await update.message.reply_text("‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")
        return
        
    try:
        message = "üìä –ü–†–û–í–ï–†–ö–ê –î–ê–ù–ù–´–•:\n\n"
        
        if MULTI_USER_MODE:
            if os.path.exists("users_data.json"):
                with open("users_data.json", "r", encoding="utf-8") as f:
                    data = json.load(f)
                message += f"‚úÖ users_data.json: {len(data)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n"
                
                for uid, user_data in data.items():
                    trades = len(user_data.get('trade_history', []))
                    counter = user_data.get('trade_counter', 0)
                    message += f"üë§ {uid}: —Å–¥–µ–ª–æ–∫={trades}, —Å—á–µ—Ç—á–∏–∫={counter}\n"
            else:
                message += "‚ùå users_data.json –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n"
                
            message += f"\nüìà –¢–ï–ö–£–©–ê–Ø –ü–ê–ú–Ø–¢–¨: {len(users)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n"
            for uid, user_data in users.items():
                trades = len(user_data.get('trade_history', []))
                counter = user_data.get('trade_counter', 0)
                message += f"üë§ {uid}: —Å–¥–µ–ª–æ–∫={trades}, —Å—á–µ—Ç—á–∏–∫={counter}\n"
                
        else:
            if os.path.exists("single_user_data.json"):
                with open("single_user_data.json", "r", encoding="utf-8") as f:
                    data = json.load(f)
                trades = len(data.get('trade_history', []))
                counter = data.get('trade_counter', 0)
                message += f"‚úÖ single_user_data.json: —Å–¥–µ–ª–æ–∫={trades}, —Å—á–µ—Ç—á–∏–∫={counter}\n"
            else:
                message += "‚ùå single_user_data.json –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n"
                
            message += f"\nüìà –¢–ï–ö–£–©–ê–Ø –ü–ê–ú–Ø–¢–¨: —Å–¥–µ–ª–æ–∫={len(single_user_data.get('trade_history', []))}, —Å—á–µ—Ç—á–∏–∫={single_user_data.get('trade_counter', 0)}"
        
        await update.message.reply_text(message)
        
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")

async def restore_from_backup_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –±—ç–∫–∞–ø–∞"""
    user_id = update.effective_user.id

    if MULTI_USER_MODE and not is_admin(user_id):
        await update.message.reply_text("‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")
        return

    await update.message.reply_text("üîÑ –ü–æ–∏—Å–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –¥–∞–Ω–Ω—ã—Ö...")

    try:
        backup_files = []
        if os.path.exists("backups"):
            backup_files = [f for f in os.listdir("backups") if f.startswith("users_data_backup")]

        if not backup_files:
            await update.message.reply_text("‚ùå –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ backups/")
            return

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤–µ–π—à–∏–µ –ø–µ—Ä–≤—ã–º–∏)
        backup_files.sort(reverse=True)
        latest_backup = os.path.join("backups", backup_files[0])

        await update.message.reply_text(f"üìÇ –ù–∞–π–¥–µ–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_files[0]}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –±—ç–∫–∞–ø–∞
        with open(latest_backup, "r", encoding="utf-8") as f:
            backup_data = json.load(f)

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç—å
        global users
        users.clear()

        for uid_str, user_data in backup_data.items():
            users[int(uid_str)] = user_data

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        save_users_data()

        # ‚úÖ üìå –í–ê–ñ–ù–û: —Å—Ä–∞–∑—É –æ–±–Ω–æ–≤–ª—è–µ–º –ø–∞–º—è—Ç—å –∏–∑ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        users.clear()
        load_users_data()
        logging.info("‚ôªÔ∏è –ü–∞–º—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—Å–ª–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –±—ç–∫–∞–ø–∞")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_trades = sum(len(user_data.get('trade_history', [])) for user_data in users.values())
        await update.message.reply_text(
            f"‚úÖ –î–∞–Ω–Ω—ã–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏–∑ –±—ç–∫–∞–ø–∞!\n"
            f"üìä –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(users)}\n"
            f"üìà –°–¥–µ–ª–æ–∫: {total_trades}\n"
            f"‚ôªÔ∏è –ü–∞–º—è—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞ ‚Äî –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è"
        )

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ –±—ç–∫–∞–ø–∞: {e}", exc_info=True)
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")


async def recalculate_real_ml_features_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç ML —Ñ–∏—á–∏ –Ω–∞ –†–ï–ê–õ–¨–ù–´–• –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Å–¥–µ–ª–æ–∫ —Å –Ω–æ–≤—ã–º–∏ —Ñ–∏—á–∞–º–∏"""
    user_id = update.effective_user.id
    
    if MULTI_USER_MODE and not is_admin(user_id):
        await update.message.reply_text("‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")
        return
        
    await update.message.reply_text("üîÑ –ü–µ—Ä–µ—Å—á–µ—Ç –†–ï–ê–õ–¨–ù–´–• ML —Ñ–∏—á–µ–π –¥–ª—è –≤—Å–µ—Ö —Å–¥–µ–ª–æ–∫ —Å –Ω–æ–≤—ã–º–∏ —Ñ–∏—á–∞–º–∏...")
    
    try:
        recalculated_count = 0
        failed_count = 0
        total_trades = 0
        
        # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        if MULTI_USER_MODE:
            for user_id, user_data in users.items():
                total_trades += len(user_data.get('trade_history', []))
        else:
            total_trades = len(all_trades)
        
        processed = 0
        
        if MULTI_USER_MODE:
            for user_id, user_data in users.items():
                for trade in user_data.get('trade_history', []):
                    if trade.get('pair'):
                        pair = trade['pair']
                        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞
                        df_m1 = get_mt5_data(pair, 400, mt5.TIMEFRAME_M1)
                        
                        if df_m1 is not None and len(df_m1) > 100:
                            # ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é prepare_ml_features() ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è
                            feats = prepare_ml_features(df_m1)
                            if feats is not None:
                                # ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è –í–ê–ñ–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º –í–°–ï —Ñ–∏—á–∏, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ 9 ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è
                                trade['ml_features'] = feats  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ñ–∏—á–∏ –∫–∞–∫ –µ—Å—Ç—å
                                recalculated_count += 1
                                logging.info(f"‚úÖ –ü–µ—Ä–µ—Å—á–∏—Ç–∞–Ω—ã —Ñ–∏—á–∏ –¥–ª—è {pair} (—Ñ–∏—á–µ–π: {len(feats)})")
                            else:
                                failed_count += 1
                                logging.warning(f"‚ùå prepare_ml_features –≤–µ—Ä–Ω—É–ª None –¥–ª—è {pair}")
                        else:
                            failed_count += 1
                            
                    processed += 1
                    # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 20 —Å–¥–µ–ª–æ–∫
                    if processed % 20 == 0:
                        await update.message.reply_text(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed}/{total_trades} —Å–¥–µ–ª–æ–∫...")
        
        else:
            # –†–µ–∂–∏–º –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            for i, trade in enumerate(all_trades):
                if trade.get('pair'):
                    pair = trade['pair']
                    df_m1 = get_mt5_data(pair, 400, mt5.TIMEFRAME_M1)
                    
                    if df_m1 is not None and len(df_m1) > 100:
                        feats = prepare_ml_features(df_m1)
                        if feats is not None:
                            trade['ml_features'] = feats  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ñ–∏—á–∏
                            recalculated_count += 1
                            logging.info(f"‚úÖ –ü–µ—Ä–µ—Å—á–∏—Ç–∞–Ω—ã —Ñ–∏—á–∏ –¥–ª—è {pair} (—Ñ–∏—á–µ–π: {len(feats)})")
                        else:
                            failed_count += 1
                    else:
                        failed_count += 1
                
                processed += 1
                if processed % 20 == 0 and processed > 0:
                    await update.message.reply_text(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed}/{total_trades} —Å–¥–µ–ª–æ–∫...")
        
        if recalculated_count > 0:
            save_users_data()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á –≤ –ø–µ—Ä–≤–æ–π —É—Å–ø–µ—à–Ω–æ–π —Å–¥–µ–ª–∫–µ
            sample_features_count = 0
            if MULTI_USER_MODE:
                for user_id, user_data in users.items():
                    for trade in user_data.get('trade_history', []):
                        if trade.get('ml_features'):
                            sample_features_count = len(trade['ml_features'])
                            break
                    if sample_features_count > 0:
                        break
            else:
                for trade in all_trades:
                    if trade.get('ml_features'):
                        sample_features_count = len(trade['ml_features'])
                        break
            
            await update.message.reply_text(
                f"‚úÖ –ü–µ—Ä–µ—Å—á–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!\n"
                f"‚Ä¢ –£—Å–ø–µ—à–Ω–æ: {recalculated_count} —Å–¥–µ–ª–æ–∫\n"
                f"‚Ä¢ –û—à–∏–±–æ–∫: {failed_count}\n"
                f"‚Ä¢ –ù–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á: {sample_features_count}\n"
                f"üí° –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å /retrain"
            )
        else:
            await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π —Å–¥–µ–ª–∫–∏")
            
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ ML —Ñ–∏—á–µ–π: {e}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")

async def recalculate_ml_features_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç ML —Ñ–∏—á–∏ –¥–ª—è –í–°–ï–• —Å–¥–µ–ª–æ–∫"""
    await update.message.reply_text("üîÑ –ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ—Å—á–µ—Ç ML —Ñ–∏—á–µ–π –¥–ª—è –≤—Å–µ—Ö —Å–¥–µ–ª–æ–∫...")
    
    recalculated = 0
    errors = 0
    total = len(all_trades)
    
    for i, trade in enumerate(all_trades):
        try:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–¥–µ–ª–∫–∏ –±–µ–∑ –ø–∞—Ä—ã
            if not trade.get('pair'):
                continue
                
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
            df = get_historical_data(trade['pair'])
            if df is None or df.empty:
                errors += 1
                continue
            
            # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∏—á–∏
            new_features = prepare_ml_features(df)
            if new_features:
                trade['ml_features'] = new_features
                recalculated += 1
                
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Å–¥–µ–ª–æ–∫
            if i % 10 == 0:
                await update.message.reply_text(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{total} —Å–¥–µ–ª–æ–∫...")
                
        except Exception as e:
            errors += 1
            logging.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ —Ñ–∏—á –¥–ª—è —Å–¥–µ–ª–∫–∏ {trade.get('pair')}: {e}")
    
    save_users_data()
    
    message = (
        f"‚úÖ –ü–µ—Ä–µ—Å—á–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!\n"
        f"‚Ä¢ –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {total}\n"
        f"‚Ä¢ –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–æ: {recalculated}\n"
        f"‚Ä¢ –û—à–∏–±–æ–∫: {errors}\n"
        f"‚Ä¢ –ù–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á: {len(new_features) if recalculated > 0 else 'N/A'}"
    )
    await update.message.reply_text(message)

async def reset_ml_features_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–£–¥–∞–ª—è–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ ML —Ñ–∏—á–∏ –∏ –≥–æ—Ç–æ–≤–∏—Ç –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞"""
    user_id = update.effective_user.id
    
    if MULTI_USER_MODE and not is_admin(user_id):
        await update.message.reply_text("‚ùå –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")
        return
        
    await update.message.reply_text("üîÑ –°–±—Ä–æ—Å ML —Ñ–∏—á–µ–π –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    try:
        reset_count = 0
        
        if MULTI_USER_MODE:
            for user_id, user_data in users.items():
                for trade in user_data.get('trade_history', []):
                    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–ª—É—á–∞–π–Ω—ã–µ —Ñ–∏—á–∏
                    if trade.get('ml_features'):
                        trade['ml_features'] = None
                        trade['needs_ml_recalculation'] = True
                        reset_count += 1
        
        if reset_count > 0:
            save_users_data()
            await update.message.reply_text(
                f"‚úÖ –°–±—Ä–æ—à–µ–Ω–æ ML —Ñ–∏—á–µ–π: {reset_count} —Å–¥–µ–ª–æ–∫\n"
                f"üìù –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /recalculateml –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
            )
        else:
            await update.message.reply_text("‚ÑπÔ∏è –ù–µ—Ç ML —Ñ–∏—á–µ–π –¥–ª—è —Å–±—Ä–æ—Å–∞")
            
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–±—Ä–æ—Å–∞ ML —Ñ–∏—á–µ–π: {e}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")

async def force_enable_ml_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤–∫–ª—é—á–∞–µ—Ç ML –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏"""
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)
    
    user_data['ml_enabled'] = True
    save_users_data()
    
    await update.message.reply_text(
        "üü¢ ML –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –í–ö–õ–Æ–ß–ï–ù!\n"
        "üìä –¢–µ–∫—É—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: 50.0%\n"
        "‚ö†Ô∏è –ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–∞–∂–µ —Å –Ω–∏–∑–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é\n"
        "üîÑ –ú–æ–¥–µ–ª—å —É–ª—É—á—à–∏—Ç—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –ø—Ä–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö"
    )

# ===================== CLEAR ALL TRADES (ADMIN) =====================
from telegram import Update
from telegram.ext import ContextTypes

ADMIN_IDS = [5129282647]  

async def clear_all_trades_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–∞–µ—Ç –≤—Å–µ –æ—Ç–∫—Ä—ã—Ç—ã–µ —Å–¥–µ–ª–∫–∏ —É –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)"""
    user_id = update.effective_user.id

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤
    if user_id not in ADMIN_IDS:
        await update.message.reply_text("‚õî –£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã.")
        return

    cleared_count = 0
    for uid, data in users.items():
        if "current_trade" in data:
            data.pop("current_trade", None)
            cleared_count += 1
            logging.info(f"üßπ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–µ–Ω–∞ —Å–¥–µ–ª–∫–∞ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {uid}")

    save_users_data()
    logging.info(f"‚úÖ –ê–¥–º–∏–Ω {user_id} –æ—á–∏—Å—Ç–∏–ª {cleared_count} –æ—Ç–∫—Ä—ã—Ç—ã—Ö —Å–¥–µ–ª–æ–∫ —É –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")

    await update.message.reply_text(f"üßπ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–µ–Ω–æ —Å–¥–µ–ª–æ–∫: {cleared_count}")

# ===================== MARKET STATUS COMMAND =====================
async def market_status_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞ –ø–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –ª–æ–∫–∞–ª—å–Ω–æ–º—É –≥—Ä–∞—Ñ–∏–∫—É"""
    now = datetime.now()
    status = "üü¢ –†–ê–ë–û–¢–ê–ï–¢" if is_trading_time() else "üî¥ –í–ù–ï –ì–†–ê–§–ò–ö–ê"

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º—è –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∏—è, –µ—Å–ª–∏ —Å–µ–π—á–∞—Å –≤–Ω–µ –≥—Ä–∞—Ñ–∏–∫–∞
    if not is_trading_time():
        today_open = datetime.combine(now.date(), TRADING_START)
        tomorrow_open = datetime.combine(now.date() + timedelta(days=1), TRADING_START)
        next_open = today_open if now.time() < TRADING_START else tomorrow_open
        time_until_open = next_open - now
        hours, remainder = divmod(int(time_until_open.total_seconds()), 3600)
        minutes = remainder // 60
        until_text = f"‚è∞ –î–æ –æ—Ç–∫—Ä—ã—Ç–∏—è: {hours} —á {minutes} –º–∏–Ω"
    else:
        until_text = "‚úÖ –ë–æ—Ç —Å–µ–π—á–∞—Å –∞–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç"

    status_text = (
        f"üìä –°–¢–ê–¢–£–° –†–ê–ë–û–¢–´ –ë–û–¢–ê\n\n"
        f"üïê –¢–µ–∫—É—â–µ–µ –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {now.strftime('%Y-%m-%d %H:%M:%S')}\n"
        f"üìà –°—Ç–∞—Ç—É—Å: {status}\n"
        f"{until_text}\n\n"
        f"üïí –ì—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã:\n"
        f"‚Ä¢ –ö–∞–∂–¥—ã–π –¥–µ–Ω—å: {TRADING_START.strftime('%H:%M')} ‚Äî {TRADING_END.strftime('%H:%M')}"
    )

    await update.message.reply_text(status_text)

# üîß –î–û–ë–ê–í–¨–¢–ï –≠–¢–£ –§–£–ù–ö–¶–ò–Æ –ü–û–°–õ–ï market_status_command
async def debug_user_data(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)
    
    # –î–∞–Ω–Ω—ã–µ –∏–∑ –ø–∞–º—è—Ç–∏
    memory_trades = len(user_data.get('trade_history', []))
    memory_counter = user_data.get('trade_counter', 0)
    
    # –î–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    file_trades = 0
    if MULTI_USER_MODE and os.path.exists("users_data.json"):
        with open("users_data.json", "r", encoding="utf-8") as f:
            file_data = json.load(f)
            if str(user_id) in file_data:
                file_trades = len(file_data[str(user_id)].get('trade_history', []))
    
    debug_text = (
        f"üîß –û–¢–õ–ê–î–ö–ê –î–ê–ù–ù–´–•\n\n"
        f"üë§ User ID: {user_id}\n"
        f"üíæ –í –ø–∞–º—è—Ç–∏: {memory_trades} —Å–¥–µ–ª–æ–∫, —Å—á–µ—Ç—á–∏–∫: {memory_counter}\n"
        f"üìÅ –í —Ñ–∞–π–ª–µ: {file_trades} —Å–¥–µ–ª–æ–∫\n"
        f"üìä –ó–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö: {len([t for t in user_data.get('trade_history', []) if t.get('result') in ('WIN', 'LOSS')])}"
    )
    
    await update.message.reply_text(debug_text)

# ===================== HANDLE MESSAGE =====================
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ì–ª–∞–≤–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–∂–∞—Ç–∏–π –Ω–∞ –∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é"""
    text = update.message.text
    user_id = update.effective_user.id

    # ---------- üìå –ì–õ–ê–í–ù–û–ï –ú–ï–ù–Æ ----------
    if text == "üìä –¢–æ—Ä–≥–æ–≤–ª—è":
        await trading_menu(update, context)

    elif text == "‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ":
        await management_menu(update, context)

    elif text == "üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞":
        await statistics_command(update, context)

    elif text == "üß† –ú–æ–¥–µ–ª–∏":
        await models_menu(update, context)

    elif text == "üìã –ü–æ–º–æ—â—å":
        await help_command(update, context)

    elif text == "üìÖ –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ":  # ‚Üê –î–û–ë–ê–í–¨–¢–ï –≠–¢–û–¢ –ë–õ–û–ö
        await schedule_command(update, context)

    # ---------- ‚¨ÖÔ∏è –í–û–ó–í–†–ê–¢ –í –ú–ï–ù–Æ ----------
    elif text in ["‚óÄÔ∏è –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", "‚óÄÔ∏è –ù–∞–∑–∞–¥", "‚óÄÔ∏è –ù–∞–∑–∞–¥ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"]:
        await update.message.reply_text("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", reply_markup=main_markup)


    # ---------- üìä –ú–ï–ù–Æ –¢–û–†–ì–û–í–õ–ò ----------
    elif text == "üîÑ –°–ª–µ–¥—É—é—â–∏–π —Å–∏–≥–Ω–∞–ª":
        await next_signal_command(update, context)

    elif text == "üìà –ò—Å—Ç–æ—Ä–∏—è":
        await history_command(update, context)

    elif "–ê–≤—Ç–æ-—Ç–æ—Ä–≥–æ–≤–ª—è" in text:
        await toggle_auto_trading(update, context)


    # ---------- üß† –ú–ï–ù–Æ –ú–û–î–ï–õ–ï–ô ----------
    elif text == "üìä ML –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞":
        await model_stats_command(update, context)

    elif text == "üîÑ –û–±—É—á–∏—Ç—å ML":
        await retrain_model_command(update, context)

    elif "ML:" in text:
        await toggle_ml(update, context)

    elif "GPT:" in text:
        await toggle_gpt(update, context)

    elif "SMC:" in text:
        await toggle_smc(update, context)


    # ---------- ‚ùì –ù–ï–ò–ó–í–ï–°–¢–ù–´–ô –í–í–û–î ----------
    else:
        await update.message.reply_text("‚ùì –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é", reply_markup=main_markup)



# ===================== –ú–ï–ù–Æ –ü–û–î–†–ê–ó–î–ï–õ–û–í =====================
async def trading_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """üìä –ú–µ–Ω—é —Ç–æ—Ä–≥–æ–≤–ª–∏"""
    user_id = update.effective_user.id
    await update.message.reply_text(
        "üìä –ú–ï–ù–Æ –¢–û–†–ì–û–í–õ–ò\n\n–£–ø—Ä–∞–≤–ª—è–π—Ç–µ —Å–∏–≥–Ω–∞–ª–∞–º–∏ –∏ –∞–≤—Ç–æ-—Ç–æ—Ä–≥–æ–≤–ª–µ–π üëá",
        reply_markup=get_trading_keyboard(user_id)
    )


async def models_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """üß† –ú–µ–Ω—é –º–æ–¥–µ–ª–µ–π"""
    user_id = update.effective_user.id
    user_data = get_user_data(user_id)

    ml_state = "–≤–∫–ª—é—á–µ–Ω–æ" if user_data.get('ml_enabled', ML_ENABLED) else "–æ—Ç–∫–ª—é—á–µ–Ω–æ"
    gpt_state = "–≤–∫–ª—é—á–µ–Ω–æ" if user_data.get('gpt_enabled', USE_GPT) else "–æ—Ç–∫–ª—é—á–µ–Ω–æ"
    smc_state = "–≤–∫–ª—é—á–µ–Ω–æ" if user_data.get('smc_enabled', True) else "–æ—Ç–∫–ª—é—á–µ–Ω–æ"

    await update.message.reply_text(
        f"üß† –£–ü–†–ê–í–õ–ï–ù–ò–ï –ú–û–î–ï–õ–Ø–ú–ò\n\n"
        f"ü§ñ ML: {ml_state}\n"
        f"üí¨ GPT: {gpt_state}\n"
        f"üìä SMC: {smc_state}\n\n"
        f"–í–∫–ª—é—á–∞–π—Ç–µ –∏–ª–∏ –æ—Ç–∫–ª—é—á–∞–π—Ç–µ –Ω—É–∂–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã üëá",
        reply_markup=get_models_keyboard(user_id)
    )

async def management_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """‚öôÔ∏è –ú–µ–Ω—é —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–æ—Ç–æ–º"""
    await update.message.reply_text(
        "‚öôÔ∏è –£–ü–†–ê–í–õ–ï–ù–ò–ï –°–ò–°–¢–ï–ú–û–ô\n\n–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –∫–æ–Ω—Ç—Ä–æ–ª—å –±–æ—Ç–∞ üëá",
        reply_markup=management_markup
    )

# ===================== MAIN =====================
def main():
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞
    try:
        with open("bot_ai.log", "a", encoding="utf-8") as f:
            f.write(f"\n{'='*50}\n")
            f.write(f"üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –±–æ—Ç–∞: {datetime.now()}\n")
            f.write(f"{'='*50}\n")
        logging.info("‚úÖ –ü—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –ª–æ–≥-—Ñ–∞–π–ª—É –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –ª–æ–≥-—Ñ–∞–π–ª—É: {e}")
        return
    
    # üîß 6. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–¢–ê–¢–£–°–ê –ë–û–¢–ê –ü–†–ò –ó–ê–ü–£–°–ö–ï
    global BOT_LAST_STATUS, BOT_STATUS_NOTIFIED
    BOT_LAST_STATUS = is_trading_time()
    BOT_STATUS_NOTIFIED = False
    
    # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
    status_text = "üü¢ –†–ê–ë–û–¢–ê–ï–¢" if BOT_LAST_STATUS else "üî¥ –û–°–¢–ê–ù–û–í–õ–ï–ù (–≤–Ω–µ —Ä–∞–±–æ—á–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)"
    logging.info(f"ü§ñ –°—Ç–∞—Ç—É—Å –±–æ—Ç–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ: {status_text}")
    print(f"ü§ñ –°—Ç–∞—Ç—É—Å –±–æ—Ç–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ: {status_text}")
    
    # –ï—Å–ª–∏ –±–æ—Ç –∑–∞–ø—É—â–µ–Ω –≤ –Ω–µ—Ä–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è - –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º
    if not BOT_LAST_STATUS:
        now = datetime.now()
        logging.warning(f"‚è∏ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –≤ –Ω–µ—Ä–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è: {now.strftime('%Y-%m-%d %H:%M:%S')}")
        print("‚ö† –í–ù–ò–ú–ê–ù–ò–ï: –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –≤ –Ω–µ—Ä–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è –∏ –±—É–¥–µ—Ç –æ–∂–∏–¥–∞—Ç—å –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—á–µ–≥–æ –¥–Ω—è")
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MT5
    if not mt5.initialize(path=MT5_PATH, login=MT5_LOGIN, password=MT5_PASSWORD, server=MT5_SERVER):
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MT5: {mt5.last_error()}")
        return
    logging.info("‚úÖ MT5 –ø–æ–¥–∫–ª—é—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
    print("‚úÖ MT5 –ø–æ–¥–∫–ª—é—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è Telegram
    app = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(CommandHandler("status", status_command))
    app.add_handler(CommandHandler("schedule", schedule_command))
    app.add_handler(CommandHandler("whitelist_add", whitelist_add_command))
    app.add_handler(CommandHandler("whitelist_remove", whitelist_remove_command))
    app.add_handler(CommandHandler("whitelist_stats", whitelist_stats_command))
    app.add_handler(CommandHandler("whitelist_show", whitelist_show_command))    
    app.add_handler(CommandHandler("history", history_command))
    app.add_handler(CommandHandler("next", next_signal_command))
    app.add_handler(CommandHandler("stats", statistics_command))
    app.add_handler(CommandHandler("modelstats", model_stats_command))
    app.add_handler(CommandHandler("retrain", retrain_model_command))  
    app.add_handler(CommandHandler("settings", settings_command))
    app.add_handler(CommandHandler("stop", stop_command))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("cleartrade", clear_active_trade_command))
    app.add_handler(CommandHandler("repairml", repair_ml_command))
    app.add_handler(CommandHandler("restorecounter", restore_counter_command))
    app.add_handler(CommandHandler("checkdata", check_data_command))
    app.add_handler(CommandHandler("restorebackup", restore_from_backup_command))
    app.add_handler(CommandHandler("recalculateml", recalculate_real_ml_features_command))
    app.add_handler(CommandHandler("resetml", reset_ml_features_command))
    app.add_handler(CommandHandler("forceml", force_enable_ml_command))
    app.add_handler(CommandHandler("marketstatus", market_status_command))
    app.add_handler(CommandHandler("clearalltrades", clear_all_trades_command))
    app.add_handler(CommandHandler("debug", debug_user_data))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    # ===================== JOB QUEUE =====================
    job_queue = app.job_queue
    if job_queue:
        job_queue.run_repeating(auto_trading_loop, interval=60, first=10)  # 60 —Å–µ–∫—É–Ω–¥ –≤–º–µ—Å—Ç–æ 30
        job_queue.scheduler.add_listener(job_listener, 
                                   EVENT_JOB_MISSED | EVENT_JOB_ERROR | EVENT_JOB_EXECUTED)
        logging.info("üìÖ JobQueue –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ‚Äî –∞–≤—Ç–æ—Ü–∏–∫–ª –∫–∞–∂–¥—ã–µ 60 —Å–µ–∫ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º")
        
    else:
        logging.error("‚ùå JobQueue –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ‚Äî –∞–≤—Ç–æ—Ü–∏–∫–ª –Ω–µ –∑–∞–ø—É—â–µ–Ω")
        return

    # ===================== –°–¢–ê–†–¢ =====================
    IS_RUNNING = True   # ‚ö° –í–ê–ñ–ù–û: —Ç–µ–ø–µ—Ä—å —Ü–∏–∫–ª —Ä–µ–∞–ª—å–Ω–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å
    logging.info("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    app.run_polling()
    
    # ===================== –ó–ê–í–ï–†–®–ï–ù–ò–ï =====================
    IS_RUNNING = False
    save_users_data()
    mt5.shutdown()
    logging.info("üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã, MT5 –æ—Ç–∫–ª—é—á–µ–Ω")
    print("üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã, MT5 –æ—Ç–∫–ª—é—á–µ–Ω")


if __name__ == "__main__":
    main()

